import io
import json
import logging
from pathlib import Path
from typing import List

from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.responses import JSONResponse, HTMLResponse, PlainTextResponse, FileResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from convey_extract import extract_with_ocr_fallback, conv_extract_from_text, pdf_to_text
from risk import risk_engine
from risk_extra import from_title_blocks, checklist_from_extracted
from title_ingest import parse_title_text, summarise_title
from db import get_session, insert_convey_search, list_convey_searches, set_review_flag, get_convey_search, add_note, list_notes, add_title_doc, get_title_docs
from models import ConveySearch
from pack_export import build_pack
from completion import sdlt_draft
from notify import send_email_console, send_webhook
from aml import aml_start, aml_status, parse_bank_csv
logging.basicConfig(level=logging.INFO)
app = FastAPI()
@app.get("/api/ping")
def api_ping()
:
    return {"ok": True}
# Serve frontend if present
frontend_dir = Path("frontend")
if frontend_dir.exists()
:
    app.mount("/app", StaticFiles(directory=str(frontend_dir)
, html=True)
, name="app")
@app.get("/", response_class=HTMLResponse)
def root()
:
    idx = frontend_dir / "index.html"
    if idx.exists()
:
        return idx.read_text()
return "<h1>Domus Conveyancing</h1><p>Frontend not found. Upload via /app .</p>"
# --------- API: list recent ---------
@app.get("/api/searches")
def api_list()
:
    from db import get_session, list_convey_searches
    with get_session()
as session:
        rows = list_convey_searches(session)
out = []
        for r in rows:
            out.append({
                "id": r.id,
                "filename": r.filename,
                "council": r.council,
                "risk_score": r.risk_score,
                "needs_review": bool(r.needs_review)
,
                "created_at": str(r.created_at)
if r.created_at else ""
            })
return JSONResponse(out)
def api_list()
:
    from db import get_session, list_convey_searches
    with get_session()
as session:
        rows = list_convey_searches(session)
out = []
        for r in rows:
            out.append({
                "id": r.id,
                "filename": r.filename,
                "council": r.council,
                "risk_score": r.risk_score,
                "needs_review": bool(r.needs_review)
,
                "created_at": str(r.created_at)
if r.created_at else ""
            })
return JSONResponse(out)
def api_list()
:
    from db import get_session, list_convey_searches
    from models import ConveySearch  # not used directly; keeps imports consistent
    with get_session()
as session:
        rows = list_convey_searches(session)
out = []
        for r in rows:
            out.append({
                "id": r.id,
                "filename": r.filename,
                "council": r.council,
                "risk_score": r.risk_score,
                "needs_review": bool(r.needs_review)
,
                "created_at": str(r.created_at)
if r.created_at else ""
            })
return JSONResponse(out)
def api_list()
:
    from db import get_session, list_convey_searches
    from models import ConveySearch  # not used directly; keeps imports consistent
    with get_session()
as session:
        rows = list_convey_searches(session)
out = []
        for r in rows:
            out.append({
                "id": r.id,
                "filename": r.filename,
                "council": r.council,
                "risk_score": r.risk_score,
                "needs_review": bool(r.needs_review)
,
                "created_at": str(r.created_at)
if r.created_at else ""
            })
return JSONResponse(out)
# --------- API: review queue ---------
@app.get("/api/review-queue")
def api_review_queue()
:
    from db import get_session
    with get_session()
as session:
        rows = (
            session.query(ConveySearch)
.filter(ConveySearch.needs_review == True)
# noqa: E712
            .order_by(ConveySearch.created_at.desc()
.all()
)
out = []
        for r in rows:
            out.append({
                "id": r.id,
                "filename": r.filename,
                "council": r.council,
                "needs_review": bool(r.needs_review)
,
                "created_at": str(r.created_at)
if r.created_at else ""
            })
return JSONResponse(out)
def api_review_queue()
:
    from db import get_session
    from models import ConveySearch
    with get_session()
as session:
        rows = (
    session.query(ConveySearch)
    .filter(ConveySearch.needs_review == True)
    .order_by(ConveySearch.created_at.desc()
    .all()
)
# noqa: E712
        out = []
        for r in rows:
            out.append({
                "id": r.id,
                "filename": r.filename,
                "council": r.council,
                "needs_review": bool(r.needs_review)
,
                "created_at": str(r.created_at)
if r.created_at else ""
            })
return JSONResponse(out)
def api_review_queue()
:
    from db import get_session
    from models import ConveySearch
    with get_session()
as session:
        rows = (
    session.query(ConveySearch)
    .filter(ConveySearch.needs_review == True)
    .order_by(ConveySearch.created_at.desc()
    .all()
)
# noqa: E712
        out = []
        for r in rows:
            out.append({
                "id": r.id,
                "filename": r.filename,
                "council": r.council,
                "needs_review": bool(r.needs_review)
,
                "created_at": str(r.created_at)
if r.created_at else ""
            })
return JSONResponse(out)
def api_review_queue()
:
    from db import get_session
    from models import ConveySearch
rows = (
    session.query(ConveySearch)
.filter(ConveySearch.needs_review == True)
# noqa: E712
    .order_by(ConveySearch.created_at.desc()
.all()
)
rows = (
    session.query(ConveySearch)
.filter(ConveySearch.needs_review == True)
# noqa: E712
    .order_by(ConveySearch.created_at.desc()
.all()
)
@app.patch("/api/search/{rec_id}/review")
def api_set_review(rec_id: int, flag: bool = Form(...)
:
        ok = set_review_flag(session, rec_id, flag)
if not ok:
            raise HTTPException(status_code=404, detail="Record not found")
return {"id": rec_id, "needs_review": bool(flag)
}
# --------- API: save notes ---------
@app.post("/api/search/{rec_id}/notes")
def api_save_notes(rec_id: int, notes: str = Form("")
:
        ok = save_notes(session, rec_id, notes or "")
return {"id": rec_id, "notes": notes or ""}
# --------- API: PDF summary ---------
@app.get("/api/report/{rec_id}.pdf")
def api_pdf(rec_id: int)
:
        rec = get_convey_search, add_note, list_notes(session, rec_id)
if not rec:
        pdf_bytes = build_summary_pdf(rec)
return HTMLResponse(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={"Content-Disposition": f'inline; filename="summary-{rec_id}.pdf"'}
        )
# --------- API: process PDFs ---------
@app.post("/api/process-batch")
async def api_process_batch(request: Request, council: str = Form("")
, files: List[UploadFile] = File(...)
:
    logging.info("POST /api/process-batch  council=%r  files=%d", council, len(files)
if files else 0)
if not files or len(files)
== 0:
        raise HTTPException(status_code=400, detail="No files uploaded. Make sure the input name is 'files' and at least one PDF is selected.")
results, ids, errors = [], [], []
    for file in files:
        fname = getattr(file, "filename", "unknown.pdf")
try:
            logging.info("Processing file: %s (content_type=%s)")
", fname, getattr(file, "content_type", "?")
data = await file.read()
if not data:
                raise ValueError("Uploaded file has zero bytes")
# Extract
            try:
                text = pdf_to_text(data)
except Exception:
                text = None
            if not text or len(text)
< 50:
                logging.info("PDF text is short/empty; trying OCR fallback: %s", fname)
text = extract_with_ocr_fallback(data)
# may return str or dict
            # Normalise to dict
            if isinstance(text, dict)
:
                extracted = text
            else:
                extracted = conv_extract_from_text(text or "")
if not isinstance(extracted, dict)
:
                raise ValueError("Extractor did not return a dict")
# Effective council
            effective_council = (council or extracted.get("council")
or "")
.strip()
# Conveyancing block safely
            conveyancing_block = extracted.get("conveyancing", {})
if isinstance(extracted, dict)
else {}
            # Risk
            risk = risk_engine(extracted, conveyancing_block)
# Persist
            with get_session()
as session:
                rec_id = insert_convey_search(
                    session,
                    filename=fname,
                    council=effective_council,
                    extracted=extracted,
                    risk=risk
                )
ids.append(rec_id)
# Auto-review rules
                try:
                    needs = False
                    llc1 = (conveyancing_block or {})
.get("llc1", {})
if isinstance(conveyancing_block, dict)
else {}
                    c29  = (conveyancing_block or {})
.get("con29", {})
if isinstance(conveyancing_block, dict)
else {}
                    if c29.get("road_status")
in (None, "")
or (c29.get("road_status_confidence")
== "low")
:
                        needs = True
                    if llc1.get("s106")
:
                    if llc1.get("tpo")
and llc1.get("conservation_area")
:
                    if needs:
                        set_review_flag(session, rec_id, True)
except Exception:
                    logging.exception("Auto-flagging failed for %s", fname)
# Warnings
            warnings = []
                addr = (extracted or {})
.get("property_address","")
if isinstance(extracted, dict)
else ""
                council_l = (effective_council or "")
.lower()
import re as _re
                m = _re.search(r'\b([A-Z]{1,2})
\d{1,2}[A-Z]?\s*\d[A-Z]{2}\b', addr, _re.I)
pc_area = (m.group(1)
.upper()
if m else "")
if pc_area and "hert" in council_l and pc_area not in ("AL","EN","SG","WD","HP")
:
                    warnings.append("Postcode area suggests non-Hertfordshire location.")
if not extracted or not isinstance(extracted, dict)
:
                    warnings.append("Extractor returned minimal fields; check PDF quality/OCR.")
logging.exception("Warning generation failed for %s", fname)
results.append({
                "id": rec_id,
                "filename": fname,
                "council": effective_council,
                "extracted": extracted,
                "conveyancing": conveyancing_block,
                "risk": risk,
                "warnings": warnings
        except Exception as e:
            logging.exception("Failed to process %s", fname)
errors.append({"filename": fname, "error": str(e)
})
resp = {
        "count": len(results)
,
        "records": results,
        "errors": errors,
        "csv_url": "/api/searches.csv",
        "pdf_pack_url": f"/api/report-pack?ids={','.join(map(str, ids)
}" if ids else ""
    }
    return JSONResponse(resp)
@app.get("/api/health")
def api_health()
:
@app.post("/api/echo")
async def api_echo(request: Request)
:
    form = await request.form()
return {"form_keys": list(form.keys()
}
@app.post("/api/aml/start")
def api_aml_start(name: str = Form(...)
, email: str = Form(...)
:
    return aml_start(name, email)
@app.get("/api/aml/status")
def api_aml_status(token: str)
:
    return aml_status(token)
@app.post("/api/bank/parse")
async def api_bank_parse(file: UploadFile = File(...)
:
    data = await file.read()
return parse_bank_csv(data)
@app.post("/api/notify")
def api_notify(to_email: str = Form("")
, subject: str = Form("Update")
, body: str = Form("")
, webhook_url: str = Form("")
:
    ok1 = (send_email_console(to_email, subject, body)
if to_email else True)
ok2 = (send_webhook(webhook_url, {"subject": subject, "body": body})
if webhook_url else True)
return {"email_sent": ok1, "webhook_ok": ok2}
@app.post("/api/contract/ta6.pdf")
async def api_ta6(address: str = Form("")
, seller: str = Form("")
, tenure: str = Form("")
,
                  lease_years: str = Form("")
, alterations: str = Form("")
, disputes: str = Form("")
,
                  notices: str = Form("")
, certs: str = Form("")
, flood: str = Form("")
:
    from pathlib import Path
    tmp = Path("ta6_summary.pdf")
build_ta6_pdf(str(tmp)
, locals()
return FileResponse(str(tmp)
, media_type="application/pdf", filename="TA6-summary.pdf")
@app.post("/api/risk/recalc/{rec_id}")
def api_risk_recalc(rec_id: int)
:
    from db import get_session, get_convey_search, add_note, list_notes, get_title_docs
        extracted = rec.extracted_json or {}
        base_risk = rec.risk_json or {}
        extra = checklist_from_extracted(extracted)
# add title-derived risks if linked
        docs = get_title_docs(session, rec_id)
for d in docs:
            t = d.extracted_json or {}
            er = from_title_blocks(t)
base_risk.setdefault("issues", [])
.extend(er.get("extra_risks", [])
if er.get("lease_years")
is not None:
                base_risk.setdefault("meta", {})
["lease_years"] = er["lease_years"]
        base_risk.setdefault("issues", [])
.extend(extra.get("checklist", [])
# keep score; don't change your existing risk bands
        rec.risk_json = base_risk
        session.commit()
return base_risk
@app.get("/api/completion/sdlt-draft/{rec_id}")
def api_sdlt_draft(rec_id: int)
:
    from db import get_session, get_convey_search, add_note, list_notes
        payload = {
            "id": rec.id,
            "filename": rec.filename,
            "extracted_json": rec.extracted_json or {},
            "risk_json": rec.risk_json or {}
        }
        return sdlt_draft(payload)
@app.post("/api/title-upload/{rec_id}")
async def api_title_upload(rec_id: int, kind: str = Form("register")
, file: UploadFile = File(...)
:
    # Reuse our PDF text util if available
    try:
        txt = pdf_to_text(data)
if not isinstance(txt, str)
: txt = str(txt or "")
except Exception:
        txt = data.decode("utf-8", errors="ignore")
parsed = parse_title_text(txt)
summary = summarise_title(parsed)
# ensure parent exists
            raise HTTPException(status_code=404, detail="Search record not found")
add_title_doc(session, rec_id, kind, {**parsed, "plain_text_len": len(txt)
})
return {"ok": True, "parsed": parsed, "summary": summary}
@app.post("/api/notes/{rec_id}")
def api_add_note(rec_id: int, author: str = Form("user")
, note: str = Form(...)
:
        if not get_convey_search(session, rec_id)
:
        nid = add_note(session, rec_id, author, note)
return {"id": nid}
@app.get("/api/notes/{rec_id}")
def api_list_notes(rec_id: int)
:
        rows = list_notes(session, rec_id)
return [{"id": n.id, "author": n.author, "note": n.note, "created_at": str(n.created_at)
} for n in rows]
@app.get("/api/export/pack/{rec_id}.zip")
def api_export_pack(rec_id: int)
:
    from db import get_session, get_convey_search
        rec = get_convey_search(session, rec_id)
if not rec: raise HTTPException(status_code=404, detail="Record not found")
payload = {"extracted_json": rec.extracted_json or {}, "risk_json": rec.risk_json or {}}
        blob = build_pack(payload)
return StreamingResponse(io.BytesIO(blob)
, media_type="application/zip", headers={"Content-Disposition":"attachment; filename=domus-pack.zip"})
@app.patch("/api/status/{rec_id}")
def api_set_status(rec_id: int, status: str = Form(...)
:
        # if you have a status column, set & commit; otherwise just notify
        send_email_console("", "Case status updated", f"Record {rec_id} set to status={status}")
return {"ok": True, "status": status}