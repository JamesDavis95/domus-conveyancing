#!/usr/bin/env python3
"""
Domus Planning Platform - Professional Planning Intelligence System
Complete AI-powered planning and development solution

Planning AI - Site analysis and approval probability prediction
Auto-Docs - Professional planning document generation  
Property API - Unified UK property data integration
Offsets Marketplace - Biodiversity Net Gain trading platform
"""

# Load environment variables first
from dotenv import load_dotenv
import os

# Gate environment file loading by ENVIRONMENT variable
if os.getenv("ENVIRONMENT", "development") != "production":
    # Try production environment first, then fallback to local
    if os.path.exists('.env.production'):
        load_dotenv('.env.production')
        print("Loaded .env.production environment")
    elif os.path.exists('.env.local'):
        load_dotenv('.env.local')
        print("Loaded .env.local environment")
    else:
        print("No environment file found, using system environment variables")
else:
    print("Production environment detected - using Render environment variables")

import time
import json
from typing import List, Optional
from fastapi import FastAPI, HTTPException, Depends, Request, Response
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from datetime import datetime, timedelta
from pathlib import Path
import random
from sqlalchemy.orm import Session
from pydantic import BaseModel

# Import our auth system
from auth_system import (
    get_current_user, require_permission, require_quota, 
    hash_password, verify_password, create_access_token,
    increment_usage, org_scoped_query
)
from models import Users, Orgs, Projects, UserRole, PlanType, UsageCounters, MarketplaceSupply, Contracts, ContractStatus, SourceFreshness, AnalysisSnapshots, SubmissionPacks

# Import security hardening
try:
    from security_hardening import (
        security_manager, two_factor_auth, rate_limiter, captcha_service, 
        csp_manager, log_redactor, require_2fa, rate_limit, require_captcha,
        log_security_event, SecurityMiddleware
    )
    SECURITY_ENABLED = True
except ImportError:
    print("Security hardening modules not available - running in development mode")
    SECURITY_ENABLED = False
    
    # Create dummy decorators for development
    def require_2fa(f): return f
    def rate_limit(limit_type='api'): return lambda f: f
    def require_captcha(f): return f

# Database dependency (placeholder - need to set up proper DB session)
def get_db():
    # TODO: Implement proper database session
    pass

# Pydantic models for requests
class LoginRequest(BaseModel):
    email: str
    password: str

class SignupRequest(BaseModel):
    email: str
    password: str
    org_name: str
    role: UserRole = UserRole.DEVELOPER

class ProjectCreateRequest(BaseModel):
    title: str
    address: str = None
    site_geometry: dict = None

# Stripe billing implementation
import stripe
import os
from typing import Optional

# Configure Stripe
stripe.api_key = os.getenv('STRIPE_SECRET_KEY')

class StripeService:
    @staticmethod
    async def create_checkout_session(org_id: int, plan: str, success_url: str, cancel_url: str, db: Session):
        """Create Stripe Checkout session with Bacs Direct Debit support"""
        try:
            # Get or create Stripe customer
            org = db.query(Orgs).filter(Orgs.id == org_id).first()
            customer_id = org.billing_customer_id
            
            if not customer_id:
                customer = stripe.Customer.create(
                    email=f"billing@org{org_id}.domus.com",
                    metadata={'org_id': org_id}
                )
                customer_id = customer.id
                org.billing_customer_id = customer_id
                db.commit()
            
            # Define price IDs for plans
            price_ids = {
                'PRO': os.getenv('STRIPE_PRICE_PRO'),
                'ENTERPRISE': os.getenv('STRIPE_PRICE_ENT')
            }
            
            if plan not in price_ids:
                raise ValueError(f"Invalid plan: {plan}")
            
            # Create checkout session with Bacs DD
            session = stripe.checkout.Session.create(
                customer=customer_id,
                payment_method_types=['card', 'bacs_debit'],
                line_items=[{
                    'price': price_ids[plan],
                    'quantity': 1,
                }],
                mode='subscription',
                success_url=success_url,
                cancel_url=cancel_url,
                metadata={'org_id': org_id, 'plan': plan},
                billing_address_collection='required',
                tax_id_collection={'enabled': True}  # VAT collection
            )
            
            return session.url
            
        except Exception as e:
            raise Exception(f"Failed to create checkout session: {str(e)}")
    
    @staticmethod
    async def get_billing_portal_url(org_id: int, return_url: str, db: Session):
        """Get Stripe billing portal URL"""
        try:
            org = db.query(Orgs).filter(Orgs.id == org_id).first()
            if not org.billing_customer_id:
                return None
                
            session = stripe.billing_portal.Session.create(
                customer=org.billing_customer_id,
                return_url=return_url
            )
            return session.url
        except Exception as e:
            raise Exception(f"Failed to create portal session: {str(e)}")
    
    @staticmethod
    async def get_invoices(org_id: int, db: Session):
        """Get invoices for organization"""
        try:
            org = db.query(Orgs).filter(Orgs.id == org_id).first()
            if not org.billing_customer_id:
                return []
                
            invoices = stripe.Invoice.list(
                customer=org.billing_customer_id,
                limit=10
            )
            
            return [{
                'id': inv.id,
                'amount': inv.amount_due / 100,  # Convert from cents
                'currency': inv.currency,
                'status': inv.status,
                'created': inv.created,
                'pdf_url': inv.invoice_pdf
            } for inv in invoices.data]
        except Exception as e:
            raise Exception(f"Failed to get invoices: {str(e)}")

class QuotaService:
    @staticmethod
    def get_plan_quotas(plan: str):
        """Get quota limits for plan"""
        quotas = {
            'DEMO': {
                'projects': 1,
                'docs_per_month': 5,
                'viability_runs': 2,
                'bng_runs': 2,
                'transport_runs': 1,
                'environment_runs': 1,
                'packs_created': 1,
                'api_calls_per_month': 100
            },
            'PRO': {
                'projects': 10,
                'docs_per_month': 50,
                'viability_runs': 20,
                'bng_runs': 20,
                'transport_runs': 15,
                'environment_runs': 15,
                'packs_created': 10,
                'api_calls_per_month': 1000
            },
            'ENTERPRISE': {
                'projects': 100,
                'docs_per_month': 500,
                'viability_runs': 200,
                'bng_runs': 200,
                'transport_runs': 150,
                'environment_runs': 150,
                'packs_created': 100,
                'api_calls_per_month': 10000
            }
        }
        return quotas.get(plan, quotas['DEMO'])
    
    @staticmethod
    async def check_quota(org_id: int, resource: str, db: Session):
        """Check if organization has quota for resource"""
        org = db.query(Orgs).filter(Orgs.id == org_id).first()
        plan_quotas = QuotaService.get_plan_quotas(org.plan.value)
        
        # Get current month usage
        from datetime import datetime
        current_month = datetime.now().strftime('%Y-%m')
        usage = db.query(UsageCounters).filter(
            UsageCounters.org_id == org_id,
            UsageCounters.month == current_month
        ).first()
        
        if not usage:
            # Create usage record for current month
            usage = UsageCounters(
                org_id=org_id,
                month=current_month,
                projects_used=0,
                docs_used=0,
                viability_runs=0,
                bng_runs=0,
                transport_runs=0,
                environment_runs=0,
                packs_created=0,
                api_calls_used=0
            )
            db.add(usage)
            db.commit()
        
        # Check specific resource quota
        current_usage = getattr(usage, resource, 0)
        quota_limit = plan_quotas.get(resource.replace('_used', '').replace('_', '_') + ('_per_month' if 'docs' in resource or 'api' in resource else ''), 0)
        
        return current_usage < quota_limit
    
    @staticmethod
    async def increment_usage(org_id: int, resource: str, db: Session):
        """Increment usage counter for resource"""
        from datetime import datetime
        current_month = datetime.now().strftime('%Y-%m')
        usage = db.query(UsageCounters).filter(
            UsageCounters.org_id == org_id,
            UsageCounters.month == current_month
        ).first()
        
        if usage:
            current_value = getattr(usage, resource, 0)
            setattr(usage, resource, current_value + 1)
            db.commit()
    
    @staticmethod
    async def reset_monthly_quotas(db: Session):
        """Reset monthly quotas for all organizations"""
        from datetime import datetime
        current_month = datetime.now().strftime('%Y-%m')
        
        # Reset counters for current month
        db.query(UsageCounters).filter(
            UsageCounters.month == current_month
        ).update({
            'docs_used': 0,
            'api_calls_used': 0
        })
        db.commit()

class VATService:
    @staticmethod
    def validate_vat_number(vat_number: str, country_code: str):
        """Validate VAT number format"""
        import re
        
        # Basic VAT validation patterns
        patterns = {
            'GB': r'^GB\d{9}$|^GB\d{12}$|^GBGD\d{3}$|^GBHA\d{3}$',
            'DE': r'^DE\d{9}$',
            'FR': r'^FR[A-Z0-9]{2}\d{9}$',
            'IE': r'^IE\d{7}[A-Z]{1,2}$|^IE\d[A-Z]\d{5}[A-Z]$'
        }
        
        pattern = patterns.get(country_code.upper())
        if not pattern:
            return False
            
        return bool(re.match(pattern, vat_number.upper()))

# Environment flags for optional features
PRODUCTION_AUTH_AVAILABLE = False

# Simple database initialization function
def init_database():
    # TODO: Implement proper database initialization
    pass

# Initialize database on startup
init_database()
def init_database():
    """Initialize database tables if they don't exist"""
    try:
        from models import Base, engine
        Base.metadata.create_all(bind=engine)
        print(" Database tables initialized")
    except Exception as e:
        print(f" Database initialization issue (non-critical): {e}")

# Initialize database on startup
init_database()


# Initialize the Domus Planning Platform
app = FastAPI(
    title="Domus Planning Platform - AI Operating System", 
    description="The 4-Pillar AI Planning System: Planning AI + Auto-Docs + Property API + Offsets Marketplace",
    version="4.0.0",
    contact={
        "name": "Domus Platform",
        "email": "hello@domusplanning.co.uk",
        "url": "https://domusplanning.co.uk"
    }
)

# Startup logging for production monitoring
current_env = os.getenv("ENVIRONMENT", "development")
try:
    import subprocess
    git_sha = subprocess.run(['git', 'rev-parse', 'HEAD'], 
                           capture_output=True, text=True, cwd=os.path.dirname(__file__))
    version_info = git_sha.stdout.strip()[:8] if git_sha.returncode == 0 else "unknown"
except:
    version_info = "unknown"

env_vars_present = [k for k in os.environ.keys() if k.startswith(('STRIPE_', 'OPENAI_', 'SENDGRID_', 'EPC_', 'CH_', 'OS_', 'RECAPTCHA_', 'MAPBOX_'))]
print(f"ðŸš€ DOMUS STARTUP: Environment={current_env}, Version={version_info}, EnvVars={len(env_vars_present)} configured")

# Setup Jinja2 templates
templates = Jinja2Templates(directory="templates")

# Simple CORS for development
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["*"]
)

# Security middleware and headers
if SECURITY_ENABLED:
    @app.middleware("http")
    async def security_middleware(request: Request, call_next):
        # Rate limiting check
        identifier = request.client.host
        
        # Extract limit type from path
        limit_type = 'api'
        if '/auth/' in str(request.url):
            limit_type = 'auth'
        elif '/upload' in str(request.url):
            limit_type = 'upload'
        
        rate_result = rate_limiter.is_allowed(identifier, limit_type)
        
        if not rate_result['allowed']:
            return JSONResponse(
                status_code=429,
                content={
                    'error': 'Rate limit exceeded',
                    'retry_after': rate_result['retry_after']
                },
                headers={
                    'Retry-After': str(rate_result['retry_after']),
                    'X-RateLimit-Remaining': '0'
                }
            )
        
        # Process request
        response = await call_next(request)
        
        # Add security headers
        response.headers['X-Content-Type-Options'] = 'nosniff'
        response.headers['X-Frame-Options'] = 'DENY'
        response.headers['X-XSS-Protection'] = '1; mode=block'
        response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains'
        response.headers['Content-Security-Policy'] = csp_manager.generate_csp_header()
        response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'
        response.headers['Permissions-Policy'] = 'geolocation=(), microphone=(), camera=()'
        
        # Add rate limit headers
        response.headers['X-RateLimit-Remaining'] = str(rate_result['remaining'])
        if 'reset_time' in rate_result:
            response.headers['X-RateLimit-Reset'] = str(rate_result['reset_time'])
        
        return response
    
    # CSP violation reporting endpoint
    @app.post("/api/security/csp-report")
    async def csp_report(request: Request):
        try:
            violation_data = await request.json()
            log_security_event('csp_violation', {
                'violation': violation_data,
                'ip': request.client.host,
                'user_agent': request.headers.get('user-agent')
            })
            return {'status': 'reported'}
        except:
            return {'status': 'error'}

# Load core platform modules
print("Loading Domus Professional Platform...")

try:
    print("   Auto-Docs module: In-app implementation")
except ImportError as e:
    print(f"   Auto-Docs not available: {e}")

try:
    from planning_ai.router import router as planning_ai_router
    app.include_router(planning_ai_router, prefix="/api")
    print("   Planning AI module loaded")
except ImportError as e:
    print(f"   Planning AI not available: {e}")

try:
    from integrations.stripe_integration import router as stripe_router
    app.include_router(stripe_router)
    print("   Stripe Billing module loaded")
except ImportError as e:
    print(f"   Stripe Billing not available: {e}")

try:
    from integrations.openai_integration import router as openai_router
    app.include_router(openai_router)
    print("   OpenAI Planning AI module loaded")
except ImportError as e:
    print(f"   OpenAI Planning AI not available: {e}")

try:
    from integrations.email_service import router as email_router
    app.include_router(email_router)
    print("   Email Service module loaded")
except ImportError as e:
    print(f"   Email Service not available: {e}")

try:
    from integrations.epc_integration import router as epc_router
    app.include_router(epc_router)
    print("   EPC Energy Certificates module loaded")
except ImportError as e:
    print(f"   EPC Energy Certificates not available: {e}")

try:
    from property_api.router import router as property_api_router
    app.include_router(property_api_router)
    print("   Property API module loaded")
except ImportError as e:
    print(f"   Property API not available: {e}")

try:
    from offsets_marketplace.router import router as offsets_router
    app.include_router(offsets_router)
    print("   Offsets Marketplace module loaded")
except ImportError as e:
    print(f"   Offsets Marketplace not available: {e}")

# try:
#     from api.billing import router as billing_router
#     app.include_router(billing_router)
#     print("   Live Billing API module loaded")
# except ImportError as e:
#     print(f"   Live Billing API not available: {e}")

# try:
#     from api.marketplace_connect import router as marketplace_connect_router
#     app.include_router(marketplace_connect_router)
#     print("   Marketplace Connect API module loaded")
# except ImportError as e:
#     print(f"   Marketplace Connect API not available: {e}")

try:
    from api.background_jobs import router as background_jobs_router
    app.include_router(background_jobs_router)
    print("   Background Jobs API module loaded")
except ImportError as e:
    print(f"   Background Jobs API not available: {e}")

try:
    from api.explainability import router as explainability_router
    app.include_router(explainability_router)
    print("   AI Explainability API module loaded")
except ImportError as e:
    print(f"   AI Explainability API not available: {e}")

try:
    from api.submission_packs import router as submission_packs_router
    app.include_router(submission_packs_router)
    print("   Submission Packs API module loaded")
except ImportError as e:
    print(f"   Submission Packs API not available: {e}")

try:
    from integrations.companies_house_integration import router as companies_house_router
    app.include_router(companies_house_router)
    print("   Companies House API module loaded")
except ImportError as e:
    print(f"   Companies House API not available: {e}")

try:
    from integrations.recaptcha_integration import router as recaptcha_router
    app.include_router(recaptcha_router)
    print("   reCAPTCHA v3 Protection module loaded")
except ImportError as e:
    print(f"   reCAPTCHA v3 Protection not available: {e}")

try:
    from integrations.public_data_integration import router as public_data_router
    app.include_router(public_data_router)
    print("   Public Data Sources (EA/PlanIt/PDG) module loaded")
except ImportError as e:
    print(f"   Public Data Sources not available: {e}")

try:
    from health import router as health_router
    app.include_router(health_router)
    print("   Health monitoring module loaded")
except ImportError as e:
    print(f"   Health monitoring not available: {e}")

# Quota enforcement middleware
async def enforce_quota_middleware(request: Request, call_next):
    """Enforce quota limits on resource-intensive endpoints"""
    
    # Define quota-sensitive endpoints
    quota_endpoints = {
        '/api/planning-ai/analyze': 'api_calls_used',
        '/api/auto-docs/generate': 'docs_used',
        '/api/viability/run': 'viability_runs',
        '/api/bng/calculate': 'bng_runs',
        '/api/transport/assess': 'transport_runs',
        '/api/environment/assess': 'environment_runs',
        '/api/submission-pack/create': 'packs_created',
        '/api/projects': 'projects_used'
    }
    
    # Check if this endpoint requires quota checking
    path = str(request.url.path)
    quota_resource = None
    
    for endpoint, resource in quota_endpoints.items():
        if path.startswith(endpoint):
            quota_resource = resource
            break
    
    if quota_resource and request.method in ['POST', 'PUT']:
        try:
            # Get user from token
            auth_header = request.headers.get('Authorization')
            if auth_header and auth_header.startswith('Bearer '):
                token = auth_header.split(' ')[1]
                from auth_system import decode_access_token
                user_data = decode_access_token(token)
                
                if user_data:
                    from database_config import get_db
                    db = next(get_db())
                    
                    # Check quota
                    has_quota = await QuotaService.check_quota(
                        org_id=user_data["org_id"],
                        resource=quota_resource,
                        db=db
                    )
                    
                    if not has_quota:
                        return JSONResponse(
                            status_code=403,
                            content={
                                "detail": f"Quota exceeded for {quota_resource}",
                                "upgrade_required": True,
                                "resource": quota_resource
                            }
                        )
        except Exception as e:
            # Log error but don't block request
            print(f"Quota check error: {e}")
    
    return await call_next(request)

print("   Authentication and billing systems loaded")
app.middleware("http")(enforce_quota_middleware)

print("\nDomus Professional Platform Ready")

# =====================================
# AUTHENTICATION ENDPOINTS
# =====================================

@app.post("/api/auth/signup")
async def signup(request: SignupRequest, db: Session = Depends(get_db)):
    """Create new user account"""
    try:
        # For now, return mock response until DB is properly connected
        return {
            "token": "mock_token_" + request.email,
            "user": {
                "id": 1,
                "email": request.email,
                "role": request.role.value,
                "org_id": 1,
                "plan": "core"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/api/auth/login")
async def login(request: LoginRequest, db: Session = Depends(get_db)):
    """User login"""
    try:
        # For now, return mock response until DB is properly connected
        return {
            "token": "mock_token_" + request.email,
            "user": {
                "id": 1,
                "email": request.email,
                "role": "super_admin",
                "org_id": 1,
                "plan": "enterprise"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/session")
async def get_session():
    """Get current user session info"""
    try:
        # For now, return mock super admin session
        return {
            "user": {
                "id": 1,
                "email": "admin@domusplanning.co.uk",
                "role": "super_admin",
                "org_id": 1,
                "plan": "enterprise"
            },
            "org": {
                "id": 1,
                "name": "Domus Planning",
                "plan": "enterprise"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/usage")
async def get_usage():
    """Get current usage information for the organization"""
    try:
        # Return mock usage data
        return {
            "org_id": 1,
            "org_name": "Domus Planning",
            "plan": "enterprise",
            "quotas": {
                "projects": {
                    "current": 3,
                    "limit": -1,
                    "unlimited": True,
                    "percentage": 0,
                    "available": -1
                },
                "docs": {
                    "current": 15,
                    "limit": -1,
                    "unlimited": True,
                    "percentage": 0,
                    "available": -1
                },
                "marketplace_posts": {
                    "current": 2,
                    "limit": -1,
                    "unlimited": True,
                    "percentage": 0,
                    "available": -1
                },
                "contracts": {
                    "current": 1,
                    "limit": -1,
                    "unlimited": True,
                    "percentage": 0,
                    "available": -1
                }
            },
            "period": "monthly"
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

# =====================================
# COOKIE CONSENT & COMPLIANCE ENDPOINTS
# =====================================

@app.post("/api/consent/record")
async def record_consent(request: Request):
    """Record user cookie consent for compliance"""
    try:
        body = await request.json()
        consent_data = body.get("consent", {})
        
        # In production, save to database with user/session association
        # For now, just log the consent record
        
        # Simulate saving consent record
        consent_record = {
            "timestamp": datetime.now().isoformat(),
            "ip_address": request.client.host,
            "user_agent": request.headers.get("user-agent"),
            "consent_version": consent_data.get("version", "1.0"),
            "categories": consent_data.get("categories", {}),
            "has_consented": consent_data.get("hasConsented", False)
        }
        
        # TODO: Save to database
        # consent_service.save_consent_record(consent_record)
        
        return {"success": True, "message": "Consent recorded"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to record consent: {str(e)}")

@app.post("/api/consent/update")
async def update_consent(request: Request):
    """Update user cookie consent preferences"""
    try:
        body = await request.json()
        consent_data = body.get("consent", {})
        
        # In production, update user's consent preferences in database
        # For now, just acknowledge the update
        
        update_record = {
            "timestamp": datetime.now().isoformat(),
            "ip_address": request.client.host,
            "user_agent": body.get("userAgent"),
            "consent_data": consent_data
        }
        
        # TODO: Update database record
        # consent_service.update_consent_preferences(update_record)
        
        return {"success": True, "message": "Consent preferences updated"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to update consent: {str(e)}")

@app.get("/api/consent/status")
async def get_consent_status(request: Request):
    """Get current consent status for user"""
    try:
        # In production, retrieve from database based on user session
        # For now, return default status
        
        return {
            "hasConsented": False,
            "timestamp": None,
            "version": "1.0",
            "categories": {
                "necessary": True,
                "analytics": False,
                "marketing": False,
                "preferences": False
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get consent status: {str(e)}")

# =====================================
# DASHBOARD ENDPOINTS
# =====================================

@app.get("/api/dashboard/overview")
async def get_dashboard_overview():
    """Get dashboard overview data tailored to user role"""
    try:
        # Return role-specific dashboard data
        return {
            "metrics": {
                "total_projects": 8,
                "active_projects": 5,
                "completed_projects": 3,
                "approval_rate": 84.2,
                "time_saved": 45.5,  # hours
                "cost_saved": 12500  # pounds
            },
            "recent_activity": [
                {
                    "id": 1,
                    "type": "project_created",
                    "title": "New project created",
                    "description": "Riverside Development - Planning application started",
                    "timestamp": "2024-10-02T09:30:00",
                    "icon": "ðŸ“"
                },
                {
                    "id": 2,
                    "type": "analysis_completed",
                    "title": "Planning analysis completed",
                    "description": "Green Belt Site - 78% approval probability",
                    "timestamp": "2024-10-02T08:15:00", 
                    "icon": "ðŸ§ "
                },
                {
                    "id": 3,
                    "type": "document_generated",
                    "title": "Documents generated",
                    "description": "Planning Statement and DAS for Manor House",
                    "timestamp": "2024-10-01T16:45:00",
                    "icon": ""
                }
            ],
            "quick_actions": [
                {
                    "title": "New Project",
                    "description": "Start a new planning project",
                    "route": "/projects/new",
                    "icon": "âž•",
                    "color": "primary"
                },
                {
                    "title": "Run Analysis",
                    "description": "Analyze a site with Planning AI",
                    "route": "/planning-ai",
                    "icon": "",
                    "color": "secondary"
                },
                {
                    "title": "Generate Docs",
                    "description": "Create planning documents",
                    "route": "/auto-docs",
                    "icon": "",
                    "color": "secondary"
                },
                {
                    "title": "Property Data",
                    "description": "UK property intelligence & analytics",
                    "route": "/property-api",
                    "icon": "",
                    "color": "secondary"
                },
                {
                    "title": "BNG Marketplace",
                    "description": "Biodiversity Net Gain trading platform",
                    "route": "/offsets-marketplace",
                    "icon": "",
                    "color": "secondary"
                }
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/dashboard/recent-projects")
async def get_recent_projects():
    """Get recent projects for dashboard"""
    try:
        return [
            {
                "id": 1,
                "title": "Riverside Development",
                "address": "123 River Street, London",
                "status": "active",
                "ai_score": 78.5,
                "last_updated": "2024-10-02T09:30:00",
                "stage": "Planning Analysis"
            },
            {
                "id": 2,
                "title": "Green Belt Site",
                "address": "45 Countryside Lane, Surrey",
                "status": "pending",
                "ai_score": 65.2,
                "last_updated": "2024-10-01T14:20:00",
                "stage": "Document Generation"
            },
            {
                "id": 3,
                "title": "Manor House Extension",
                "address": "78 Historic Avenue, Bath",
                "status": "approved",
                "ai_score": 89.1,
                "last_updated": "2024-09-28T11:15:00",
                "stage": "Completed"
            }
        ]
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/dashboard/notifications")
async def get_notifications():
    """Get user notifications for dashboard"""
    try:
        return [
            {
                "id": 1,
                "type": "success",
                "title": "Analysis Complete",
                "message": "Planning analysis for Riverside Development is ready",
                "timestamp": "2024-10-02T09:30:00",
                "read": False
            },
            {
                "id": 2,
                "type": "info",
                "title": "Document Ready",
                "message": "Planning Statement generated for Green Belt Site",
                "timestamp": "2024-10-01T16:45:00",
                "read": False
            },
            {
                "id": 3,
                "type": "warning",
                "title": "Quota Alert",
                "message": "You've used 8/10 projects this month",
                "timestamp": "2024-10-01T10:00:00",
                "read": True
            }
        ]
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/dashboard/marketplace-summary")
async def get_marketplace_summary():
    """Get marketplace summary for landowner dashboard"""
    try:
        return {
            "listings": {
                "active": 3,
                "pending": 1,
                "sold": 2
            },
            "earnings": {
                "total": 45000,
                "this_month": 12000,
                "pending": 8000
            },
            "recent_activity": [
                {
                    "id": 1,
                    "type": "sale_completed",
                    "title": "Unit sale completed",
                    "description": "5.2 biodiversity units sold for Â£15,000",
                    "timestamp": "2024-10-01T14:30:00"
                },
                {
                    "id": 2,
                    "type": "new_interest",
                    "title": "New buyer interest",
                    "description": "Inquiry for woodland habitat units",
                    "timestamp": "2024-09-30T11:20:00"
                }
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

# =====================================
# PROJECTS ENDPOINTS
# =====================================

@app.get("/api/projects")
async def get_projects():
    """Get organization's projects"""
    try:
        # Return enhanced mock projects data
        return [
            {
                "id": 1,
                "name": "Riverside Development",
                "description": "Mixed-use development with 50 residential units and commercial space",
                "address": "123 River Street, London SW1A 1AA",
                "postcode": "SW1A 1AA",
                "council": "Westminster City Council",
                "type": "mixed",
                "status": "planning",
                "units": 50,
                "area": 2500,
                "value": 15000000,
                "ai_score": 78,
                "progress": 45,
                "created_at": datetime.now() - timedelta(days=15),
                "updated_at": datetime.now() - timedelta(days=2),
                "owner_name": "Thames Development Ltd",
                "latitude": 51.5074,
                "longitude": -0.1278
            },
            {
                "id": 2,
                "name": "Green Valley Homes",
                "description": "Sustainable housing development with 25 eco-friendly homes",
                "address": "456 Valley Road, Manchester M1 2AB",
                "postcode": "M1 2AB",
                "council": "Manchester City Council",
                "type": "residential",
                "status": "submitted",
                "units": 25,
                "area": 1800,
                "value": 8500000,
                "ai_score": 85,
                "progress": 70,
                "created_at": datetime.now() - timedelta(days=8),
                "updated_at": datetime.now() - timedelta(days=1),
                "owner_name": "Eco Homes Ltd",
                "latitude": 53.4808,
                "longitude": -2.2426
            },
            {
                "id": 3,
                "name": "City Centre Plaza",
                "description": "Commercial development with retail and office spaces",
                "address": "789 High Street, Birmingham B1 3CD",
                "postcode": "B1 3CD",
                "council": "Birmingham City Council",
                "type": "commercial",
                "status": "approved",
                "units": 0,
                "area": 3200,
                "value": 22000000,
                "ai_score": 92,
                "progress": 100,
                "created_at": datetime.now() - timedelta(days=30),
                "updated_at": datetime.now() - timedelta(days=5),
                "owner_name": "Urban Developments",
                "latitude": 52.4862,
                "longitude": -1.8904
            }
        ]
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

class ProjectCreateData(BaseModel):
    name: str
    description: str = ""
    address: str
    postcode: str = ""
    council: str = ""
    type: str
    units: int = 0
    area: float = 0
    value: float = 0
    planning_status: str = "planning"
    application_ref: str = ""
    target_date: str = ""

@app.post("/api/projects")
async def create_project(project_data: ProjectCreateData):
    """Create new project"""
    try:
        # Generate mock ID and timestamps
        new_id = random.randint(100, 999)
        now = datetime.now()
        
        # Calculate AI score based on project characteristics
        base_score = 60
        score_adjustments = 0
        
        # Type-based scoring
        if project_data.type == "residential":
            score_adjustments += 10
        elif project_data.type == "affordable_housing":
            score_adjustments += 15
        elif project_data.type == "commercial":
            score_adjustments += 5
        
        # Size-based scoring
        if project_data.units > 0 and project_data.units <= 50:
            score_adjustments += 8
        
        # Area-based scoring
        if project_data.area > 0 and project_data.area < 5000:
            score_adjustments += 5
        
        ai_score = min(100, max(20, base_score + score_adjustments + random.randint(-10, 15)))
        
        new_project = {
            "id": new_id,
            "name": project_data.name,
            "description": project_data.description,
            "address": project_data.address,
            "postcode": project_data.postcode,
            "council": project_data.council,
            "type": project_data.type,
            "status": project_data.planning_status,
            "units": project_data.units,
            "area": project_data.area,
            "value": project_data.value,
            "ai_score": ai_score,
            "progress": 5,  # New project starts at 5%
            "created_at": now,
            "updated_at": now,
            "application_ref": project_data.application_ref,
            "target_date": project_data.target_date,
            "latitude": 51.5074 + random.uniform(-0.1, 0.1),  # Mock coordinates
            "longitude": -0.1278 + random.uniform(-0.1, 0.1)
        }
        
        return new_project
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/projects/{project_id}")
async def get_project(project_id: int):
    """Get specific project details"""
    try:
        # Return comprehensive mock project details
        project = {
            "id": project_id,
            "name": "Riverside Development",
            "description": "Mixed-use development with 50 residential units and commercial space",
            "address": "123 River Street, London SW1A 1AA",
            "postcode": "SW1A 1AA",
            "council": "Westminster City Council",
            "type": "mixed",
            "status": "planning",
            "units": 50,
            "area": 2500,
            "value": 15000000,
            "ai_score": 78,
            "progress": 45,
            "created_at": datetime.now() - timedelta(days=15),
            "updated_at": datetime.now() - timedelta(days=2),
            "latitude": 51.5074,
            "longitude": -0.1278,
            "application_ref": "23/01234/FUL",
            "target_date": "2024-12-15",
            "constraints": [
                "Conservation Area nearby",
                "Flood Risk Zone 2",
                "Tree Preservation Orders"
            ],
            "ai_reasoning": "Strong fundamentals with good local support but moderate constraints require careful design",
            "documents": [
                {
                    "id": 1,
                    "name": "Site Survey Report.pdf",
                    "size": "2.4 MB",
                    "uploaded_at": datetime.now() - timedelta(days=5),
                    "type": "survey"
                },
                {
                    "id": 2,
                    "name": "Planning Statement.pdf",
                    "size": "1.8 MB", 
                    "uploaded_at": datetime.now() - timedelta(days=3),
                    "type": "planning"
                }
            ],
            "timeline": [
                {
                    "title": "Project Created",
                    "date": datetime.now() - timedelta(days=15),
                    "description": "Initial project setup completed"
                },
                {
                    "title": "Site Survey",
                    "date": datetime.now() - timedelta(days=10),
                    "description": "Comprehensive site survey conducted"
                },
                {
                    "title": "AI Analysis",
                    "date": datetime.now() - timedelta(days=5),
                    "description": "Planning AI analysis completed with 78% approval score"
                }
            ],
            "ai_analyses": ["Initial assessment", "Constraint analysis"]
        }
        
        return project
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.put("/api/projects/{project_id}")
async def update_project(project_id: int, project_data: ProjectCreateData):
    """Update existing project"""
    try:
        # Return updated project data
        updated_project = {
            "id": project_id,
            "name": project_data.name,
            "description": project_data.description,
            "address": project_data.address,
            "postcode": project_data.postcode,
            "council": project_data.council,
            "type": project_data.type,
            "status": project_data.planning_status,
            "units": project_data.units,
            "area": project_data.area,
            "value": project_data.value,
            "updated_at": datetime.now(),
            "application_ref": project_data.application_ref,
            "target_date": project_data.target_date
        }
        
        return updated_project
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.delete("/api/projects/{project_id}")
async def delete_project(project_id: int):
    """Delete project"""
    try:
        return {"message": "Project deleted successfully", "id": project_id}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))
print("   Professional planning intelligence and compliance automation")

# Serve the clean frontend
app.mount("/static", StaticFiles(directory="static"), name="static")
app.mount("/frontend", StaticFiles(directory="frontend"), name="frontend")

@app.get("/", response_class=HTMLResponse)
async def root(request: Request):
    """Serve the main application shell"""
    return templates.TemplateResponse("app_shell.html", {"request": request})

# All authenticated app routes serve the same app shell except projects, planning-ai, auto-docs, property-api, offsets-marketplace, and marketplace/supply which have dedicated templates
@app.get("/dashboard", response_class=HTMLResponse)
@app.get("/documents", response_class=HTMLResponse)
@app.get("/marketplace/demand", response_class=HTMLResponse)
@app.get("/contracts", response_class=HTMLResponse)
@app.get("/analytics", response_class=HTMLResponse)
@app.get("/settings", response_class=HTMLResponse)
@app.get("/settings/billing", response_class=HTMLResponse)
@app.get("/settings/api-keys", response_class=HTMLResponse)
@app.get("/admin", response_class=HTMLResponse)
async def app_routes(request: Request):
    """Serve the app shell for all authenticated routes"""
    return templates.TemplateResponse("app_shell.html", {"request": request})

# Marketplace supply template route
@app.get("/marketplace/supply", response_class=HTMLResponse)
async def marketplace_supply_page(request: Request):
    """Serve the marketplace supply page with Connect payouts"""
    return templates.TemplateResponse("marketplace_supply.html", {"request": request})

# Projects-specific template routes
@app.get("/projects", response_class=HTMLResponse)
async def projects_page(request: Request):
    """Serve the projects listing page"""
    # Mock projects data
    projects = [
        {
            "id": 1,
            "name": "Riverside Development",
            "description": "Mixed-use development with 50 residential units and commercial space",
            "address": "123 River Street, London SW1A 1AA",
            "status": "planning",
            "ai_score": 78,
            "progress": 45,
            "created_at": datetime.now() - timedelta(days=15),
            "owner_name": "Thames Development Ltd"
        },
        {
            "id": 2,
            "name": "Green Valley Homes",
            "description": "Sustainable housing development with 25 eco-friendly homes",
            "address": "456 Valley Road, Manchester M1 2AB",
            "status": "submitted",
            "ai_score": 85,
            "progress": 70,
            "created_at": datetime.now() - timedelta(days=8),
            "owner_name": "Eco Homes Ltd"
        },
        {
            "id": 3,
            "name": "City Centre Plaza",
            "description": "Commercial development with retail and office spaces",
            "address": "789 High Street, Birmingham B1 3CD",
            "status": "approved",
            "ai_score": 92,
            "progress": 100,
            "created_at": datetime.now() - timedelta(days=30),
            "owner_name": "Urban Developments"
        }
    ]
    return templates.TemplateResponse("projects.html", {"request": request, "projects": projects})

@app.get("/projects/new", response_class=HTMLResponse)
async def new_project_page(request: Request):
    """Serve the new project creation page"""
    return templates.TemplateResponse("projects_new.html", {"request": request})

@app.get("/projects/{project_id}", response_class=HTMLResponse)
async def project_detail_page(request: Request, project_id: int):
    """Serve the project detail page"""
    # Mock project data
    project = {
        "id": project_id,
        "name": "Riverside Development",
        "description": "Mixed-use development with 50 residential units and commercial space",
        "address": "123 River Street, London SW1A 1AA",
        "postcode": "SW1A 1AA",
        "council": "Westminster City Council",
        "type": "mixed",
        "status": "planning",
        "units": 50,
        "area": 2500,
        "value": 15000000,
        "ai_score": 78,
        "progress": 45,
        "created_at": datetime.now() - timedelta(days=15),
        "latitude": 51.5074,
        "longitude": -0.1278,
        "constraints": [
            "Conservation Area nearby",
            "Flood Risk Zone 2",
            "Tree Preservation Orders"
        ],
        "ai_reasoning": "Strong fundamentals with good local support but moderate constraints require careful design",
        "documents": [
            {
                "name": "Site Survey Report.pdf",
                "size": "2.4 MB",
                "uploaded_at": datetime.now() - timedelta(days=5)
            },
            {
                "name": "Planning Statement.pdf", 
                "size": "1.8 MB",
                "uploaded_at": datetime.now() - timedelta(days=3)
            }
        ],
        "timeline": [
            {
                "title": "Project Created",
                "date": datetime.now() - timedelta(days=15),
                "description": "Initial project setup completed"
            },
            {
                "title": "Site Survey",
                "date": datetime.now() - timedelta(days=10),
                "description": "Comprehensive site survey conducted"
            },
            {
                "title": "AI Analysis",
                "date": datetime.now() - timedelta(days=5),
                "description": "Planning AI analysis completed with 78% approval score"
            }
        ],
        "ai_analyses": ["Initial assessment", "Constraint analysis"]
    }
    return templates.TemplateResponse("projects_detail.html", {"request": request, "project": project, "now": datetime.now})

# Planning AI template route
@app.get("/planning-ai", response_class=HTMLResponse)
async def planning_ai_page(request: Request):
    """Serve the Planning AI analysis page"""
    return templates.TemplateResponse("planning_ai.html", {"request": request})

# Auto-Docs template route
@app.get("/auto-docs", response_class=HTMLResponse)
async def auto_docs_page(request: Request):
    """Serve the Auto-Docs generator page"""
    return templates.TemplateResponse("auto_docs.html", {"request": request})

# Property API template route
@app.get("/property-api", response_class=HTMLResponse)
async def property_api_page(request: Request):
    """Serve the Property API intelligence page"""
    return templates.TemplateResponse("property_api.html", {"request": request})

# Offsets Marketplace template route
@app.get("/offsets-marketplace", response_class=HTMLResponse)
async def offsets_marketplace_page(request: Request):
    """Serve the Biodiversity Net Gain marketplace page"""
    return templates.TemplateResponse("offsets_marketplace.html", {"request": request})

# =====================================
# LEGAL & COMPLIANCE DOCUMENT ROUTES
# =====================================

@app.get("/privacy-policy", response_class=HTMLResponse)
async def privacy_policy_page(request: Request):
    """Serve the privacy policy page"""
    return templates.TemplateResponse("privacy_policy.html", {"request": request})

@app.get("/terms-of-service", response_class=HTMLResponse)
async def terms_of_service_page(request: Request):
    """Serve the terms of service page"""
    return templates.TemplateResponse("terms_of_service.html", {"request": request})

@app.get("/cookie-policy", response_class=HTMLResponse)
async def cookie_policy_page(request: Request):
    """Serve the cookie policy page"""
    return templates.TemplateResponse("cookie_policy.html", {"request": request})

@app.get("/marketplace/terms", response_class=HTMLResponse)
async def marketplace_terms_page(request: Request):
    """Serve the marketplace terms and conditions page"""
    return templates.TemplateResponse("marketplace_terms.html", {"request": request})

# =====================================
# NEW ENTERPRISE MODULE ROUTES
# =====================================

# Viability Assessment page
@app.get("/projects/{project_id}/viability", response_class=HTMLResponse)
async def project_viability_page(request: Request, project_id: int):
    """Serve the project viability assessment page"""
    return templates.TemplateResponse("viability_assessment.html", {"request": request, "project_id": project_id})

# BNG (Biodiversity Net Gain) page
@app.get("/projects/{project_id}/bng", response_class=HTMLResponse)
async def project_bng_page(request: Request, project_id: int):
    """Serve the project BNG assessment page"""
    return templates.TemplateResponse("bng_assessment.html", {"request": request, "project_id": project_id})

# Transport & Highways page
@app.get("/projects/{project_id}/transport", response_class=HTMLResponse)
async def project_transport_page(request: Request, project_id: int):
    """Serve the project transport assessment page"""
    return templates.TemplateResponse("transport_assessment.html", {"request": request, "project_id": project_id})

# Environment & Climate page
@app.get("/projects/{project_id}/environment", response_class=HTMLResponse)
async def project_environment_page(request: Request, project_id: int):
    """Serve the project environment assessment page"""
    return templates.TemplateResponse("environment_assessment.html", {"request": request, "project_id": project_id})

# Appeals Intelligence page
@app.get("/projects/{project_id}/appeals", response_class=HTMLResponse)
async def project_appeals_page(request: Request, project_id: int):
    """Serve the project appeals intelligence page"""
    return templates.TemplateResponse("appeals_intelligence.html", {"request": request, "project_id": project_id})

# Collaboration page
@app.get("/projects/{project_id}/collaboration", response_class=HTMLResponse)
async def project_collaboration_page(request: Request, project_id: int):
    """Serve the project collaboration page"""
    return templates.TemplateResponse("collaboration.html", {"request": request, "project_id": project_id})

# Submission Pack page
@app.get("/submission-pack", response_class=HTMLResponse)
async def submission_pack_page(request: Request):
    """Serve the submission pack management page"""
    return templates.TemplateResponse("submission_pack.html", {"request": request})

# Billing & Subscription page
@app.get("/billing", response_class=HTMLResponse)
async def billing_page(request: Request):
    """Serve the billing and subscription management page"""
    try:
        # Get Stripe config for frontend
        stripe_publishable_key = os.getenv('STRIPE_PUBLISHABLE_KEY', '')
        
        return templates.TemplateResponse("billing.html", {
            "request": request,
            "stripe_publishable_key": stripe_publishable_key
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load billing page: {str(e)}")

# Analytics LPA page
@app.get("/analytics/lpa", response_class=HTMLResponse)
async def analytics_lpa_page(request: Request):
    """Serve the LPA performance analytics page"""
    return templates.TemplateResponse("analytics_lpa.html", {"request": request})

# Analytics Org Insights page
@app.get("/analytics/org-insights", response_class=HTMLResponse)
async def analytics_org_insights_page(request: Request):
    """Serve the organization insights page"""
    return templates.TemplateResponse("analytics_org_insights.html", {"request": request})

# Settings - Viability Presets page
@app.get("/settings/viability-presets", response_class=HTMLResponse)
async def settings_viability_presets_page(request: Request):
    """Serve the viability presets management page"""
    return templates.TemplateResponse("settings_viability_presets.html", {"request": request})

# Authority Portal page
@app.get("/authority/{token}", response_class=HTMLResponse)
async def authority_portal_page(request: Request, token: str):
    """Serve the authority portal page for external authority access"""
    return templates.TemplateResponse("authority_portal.html", {"request": request, "token": token})

# Route aliases for navigation consistency
@app.get("/viability")
async def viability_redirect():
    """Redirect to first project viability (for demo navigation)"""
    return JSONResponse({"redirect": "/projects/1/viability"})

@app.get("/bng")
async def bng_redirect():
    """Redirect to first project BNG (for demo navigation)"""
    return JSONResponse({"redirect": "/projects/1/bng"})

@app.get("/transport")
async def transport_redirect():
    """Redirect to first project transport (for demo navigation)"""
    return JSONResponse({"redirect": "/projects/1/transport"})

@app.get("/environment")
async def environment_redirect():
    """Redirect to first project environment (for demo navigation)"""
    return JSONResponse({"redirect": "/projects/1/environment"})

@app.get("/appeals")
async def appeals_redirect():
    """Redirect to first project appeals (for demo navigation)"""
    return JSONResponse({"redirect": "/projects/1/appeals"})

@app.get("/collaboration")
async def collaboration_redirect():
    """Redirect to first project collaboration (for demo navigation)"""
    return JSONResponse({"redirect": "/projects/1/collaboration"})

@app.get("/login", response_class=HTMLResponse)
async def login_page():
    """Serve the login page"""
    try:
        with open('frontend/login.html', 'r', encoding='utf-8') as f:
            return f.read()
    except Exception as e:
        return f"<html><body><h1>Login Unavailable</h1><p>Please try again later.</p></body></html>"

@app.get("/debug-html")
async def debug_html():
    """Debug endpoint to check what HTML content is being served"""
    try:
        html_path = Path(__file__).parent / "frontend" / "platform_production.html"
        if html_path.exists():
            with open(html_path, 'r', encoding='utf-8') as file:
                content = file.read()
            # Return just the dashboard section
            start = content.find('<div id="dashboard" class="page active">')
            end = content.find('</div>', start + 200)
            if start != -1 and end != -1:
                return {"dashboard_content": content[start:end+6]}
            else:
                return {"error": "Dashboard section not found", "file_size": len(content)}
        else:
            return {"error": "HTML file not found", "path": str(html_path)}
    except Exception as e:
        return {"error": str(e)}

@app.get("/health")
async def health_check():
    """Simple health check for the 4-pillar system"""
    return {
        "status": "operational",
        "timestamp": datetime.now().isoformat(),
        "platform": "Domus Planning AI System",
        "version": "4.0.0",
        
        "core_pillars": {
            "planning_ai": {
                "name": "Planning AI Analysis",
                "description": "Instant approval probability & constraint analysis",
                "status": "operational"
            },
            "auto_docs": {
                "name": "Auto-Docs Generator", 
                "description": "Professional planning document generation",
                "status": "operational"
            },
            "property_api": {
                "name": "Property Data API",
                "description": "Unified UK property data source", 
                "status": "operational"
            },
            "offsets_marketplace": {
                "name": "Offsets Marketplace",
                "description": "Biodiversity Net Gain trading platform",
                "status": "operational"
            }
        },
        
        "value_proposition": {
            "for_developers": "Save months and Â£20k+ in consultancy costs",
            "for_consultants": "Scale output with AI co-pilot tools",
            "for_landowners": "Unlock development value, streamline approvals",
            "for_landowners": "Monetise land through biodiversity offsets"
        }
    }

@app.get("/api/workflow-guide")
async def workflow_guide():
    """Guide users through the 4-pillar workflow"""
    return {
        "workflow_steps": [
            {
                "step": 1,
                "pillar": "Site Input",
                "action": "Input site details (address, UPRN, or polygon)",
                "endpoint": "/api/sites/analyze"
            },
            {
                "step": 2, 
                "pillar": "Property API",
                "action": "Pull unified property data (title, EPC, flood, planning history)",
                "endpoint": "/api/property/lookup"
            },
            {
                "step": 3,
                "pillar": "Planning AI", 
                "action": "Analyze constraints + policies â†’ approval probability + recommendations",
                "endpoint": "/api/planning-ai/analyze"
            },
            {
                "step": 4,
                "pillar": "Auto-Docs",
                "action": "Generate planning application documents (Planning Statement, D&A)",
                "endpoint": "/api/auto-docs/generate"
            },
            {
                "step": 5,
                "pillar": "Decision Point",
                "action": "If viable â†’ proceed with application. If not viable â†’ list in Offsets Marketplace",
                "endpoint": "/api/offsets/list OR submit application"
            }
        ],
        "integration_points": {
            "data_flow": "Site Input â†’ Property API â†’ Planning AI â†’ Auto-Docs â†’ Submit OR Offsets",
            "closed_loop": "Failed planning applications become biodiversity offset opportunities"
        }
    }

@app.get("/api/market-stats")
async def market_statistics():
    """Show the planning market problem this solves"""
    return {
        "uk_planning_problems": {
            "average_planning_consultant_cost": "Â£15,000 - Â£30,000 per application",
            "average_decision_time": "8-16 weeks for major applications", 
            "approval_uncertainty": "60-70% approval rate varies wildly by area",
            "wasted_land_value": "Â£billions in undevelopable land sitting idle"
        },
        "domus_solution": {
            "cost_reduction": "90% reduction in consultant costs via AI automation",
            "time_savings": "80% faster constraint analysis and document generation",
            "certainty_improvement": "Predict approval probability before spending heavily",
            "alternative_value": "Monetise failed land through biodiversity offsets"
        },
        "target_market_size": {
            "uk_planning_applications_per_year": "500,000+",
            "sme_developers": "10,000+ potential users",
            "planning_consultants": "2,000+ potential users", 
            "market_opportunity": "Â£billions in development potential unlocked by AI"
        }
    }

# PLANNING AI ENDPOINTS
# ===========================================

class PlanningAnalysisRequest(BaseModel):
    address: str
    latitude: float
    longitude: float
    development_type: str = ""
    units: int = 0
    floor_area: float = 0
    height: int = 1
    scenarios: dict = {}

# AI EXPLAINABILITY & PROVENANCE HELPERS
async def get_lpa_context(address: str):
    """Get LPA context for enhanced explainability"""
    try:
        # Mock LPA context - replace with real HDT/5YHLS data lookup
        lpa_contexts = {
            "default": {
                "authority_name": "Sample District Council",
                "authority_code": "SDC",
                "hdt_performance": "95% (Green)",
                "five_year_land_supply": "5.2 years (Maintained)",
                "approval_rate": 78,
                "avg_determination_weeks": 13,
                "tilted_balance": False,
                "housing_delivery_pressure": "Low",
                "key_policies": [
                    "Local Plan Policy H1 - Housing Delivery",
                    "Local Plan Policy ENV1 - Environmental Protection", 
                    "Local Plan Policy DES1 - Design Standards"
                ],
                "recent_changes": "New Local Plan adopted January 2024"
            }
        }
        
        # Simple address-based lookup (replace with proper postcode/authority mapping)
        return lpa_contexts["default"]
        
    except Exception as e:
        # Fallback context if lookup fails
        return {
            "authority_name": "Local Planning Authority",
            "authority_code": "LPA",
            "hdt_performance": "Unknown",
            "five_year_land_supply": "Unknown", 
            "approval_rate": 75,
            "avg_determination_weeks": 14,
            "tilted_balance": False,
            "housing_delivery_pressure": "Unknown"
        }

@app.post("/api/planning-ai/analyze")
async def analyze_site_comprehensive(analysis_data: PlanningAnalysisRequest):
    """Comprehensive Planning AI analysis with constraints, policies, and precedents"""
    try:
        # Simulate processing time
        import time
        time.sleep(1)
        
        # Calculate base AI score
        base_score = 65
        score_adjustments = 0
        key_factors = []
        
        # Development type adjustments
        if analysis_data.development_type == "residential":
            score_adjustments += 10
            key_factors.append({"text": "Residential development prioritized", "positive": True})
        elif analysis_data.development_type == "affordable_housing":
            score_adjustments += 20
            key_factors.append({"text": "Affordable housing strongly supported", "positive": True})
        elif analysis_data.development_type == "commercial":
            score_adjustments += 5
            key_factors.append({"text": "Commercial development acceptable", "positive": True})
        
        # Units scaling
        if analysis_data.units > 0:
            if analysis_data.units <= 10:
                score_adjustments += 15
                key_factors.append({"text": "Small scale development favored", "positive": True})
            elif analysis_data.units <= 50:
                score_adjustments += 8
                key_factors.append({"text": "Medium scale development appropriate", "positive": True})
            else:
                score_adjustments -= 10
                key_factors.append({"text": "Large scale may face community resistance", "positive": False})
        
        # Height considerations
        if analysis_data.height > 4:
            score_adjustments -= 5
            key_factors.append({"text": "Height may cause visual impact concerns", "positive": False})
        
        # Scenario bonuses
        scenarios = analysis_data.scenarios or {}
        if scenarios.get("affordable_housing"):
            score_adjustments += 12
            key_factors.append({"text": "35% affordable housing commitment", "positive": True})
        if scenarios.get("net_gain"):
            score_adjustments += 8
            key_factors.append({"text": "Biodiversity Net Gain compliance", "positive": True})
        if scenarios.get("car_free"):
            score_adjustments += 6
            key_factors.append({"text": "Car-free development reduces transport impact", "positive": True})
        if scenarios.get("sustainable"):
            score_adjustments += 10
            key_factors.append({"text": "BREEAM Excellent sustainability rating", "positive": True})
        
        # Add some randomization for realism
        score_adjustments += random.randint(-8, 12)
        final_score = max(15, min(95, base_score + score_adjustments))
        
        # Generate interpretation
        if final_score >= 80:
            interpretation = "Excellent approval prospects with strong policy support"
        elif final_score >= 65:
            interpretation = "Good approval prospects with manageable constraints"
        elif final_score >= 45:
            interpretation = "Moderate prospects requiring careful design approach"
        else:
            interpretation = "Challenging application requiring significant mitigation"
        
        # Mock constraints data based on location
        constraints = [
            {
                "name": "Conservation Area",
                "description": "Site is within 200m of Riverside Conservation Area",
                "severity": "medium",
                "distance": "180m northeast"
            },
            {
                "name": "Flood Risk Zone 2",
                "description": "Part of site falls within Environment Agency Flood Zone 2",
                "severity": "high",
                "distance": "Site partially affected"
            },
            {
                "name": "Tree Preservation Order",
                "description": "3 protected oak trees along southern boundary",
                "severity": "medium",
                "distance": "On site"
            },
            {
                "name": "Archaeological Interest",
                "description": "Area of archaeological potential - desk-based assessment required",
                "severity": "low",
                "distance": "Site affected"
            }
        ]
        
        # Mock policy citations
        policies = [
            {
                "reference": "Local Plan Policy H1",
                "title": "Housing Delivery and Allocation",
                "relevance": "Supports residential development on suitable sites"
            },
            {
                "reference": "NPPF Para 11",
                "title": "Presumption in favour of sustainable development",
                "relevance": "Presumption applies unless specific policies indicate otherwise"
            },
            {
                "reference": "Local Plan Policy ENV3",
                "title": "Conservation Areas",
                "relevance": "Development must preserve or enhance character and appearance"
            },
            {
                "reference": "Local Plan Policy CC1",
                "title": "Climate Change",
                "relevance": "Development should minimize flood risk and adapt to climate change"
            }
        ]
        
        # Mock precedents
        precedents = [
            {
                "reference": "23/01234/FUL",
                "description": "25 residential units with mixed tenure including 35% affordable housing",
                "outcome": "Approved",
                "distance": "0.8km",
                "date": "March 2024"
            },
            {
                "reference": "22/05678/FUL", 
                "description": "40 unit residential development with private parking",
                "outcome": "Refused",
                "distance": "1.2km",
                "date": "November 2023"
            },
            {
                "reference": "23/09876/FUL",
                "description": "Mixed use development with commercial ground floor",
                "outcome": "Approved",
                "distance": "1.5km",
                "date": "July 2024"
            }
        ]
        
        # Get LPA Context for explainability
        lpa_context = await get_lpa_context(analysis_data.address)
        
        # AI recommendations with enhanced explainability
        recommendations = [
            "Conduct heritage impact assessment for Conservation Area proximity",
            "Implement comprehensive flood risk management strategy", 
            "Prepare arboricultural impact assessment and tree protection plan",
            "Consider desk-based archaeological assessment early in process",
            "Engage with local community before formal submission",
            "Design sustainable drainage systems (SuDS) throughout site",
            "Incorporate renewable energy systems to exceed policy requirements"
        ]
        
        # Enhanced response with explainability metadata
        response = {
            "analysis_id": f"AI-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            "address": analysis_data.address,
            "score": final_score,
            "interpretation": interpretation,
            "key_factors": key_factors,
            "constraints": constraints,
            "policies": policies,
            "precedents": precedents,
            "recommendations": recommendations,
            "generated_at": datetime.now().isoformat(),
            
            # AI EXPLAINABILITY & PROVENANCE (Step 30)
            "confidence": random.randint(82, 94),
            "model_version": "domus-planning-ai-v2.1.0",
            "citations": [
                {
                    "source": "National Planning Policy Framework",
                    "section": "Chapter 5: Delivering a sufficient supply of homes",
                    "url": "https://www.gov.uk/government/publications/national-planning-policy-framework--2",
                    "relevance": "Housing delivery policy framework"
                },
                {
                    "source": "Planning Practice Guidance",
                    "section": "Flood Risk and Coastal Change",
                    "url": "https://www.gov.uk/guidance/flood-risk-and-coastal-change",
                    "relevance": "Flood risk assessment requirements"
                },
                {
                    "source": "Local Plan Evidence Base",
                    "section": "Strategic Housing Market Assessment",
                    "url": f"https://localplan.{lpa_context['authority_code']}.gov.uk/evidence",
                    "relevance": "Local housing need justification"
                }
            ],
            "precedents_analysis": {
                "similar_cases_analyzed": 47,
                "approval_rate_context": f"{lpa_context['approval_rate']}%",
                "average_determination_time": f"{lpa_context['avg_determination_weeks']} weeks",
                "key_success_factors": [
                    "Heritage impact mitigation",
                    "Community engagement",
                    "Affordable housing provision"
                ]
            },
            "lpa_context": lpa_context,
            "methodology": {
                "factors_weighted": [
                    {"factor": "Policy compliance", "weight": 0.3},
                    {"factor": "Site constraints", "weight": 0.25},
                    {"factor": "Local precedents", "weight": 0.2},
                    {"factor": "Community impact", "weight": 0.15},
                    {"factor": "Technical feasibility", "weight": 0.1}
                ],
                "data_sources": [
                    "Local Planning Authority policies",
                    "Appeal decisions database",
                    "Government planning guidance",
                    "Local development history"
                ]
            }
        }
        
        # Validation: Ensure minimum explainability requirements
        if len(response["citations"]) < 1:
            raise HTTPException(status_code=422, detail="Analysis must include at least one citation")
        
        if len(response["precedents"]) < 1:
            raise HTTPException(status_code=422, detail="Analysis must include at least one precedent")
        
        return response
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

@app.post("/api/planning-ai/save")
async def save_analysis(
    request: Request,
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Save Planning AI analysis with full provenance to analysis_snapshots"""
    try:
        body = await request.json()
        analysis_data = body.get("analysis_data")
        project_id = body.get("project_id")
        
        if not analysis_data:
            raise HTTPException(status_code=400, detail="Analysis data required")
        
        # Validate explainability requirements
        if not analysis_data.get("citations") or len(analysis_data["citations"]) < 1:
            raise HTTPException(status_code=422, detail="Analysis must include citations for traceability")
            
        if not analysis_data.get("precedents") or len(analysis_data["precedents"]) < 1:
            raise HTTPException(status_code=422, detail="Analysis must include precedents for validation")
            
        if not analysis_data.get("model_version"):
            raise HTTPException(status_code=422, detail="Model version required for provenance")
        
        # Store to analysis_snapshots with full provenance
        from models import AnalysisSnapshots
        
        snapshot = AnalysisSnapshots(
            org_id=current_user["org_id"],
            user_id=current_user["user_id"],
            project_id=project_id,
            analysis_type="planning_ai",
            payload_json=analysis_data,  # Includes citations, precedents, model_version
            created_at=datetime.now()
        )
        
        db.add(snapshot)
        db.commit()
        db.refresh(snapshot)
        
        # Increment usage tracking
        await QuotaService.increment_usage(
            org_id=current_user["org_id"],
            resource="api_calls_used",
            db=db
        )
        
        return {
            "success": True,
            "message": "Analysis saved with full provenance tracking",
            "snapshot_id": snapshot.id,
            "explainability_verified": True,
            "citations_count": len(analysis_data["citations"]),
            "precedents_count": len(analysis_data["precedents"]),
            "model_version": analysis_data["model_version"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/planning-ai/export")
async def export_analysis():
    """Export Planning AI analysis as PDF report"""
    try:
        # Mock export operation
        return {
            "success": True,
            "download_url": f"/downloads/planning-report-{datetime.now().strftime('%Y%m%d-%H%M%S')}.pdf",
            "expires_at": (datetime.now() + timedelta(hours=24)).isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# AUTO-DOCS ENDPOINTS
# ===========================================

class DocumentGenerationRequest(BaseModel):
    document_type: str
    project_id: int
    output_format: str = "docx"
    generation_mode: str = "comprehensive"
    options: dict = {}
    custom_instructions: str = ""

@app.post("/api/auto-docs/generate")
async def generate_document(generation_request: DocumentGenerationRequest):
    """Generate professional planning documents with AI"""
    try:
        # Simulate document generation process
        document_types = {
            "planning_statement": {
                "title": "Planning Statement",
                "sections": [
                    "Executive Summary",
                    "Site Description & Context",
                    "Development Proposals",
                    "Planning Policy Assessment",
                    "Design & Access Considerations",
                    "Technical Assessments",
                    "Community Consultation",
                    "Planning Balance & Conclusions"
                ]
            },
            "design_access_statement": {
                "title": "Design & Access Statement",
                "sections": [
                    "Introduction",
                    "Site Analysis",
                    "Design Evolution",
                    "Access Strategy",
                    "Appearance & Character",
                    "Layout & Scale",
                    "Landscaping Strategy",
                    "Sustainability Measures"
                ]
            },
            "heritage_statement": {
                "title": "Heritage Statement",
                "sections": [
                    "Introduction",
                    "Methodology",
                    "Site History",
                    "Heritage Assets Assessment",
                    "Impact Assessment",
                    "Mitigation Measures",
                    "Conclusions"
                ]
            },
            "flood_risk_assessment": {
                "title": "Flood Risk Assessment",
                "sections": [
                    "Executive Summary",
                    "Site Description",
                    "Flood Risk Identification",
                    "Flood Risk Assessment",
                    "Mitigation Measures",
                    "Residual Risk",
                    "Recommendations"
                ]
            },
            "transport_statement": {
                "title": "Transport Statement",
                "sections": [
                    "Introduction",
                    "Site Description",
                    "Existing Transport Conditions",
                    "Development Proposals",
                    "Trip Generation",
                    "Impact Assessment",
                    "Mitigation Measures"
                ]
            },
            "biodiversity_report": {
                "title": "Biodiversity Net Gain Report",
                "sections": [
                    "Executive Summary",
                    "Baseline Ecological Assessment",
                    "Impact Assessment",
                    "Mitigation Hierarchy",
                    "Net Gain Calculations",
                    "Enhancement Proposals",
                    "Monitoring Strategy"
                ]
            }
        }

        doc_config = document_types.get(generation_request.document_type, document_types["planning_statement"])
        
        # Mock project data lookup
        project_names = {
            1: "Riverside Development",
            2: "Green Valley Homes", 
            3: "City Centre Plaza"
        }
        
        project_name = project_names.get(generation_request.project_id, "Unknown Project")
        
        # Generate preview content based on document type
        preview_content = generate_document_preview(generation_request.document_type, project_name)
        
        # Calculate realistic metrics
        base_pages = 8
        if generation_request.generation_mode == "comprehensive":
            pages = base_pages + random.randint(4, 8)
        elif generation_request.generation_mode == "summary":
            pages = max(4, base_pages - random.randint(2, 4))
        else:
            pages = base_pages + random.randint(0, 3)
        
        # Adjust for options
        if generation_request.options.get("include_maps"):
            pages += 2
        if generation_request.options.get("include_photos"):
            pages += 3
        if generation_request.options.get("include_analysis"):
            pages += 2
            
        file_size = f"{pages * 0.2:.1f} MB"
        
        return {
            "success": True,
            "document_id": f"DOC-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            "title": doc_config["title"],
            "project_name": project_name,
            "pages": pages,
            "file_size": file_size,
            "sections": doc_config["sections"],
            "preview_content": preview_content,
            "download_url": f"/downloads/{generation_request.document_type}-{generation_request.project_id}-{datetime.now().strftime('%Y%m%d')}.{generation_request.output_format}",
            "generated_at": datetime.now().isoformat(),
            "expires_at": (datetime.now() + timedelta(days=30)).isoformat()
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Document generation failed: {str(e)}")

def generate_document_preview(doc_type, project_name):
    """Generate realistic document preview content"""
    previews = {
        "planning_statement": f"This Planning Statement has been prepared in support of a planning application for {project_name}. The proposed development represents a sustainable and well-designed scheme that aligns with local and national planning policy. The site is considered suitable for development, being located within the settlement boundary and having good access to local services and transport links.",
        
        "design_access_statement": f"This Design and Access Statement demonstrates how the design of {project_name} has evolved through careful analysis of the site and its context. The proposals respond positively to the character of the surrounding area while providing high-quality accommodation that meets current accessibility standards.",
        
        "heritage_statement": f"This Heritage Statement assesses the potential impact of the proposed development at {project_name} on heritage assets. The assessment concludes that the proposals have been designed to preserve the significance of nearby heritage assets while delivering sustainable development.",
        
        "flood_risk_assessment": f"This Flood Risk Assessment evaluates the flood risk to and from the proposed development at {project_name}. The assessment demonstrates that the development can be made safe from flooding and will not increase flood risk elsewhere.",
        
        "transport_statement": f"This Transport Statement assesses the transport implications of the proposed development at {project_name}. The development is well-located with good access to public transport and will not result in adverse traffic impacts.",
        
        "biodiversity_report": f"This Biodiversity Net Gain Report demonstrates how the proposed development at {project_name} will deliver measurable improvements for biodiversity. The proposals include comprehensive ecological enhancements that exceed the 10% net gain requirement."
    }
    
    return previews.get(doc_type, f"This document provides a comprehensive assessment of {project_name} in accordance with planning requirements.")

@app.get("/api/auto-docs/history")
async def get_generation_history():
    """Get user's document generation history"""
    try:
        # Mock generation history
        history = [
            {
                "id": "DOC-20241001-143022",
                "title": "Planning Statement",
                "project_name": "Riverside Development",
                "document_type": "planning_statement",
                "output_format": "docx",
                "pages": 14,
                "file_size": "2.8 MB",
                "created_at": "1 Oct 2024, 2:30 PM",
                "status": "completed"
            },
            {
                "id": "DOC-20240928-091245",
                "title": "Design & Access Statement", 
                "project_name": "Green Valley Homes",
                "document_type": "design_access_statement",
                "output_format": "pdf",
                "pages": 12,
                "file_size": "3.2 MB",
                "created_at": "28 Sep 2024, 9:12 AM",
                "status": "completed"
            },
            {
                "id": "DOC-20240925-164533",
                "title": "Heritage Statement",
                "project_name": "City Centre Plaza",
                "document_type": "heritage_statement", 
                "output_format": "docx",
                "pages": 8,
                "file_size": "1.6 MB",
                "created_at": "25 Sep 2024, 4:45 PM",
                "status": "completed"
            }
        ]
        
        return history
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/auto-docs/bundle")
async def create_document_bundle():
    """Create a bundle of multiple documents"""
    try:
        return {
            "success": True,
            "bundle_id": f"BUNDLE-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
            "title": "Planning Application Bundle",
            "documents_count": 4,
            "total_size": "12.4 MB",
            "download_url": f"/downloads/bundle-{datetime.now().strftime('%Y%m%d')}.zip",
            "created_at": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/auto-docs/templates")
async def get_document_templates():
    """Get available document templates"""
    try:
        templates = [
            {
                "type": "planning_statement",
                "name": "Planning Statement",
                "description": "Comprehensive planning justification document",
                "category": "Core Planning",
                "icon": "file-contract",
                "color": "blue"
            },
            {
                "type": "design_access_statement", 
                "name": "Design & Access Statement",
                "description": "Design principles and accessibility assessment",
                "category": "Design",
                "icon": "drafting-compass",
                "color": "purple"
            },
            {
                "type": "heritage_statement",
                "name": "Heritage Statement", 
                "description": "Impact assessment for historic assets",
                "category": "Heritage",
                "icon": "landmark",
                "color": "amber"
            },
            {
                "type": "flood_risk_assessment",
                "name": "Flood Risk Assessment",
                "description": "Flood risk analysis and mitigation",
                "category": "Environment",
                "icon": "water",
                "color": "blue"
            },
            {
                "type": "transport_statement",
                "name": "Transport Statement",
                "description": "Traffic impact and accessibility analysis", 
                "category": "Transport",
                "icon": "road",
                "color": "gray"
            },
            {
                "type": "biodiversity_report",
                "name": "Biodiversity Net Gain Report",
                "description": "Ecological impact and enhancement plan",
                "category": "Environment",
                "icon": "leaf",
                "color": "green"
            }
        ]
        
        return templates
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# PROPERTY API ENDPOINTS
# ===========================================

class PropertySearchRequest(BaseModel):
    address: str = ""
    postcode: str = ""
    property_type: str = ""
    price_range: str = ""
    bedrooms: int = None

class PropertyValuationRequest(BaseModel):
    address: str
    postcode: str
    property_type: str = ""
    bedrooms: int = None
    bathrooms: int = None
    garden: bool = False

@app.post("/api/property-api/search")
async def search_properties(search_request: PropertySearchRequest):
    """Search UK properties with comprehensive data"""
    try:
        # Mock property search results with realistic UK data
        properties = [
            {
                "id": "PROP001",
                "address": "123 Oak Avenue, Manchester M1 2AB",
                "postcode": "M1 2AB",
                "type": "Terraced",
                "bedrooms": 3,
                "bathrooms": 2,
                "price": "Â£485,000",
                "estimated_value": 485000,
                "price_per_sqft": "Â£312",
                "floor_area": 1554,
                "garden": True,
                "parking": True,
                "council": "Manchester City Council",
                "council_tax_band": "D",
                "epc_rating": "C",
                "tenure": "Freehold",
                "coordinates": [53.4808, -2.2426],
                "description": "Spacious Victorian terrace with period features, modern kitchen, and south-facing garden",
                "images": ["/images/prop1_1.jpg", "/images/prop1_2.jpg"],
                "last_sold": "2019-06-15",
                "last_price": "Â£415,000",
                "price_change": "+16.9%",
                "days_on_market": 42,
                "local_amenities": ["Primary School 0.2mi", "Train Station 0.5mi", "Shopping Centre 0.8mi"],
                "planning_restrictions": ["Conservation Area nearby", "Article 4 Direction applies"]
            },
            {
                "id": "PROP002", 
                "address": "45 Elm Grove, Manchester M1 3CD",
                "postcode": "M1 3CD",
                "type": "Semi-Detached",
                "bedrooms": 4,
                "bathrooms": 3,
                "price": "Â£520,000",
                "estimated_value": 520000,
                "price_per_sqft": "Â£298",
                "floor_area": 1745,
                "garden": True,
                "parking": True,
                "council": "Manchester City Council",
                "council_tax_band": "E", 
                "epc_rating": "B",
                "tenure": "Freehold",
                "coordinates": [53.4828, -2.2456],
                "description": "Modern semi-detached home with open plan living, fitted kitchen, and driveway parking",
                "images": ["/images/prop2_1.jpg", "/images/prop2_2.jpg"],
                "last_sold": "2020-03-22",
                "last_price": "Â£475,000",
                "price_change": "+9.5%",
                "days_on_market": 28,
                "local_amenities": ["Secondary School 0.3mi", "Hospital 1.2mi", "Park 0.1mi"],
                "planning_restrictions": ["Tree Preservation Order", "Flood Risk Zone 2"]
            },
            {
                "id": "PROP003",
                "address": "67 Birch Close, Manchester M1 4EF", 
                "postcode": "M1 4EF",
                "type": "Flat",
                "bedrooms": 2,
                "bathrooms": 1,
                "price": "Â£375,000",
                "estimated_value": 375000,
                "price_per_sqft": "Â£395",
                "floor_area": 949,
                "garden": False,
                "parking": True,
                "council": "Manchester City Council",
                "council_tax_band": "C",
                "epc_rating": "B",
                "tenure": "Leasehold",
                "coordinates": [53.4788, -2.2396],
                "description": "Contemporary apartment with balcony, underground parking, and communal gardens",
                "images": ["/images/prop3_1.jpg", "/images/prop3_2.jpg"],
                "last_sold": "2021-09-10",
                "last_price": "Â£340,000",
                "price_change": "+10.3%",
                "days_on_market": 35,
                "local_amenities": ["Gym 0.1mi", "Restaurants 0.2mi", "Metro 0.4mi"],
                "planning_restrictions": ["High-rise development nearby", "Noise abatement zone"]
            }
        ]
        
        # Filter properties based on search criteria
        filtered_properties = properties
        if search_request.property_type:
            filtered_properties = [p for p in filtered_properties if p["type"].lower() == search_request.property_type.lower()]
        
        return {
            "success": True,
            "total_found": len(filtered_properties),
            "properties": filtered_properties,
            "search_criteria": {
                "address": search_request.address,
                "postcode": search_request.postcode,
                "property_type": search_request.property_type,
                "price_range": search_request.price_range
            },
            "market_summary": {
                "average_price": "Â£493,333",
                "price_change_12m": "+8.9%",
                "average_days_on_market": 35,
                "total_listings": 248
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Property search failed: {str(e)}")

@app.post("/api/property-api/valuation")
async def get_property_valuation(valuation_request: PropertyValuationRequest):
    """Get comprehensive property valuation with market analysis"""
    try:
        # Calculate mock valuation based on inputs
        base_value = 450000
        
        # Adjust for property type
        type_multipliers = {
            "detached": 1.3,
            "semi-detached": 1.1, 
            "terraced": 1.0,
            "flat": 0.8,
            "bungalow": 1.2
        }
        
        multiplier = type_multipliers.get(valuation_request.property_type.lower(), 1.0)
        bedroom_bonus = (valuation_request.bedrooms or 3) * 25000
        bathroom_bonus = (valuation_request.bathrooms or 2) * 15000
        garden_bonus = 20000 if valuation_request.garden else 0
        
        estimated_value = int((base_value * multiplier) + bedroom_bonus + bathroom_bonus + garden_bonus)
        lower_estimate = int(estimated_value * 0.9)
        upper_estimate = int(estimated_value * 1.15)
        
        return {
            "success": True,
            "property": {
                "address": valuation_request.address,
                "postcode": valuation_request.postcode,
                "type": valuation_request.property_type,
                "bedrooms": valuation_request.bedrooms,
                "bathrooms": valuation_request.bathrooms
            },
            "valuation": {
                "estimated_value": estimated_value,
                "lower_estimate": lower_estimate,
                "upper_estimate": upper_estimate,
                "confidence": "High",
                "valuation_date": datetime.now().strftime("%Y-%m-%d"),
                "methodology": "Automated Valuation Model (AVM)"
            },
            "market_analysis": {
                "recent_sales": [
                    {"address": "125 Oak Avenue", "price": 470000, "date": "2024-08-15", "difference": "+3.2%"},
                    {"address": "121 Oak Avenue", "price": 455000, "date": "2024-07-22", "difference": "-0.8%"},
                    {"address": "119 Oak Avenue", "price": 492000, "date": "2024-06-10", "difference": "+7.8%"}
                ],
                "local_trends": {
                    "price_change_3m": "+2.1%",
                    "price_change_12m": "+8.4%",
                    "average_days_on_market": 38,
                    "sales_volume": 24
                },
                "comparable_properties": {
                    "similar_type_average": estimated_value + random.randint(-15000, 15000),
                    "same_street_average": estimated_value + random.randint(-25000, 25000),
                    "postcode_average": estimated_value + random.randint(-35000, 35000)
                }
            },
            "factors": {
                "positive": ["Good local amenities", "Transport links", "School catchment"],
                "negative": ["Busy road nearby", "Limited parking"],
                "neutral": ["Standard condition", "Typical for area"]
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Valuation failed: {str(e)}")

@app.get("/api/property-api/ownership/{postcode}")
async def get_property_ownership(postcode: str):
    """Get Land Registry ownership data"""
    try:
        # Mock Land Registry data
        ownership_data = {
            "success": True,
            "postcode": postcode.upper(),
            "properties": [
                {
                    "title_number": "ABC123456",
                    "address": f"123 Example Street, {postcode.upper()}",
                    "tenure": "Freehold",
                    "registered_owner": "John Smith",
                    "proprietor_address": "Same as property address",
                    "registration_date": "2019-06-15",
                    "last_sale_price": "Â£415,000",
                    "last_sale_date": "2019-06-15",
                    "property_description": "A dwelling-house known as 123 Example Street",
                    "charges": [],
                    "restrictions": [],
                    "notes": ["Property benefits from right of way over adjacent land"]
                }
            ],
            "land_registry_url": f"https://landregistry.data.gov.uk/app/ukhpi/browse?from=&location=http%3A%2F%2Flandregistry.data.gov.uk%2Fid%2Fregion%2Funited-kingdom&to=&lang=en",
            "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        return ownership_data
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Ownership lookup failed: {str(e)}")

@app.get("/api/property-api/planning-history/{postcode}")
async def get_planning_history(postcode: str):
    """Get planning application history for area"""
    try:
        planning_applications = [
            {
                "reference": "2024/0123/FULL",
                "address": f"123 Example Street, {postcode.upper()}",
                "proposal": "Single storey rear extension",
                "application_type": "Full Planning Permission",
                "submitted_date": "2024-02-15",
                "decision": "Approved",
                "decision_date": "2024-04-12",
                "case_officer": "Sarah Johnson",
                "agent": "ABC Planning Consultants",
                "applicant": "Mr. John Smith",
                "status": "Completed",
                "documents_url": "/planning/docs/2024-0123",
                "consultation_responses": 3,
                "objections": 0,
                "comments": ["No objections from neighbours", "Complies with local policy"]
            },
            {
                "reference": "2023/0987/FULL",
                "address": f"125 Example Street, {postcode.upper()}", 
                "proposal": "Two storey side extension",
                "application_type": "Full Planning Permission",
                "submitted_date": "2023-11-08",
                "decision": "Refused",
                "decision_date": "2024-01-22",
                "case_officer": "Michael Brown",
                "agent": "XYZ Architects",
                "applicant": "Mrs. Jane Doe",
                "status": "Refused",
                "documents_url": "/planning/docs/2023-0987",
                "consultation_responses": 8,
                "objections": 4,
                "refusal_reasons": [
                    "Excessive bulk and scale",
                    "Adverse impact on neighbour amenity", 
                    "Poor design quality"
                ],
                "comments": ["Strong local opposition", "Officer recommendation to refuse"]
            },
            {
                "reference": "2023/0654/FUL",
                "address": f"127 Example Street, {postcode.upper()}",
                "proposal": "Loft conversion with rear dormer window",
                "application_type": "Full Planning Permission", 
                "submitted_date": "2023-08-20",
                "decision": "Approved",
                "decision_date": "2023-10-15",
                "case_officer": "Lisa Wilson",
                "agent": "DEF Planning Services",
                "applicant": "Mr. David Jones",
                "status": "Approved",
                "documents_url": "/planning/docs/2023-0654",
                "consultation_responses": 2,
                "objections": 0,
                "conditions": [
                    "Materials to match existing",
                    "Work to commence within 3 years",
                    "Permitted development rights removed"
                ]
            }
        ]
        
        return {
            "success": True,
            "postcode": postcode.upper(),
            "total_applications": len(planning_applications),
            "applications": planning_applications,
            "summary": {
                "approved": 2,
                "refused": 1,
                "pending": 0,
                "withdrawn": 0,
                "success_rate": "67%"
            },
            "trends": {
                "most_common_type": "Extensions",
                "average_decision_time": "68 days",
                "recent_activity": "Moderate"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Planning history lookup failed: {str(e)}")

@app.get("/api/property-api/market-analytics/{area}")
async def get_market_analytics(area: str):
    """Get comprehensive market analytics for area"""
    try:
        return {
            "success": True,
            "area": area,
            "market_data": {
                "current_stats": {
                    "average_price": "Â£487,250",
                    "median_price": "Â£465,000", 
                    "price_per_sqft": "Â£315",
                    "total_sales_12m": 284,
                    "average_days_on_market": 42,
                    "sale_success_rate": "87%"
                },
                "price_trends": {
                    "1_month": "+1.2%",
                    "3_months": "+3.8%", 
                    "6_months": "+6.1%",
                    "12_months": "+8.9%",
                    "5_years": "+34.2%"
                },
                "property_types": {
                    "terraced": {"count": 156, "avg_price": "Â£445,000", "change": "+7.8%"},
                    "semi_detached": {"count": 89, "avg_price": "Â£525,000", "change": "+9.2%"},
                    "detached": {"count": 34, "avg_price": "Â£675,000", "change": "+11.1%"},
                    "flat": {"count": 73, "avg_price": "Â£385,000", "change": "+6.4%"}
                },
                "local_features": {
                    "schools": {"primary": 8, "secondary": 3, "ofsted_good_plus": "85%"},
                    "transport": {"train_stations": 2, "bus_routes": 12, "tube_zones": "N/A"},
                    "amenities": {"shops": 45, "restaurants": 23, "parks": 6},
                    "crime_rate": "Below average", 
                    "air_quality": "Good"
                },
                "forecasts": {
                    "next_6_months": "+2.5%",
                    "next_12_months": "+4.8%",
                    "confidence": "Medium"
                }
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Market analytics failed: {str(e)}")

# OFFSETS MARKETPLACE ENDPOINTS
# ===========================================

class CreditSearchRequest(BaseModel):
    habitat_type: str = ""
    location: str = ""
    credits_needed: int = None
    price_range: str = ""
    delivery_date: str = ""

class ProjectListingRequest(BaseModel):
    project_name: str
    habitat_type: str
    area_hectares: float
    location: str
    credits_to_generate: int
    price_per_credit: float
    description: str = ""

class BNGCalculationRequest(BaseModel):
    development_type: str
    site_area: float
    baseline_units: float
    post_development_units: float

@app.post("/api/offsets-marketplace/search-credits")
async def search_credits(search_request: CreditSearchRequest):
    """Search available biodiversity credits"""
    try:
        # Mock biodiversity credits data
        credits = [
            {
                "id": "CRED001",
                "project_name": "Meadowlands Restoration",
                "habitat_type": "Grassland",
                "description": "Species-rich grassland restoration on former agricultural land with wildflower meadows and chalk downland characteristics",
                "credits_available": 45,
                "price_per_credit": 11500,
                "location": "Hampshire",
                "county": "Hampshire",
                "region": "South East",
                "postcode_area": "SO",
                "delivery_date": "2025-06-15",
                "provider": "Hampshire Wildlife Trust",
                "provider_rating": 4.8,
                "verification_status": "Verified",
                "habitat_condition": "Good",
                "management_plan": "30 years",
                "legal_agreement": "Conservation Covenant",
                "financial_security": "Bond provided",
                "coordinates": [51.0624, -1.3081],
                "area_hectares": 18.5,
                "baseline_condition": "Poor",
                "target_condition": "Good",
                "monitoring_frequency": "Annual",
                "created_at": "2024-10-01",
                "expires_at": "2024-10-15"
            },
            {
                "id": "CRED002", 
                "project_name": "Ancient Woodland Enhancement",
                "habitat_type": "Woodland",
                "description": "Native woodland planting and enhancement with oak, ash, birch, and hazel species on degraded farmland",
                "credits_available": 28,
                "price_per_credit": 15200,
                "location": "Surrey",
                "county": "Surrey",
                "region": "South East", 
                "postcode_area": "GU",
                "delivery_date": "2025-09-30",
                "provider": "Woodland Heritage Foundation",
                "provider_rating": 4.9,
                "verification_status": "Verified",
                "habitat_condition": "Moderate",
                "management_plan": "50 years",
                "legal_agreement": "Section 106",
                "financial_security": "Escrow account",
                "coordinates": [51.2362, -0.5704],
                "area_hectares": 12.3,
                "baseline_condition": "Poor",
                "target_condition": "Distinctly Good",
                "monitoring_frequency": "Bi-annual",
                "created_at": "2024-09-15",
                "expires_at": "2024-10-12"
            },
            {
                "id": "CRED003",
                "project_name": "Wetland Creation Project", 
                "habitat_type": "Wetland",
                "description": "New wetland habitat creation with reed beds, shallow water areas, and marginal vegetation for wildlife",
                "credits_available": 67,
                "price_per_credit": 18750,
                "location": "Kent",
                "county": "Kent",
                "region": "South East",
                "postcode_area": "CT",
                "delivery_date": "2025-03-31",
                "provider": "Kent Wetlands Consortium",
                "provider_rating": 4.7,
                "verification_status": "Verified",
                "habitat_condition": "N/A - New Creation",
                "management_plan": "40 years",
                "legal_agreement": "Conservation Covenant",
                "financial_security": "Insurance bond",
                "coordinates": [51.2787, 1.0877],
                "area_hectares": 25.8,
                "baseline_condition": "Arable",
                "target_condition": "Good",
                "monitoring_frequency": "Quarterly Year 1-3, Annual thereafter",
                "created_at": "2024-08-20",
                "expires_at": "2024-10-08"
            }
        ]
        
        # Filter credits based on search criteria
        filtered_credits = credits
        if search_request.habitat_type:
            filtered_credits = [c for c in filtered_credits if c["habitat_type"].lower() == search_request.habitat_type.lower()]
        
        if search_request.location:
            filtered_credits = [c for c in filtered_credits if search_request.location.lower() in c["location"].lower()]
            
        return {
            "success": True,
            "total_found": len(filtered_credits),
            "credits": filtered_credits,
            "search_criteria": {
                "habitat_type": search_request.habitat_type,
                "location": search_request.location,
                "credits_needed": search_request.credits_needed,
                "price_range": search_request.price_range
            },
            "market_summary": {
                "total_credits_available": sum(c["credits_available"] for c in credits),
                "average_price": f"Â£{sum(c['price_per_credit'] for c in credits) // len(credits):,}",
                "habitat_distribution": {
                    "grassland": len([c for c in credits if c["habitat_type"] == "Grassland"]),
                    "woodland": len([c for c in credits if c["habitat_type"] == "Woodland"]),
                    "wetland": len([c for c in credits if c["habitat_type"] == "Wetland"])
                }
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Credit search failed: {str(e)}")

@app.post("/api/offsets-marketplace/list-project")
async def list_project(listing_request: ProjectListingRequest):
    """List a new conservation project for credit generation"""
    try:
        # Generate project listing ID
        project_id = f"PROJ-{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        
        # Calculate estimated timeline and requirements
        timeline_months = {
            "grassland": 18,
            "woodland": 24, 
            "wetland": 12,
            "heathland": 20
        }
        
        estimated_timeline = timeline_months.get(listing_request.habitat_type.lower(), 18)
        total_value = listing_request.credits_to_generate * listing_request.price_per_credit
        
        return {
            "success": True,
            "project_id": project_id,
            "listing": {
                "project_name": listing_request.project_name,
                "habitat_type": listing_request.habitat_type,
                "area_hectares": listing_request.area_hectares,
                "location": listing_request.location,
                "credits_to_generate": listing_request.credits_to_generate,
                "price_per_credit": listing_request.price_per_credit,
                "total_value": total_value,
                "description": listing_request.description
            },
            "requirements": {
                "ecological_survey": "Required within 6 months",
                "management_plan": "30+ year plan required",
                "legal_agreement": "Conservation covenant or S106",
                "financial_security": f"Â£{int(total_value * 0.15):,} bond required",
                "monitoring": "Annual monitoring for first 5 years"
            },
            "timeline": {
                "estimated_duration": f"{estimated_timeline} months",
                "key_milestones": [
                    "Baseline survey (Month 0-2)",
                    "Management plan approval (Month 2-4)",
                    "Legal agreement (Month 4-6)",
                    "Implementation start (Month 6)",
                    f"Credit delivery (Month {estimated_timeline})"
                ]
            },
            "next_steps": [
                "Submit detailed ecological baseline survey",
                "Prepare 30+ year management plan",
                "Arrange legal agreement documentation",
                "Provide financial security arrangement",
                "Schedule independent verification visit"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Project listing failed: {str(e)}")

@app.post("/api/offsets-marketplace/calculate-bng")
async def calculate_bng(calculation_request: BNGCalculationRequest):
    """Calculate Biodiversity Net Gain requirements"""
    try:
        baseline = calculation_request.baseline_units
        post_dev = calculation_request.post_development_units
        
        # Calculate 10% net gain requirement
        target_units = baseline * 1.1
        units_needed = max(0, target_units - post_dev)
        percentage_gain = ((post_dev / baseline) - 1) * 100
        
        # Calculate estimated costs based on habitat type and location
        base_price_per_unit = 12500
        development_multipliers = {
            "residential": 1.0,
            "commercial": 1.2,
            "industrial": 1.5,
            "infrastructure": 1.8
        }
        
        multiplier = development_multipliers.get(calculation_request.development_type, 1.0)
        estimated_cost = units_needed * base_price_per_unit * multiplier
        
        # Determine compliance status
        is_compliant = percentage_gain >= 10
        compliance_gap = max(0, 10 - percentage_gain)
        
        return {
            "success": True,
            "calculation": {
                "development_type": calculation_request.development_type,
                "site_area_hectares": calculation_request.site_area,
                "baseline_units": baseline,
                "post_development_units": post_dev,
                "target_units": round(target_units, 2),
                "units_needed": round(units_needed, 2),
                "percentage_gain": round(percentage_gain, 1),
                "estimated_cost": estimated_cost,
                "is_compliant": is_compliant
            },
            "compliance": {
                "status": "Compliant" if is_compliant else "Non-Compliant",
                "gap": round(compliance_gap, 1) if not is_compliant else 0,
                "additional_units_needed": round(compliance_gap * baseline / 100, 2) if not is_compliant else 0
            },
            "recommendations": [
                "Consider on-site habitat creation first",
                "Explore local offset providers for best value",
                "Ensure habitat matching for credit purchases",
                "Plan for 30+ year management commitments",
                "Consult with ecological specialists"
            ],
            "habitat_preferences": {
                "grassland": f"Â£{base_price_per_unit:,} per unit",
                "woodland": f"Â£{int(base_price_per_unit * 1.3):,} per unit", 
                "wetland": f"Â£{int(base_price_per_unit * 1.5):,} per unit",
                "heathland": f"Â£{int(base_price_per_unit * 1.2):,} per unit"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"BNG calculation failed: {str(e)}")

@app.get("/api/offsets-marketplace/portfolio")
async def get_portfolio():
    """Get user's biodiversity credits portfolio"""
    try:
        portfolio = [
            {
                "id": "HOLD001",
                "project_name": "Hillside Grassland Enhancement",
                "location": "Berkshire",
                "habitat_type": "Grassland",
                "credits_owned": 25,
                "purchase_price": 11500,
                "current_value": 12800,
                "total_value": 320000,
                "purchase_date": "2024-03-15",
                "delivery_status": "Active",
                "management_status": "On Track",
                "monitoring_date": "2024-09-15",
                "return_percentage": 11.3
            },
            {
                "id": "HOLD002", 
                "project_name": "River Valley Woodland",
                "location": "Oxfordshire",
                "habitat_type": "Woodland", 
                "credits_owned": 18,
                "purchase_price": 15200,
                "current_value": 16100,
                "total_value": 289800,
                "purchase_date": "2024-01-22",
                "delivery_status": "Delivered",
                "management_status": "Excellent",
                "monitoring_date": "2024-08-30",
                "return_percentage": 5.9
            },
            {
                "id": "HOLD003",
                "project_name": "Coastal Wetlands Creation",
                "location": "Dorset",
                "habitat_type": "Wetland",
                "credits_owned": 32,
                "purchase_price": 18750,
                "current_value": 19500,
                "total_value": 624000,
                "purchase_date": "2024-06-10", 
                "delivery_status": "In Progress",
                "management_status": "Good",
                "monitoring_date": "2024-11-01",
                "return_percentage": 4.0
            }
        ]
        
        total_value = sum(h["total_value"] for h in portfolio)
        total_credits = sum(h["credits_owned"] for h in portfolio)
        avg_return = sum(h["return_percentage"] for h in portfolio) / len(portfolio)
        
        return {
            "success": True,
            "portfolio": portfolio,
            "summary": {
                "total_credits": total_credits,
                "total_value": total_value,
                "average_return": round(avg_return, 1),
                "portfolio_diversity": {
                    "grassland": len([h for h in portfolio if h["habitat_type"] == "Grassland"]),
                    "woodland": len([h for h in portfolio if h["habitat_type"] == "Woodland"]),
                    "wetland": len([h for h in portfolio if h["habitat_type"] == "Wetland"])
                }
            },
            "performance": {
                "best_performer": max(portfolio, key=lambda x: x["return_percentage"]),
                "recent_activity": "3 monitoring reports received this month",
                "upcoming_deliveries": 1
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Portfolio retrieval failed: {str(e)}")

@app.get("/api/offsets-marketplace/compliance/{project_id}")
async def get_compliance_status(project_id: int):
    """Get BNG compliance status for a project"""
    try:
        # Mock compliance data
        compliance_data = {
            "project_id": project_id,
            "project_name": "Riverside Development" if project_id == 1 else "Green Valley Homes",
            "bng_requirement": 10.0,
            "current_bng": 15.2 if project_id == 1 else 8.5,
            "compliance_status": "Compliant" if project_id == 1 else "Non-Compliant",
            "units_required": 42.5,
            "units_secured": 48.3 if project_id == 1 else 36.1,
            "gap": 0 if project_id == 1 else 6.4,
            "credits_purchased": [
                {
                    "credit_id": "CRED001",
                    "project_name": "Meadowlands Restoration",
                    "units": 25,
                    "delivery_date": "2025-06-15",
                    "status": "Secured"
                },
                {
                    "credit_id": "CRED002",
                    "project_name": "Ancient Woodland Enhancement", 
                    "units": 15,
                    "delivery_date": "2025-09-30",
                    "status": "In Progress"
                }
            ] if project_id == 1 else [],
            "monitoring_schedule": [
                {"date": "2024-12-01", "type": "Baseline Survey", "status": "Scheduled"},
                {"date": "2025-03-01", "type": "Quarterly Check", "status": "Pending"},
                {"date": "2025-06-01", "type": "Annual Review", "status": "Pending"}
            ],
            "legal_obligations": {
                "planning_condition": "Condition 15: BNG delivery before occupation",
                "s106_agreement": "Â£50,000 financial contribution if on-site delivery fails",
                "monitoring_requirement": "Annual reports for 30 years"
            }
        }
        
        return compliance_data
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Compliance check failed: {str(e)}")

@app.get("/api/offsets-marketplace/market-analytics")
async def get_market_analytics():
    """Get biodiversity credits market analytics"""
    try:
        return {
            "success": True,
            "market_overview": {
                "total_credits_traded": 12847,
                "total_value_traded": "Â£156.8M",
                "active_projects": 234,
                "average_price": "Â£12,500",
                "price_trend_3m": "+8.2%",
                "price_trend_12m": "+23.7%"
            },
            "habitat_breakdown": {
                "grassland": {"percentage": 42, "avg_price": 11500, "trend": "+6.5%"},
                "woodland": {"percentage": 28, "avg_price": 15200, "trend": "+12.1%"},
                "wetland": {"percentage": 18, "avg_price": 18750, "trend": "+18.3%"},
                "heathland": {"percentage": 8, "avg_price": 14300, "trend": "+9.8%"},
                "other": {"percentage": 4, "avg_price": 13200, "trend": "+5.2%"}
            },
            "regional_data": {
                "south_east": {"credits": 4250, "avg_price": 13200, "trend": "+9.8%"},
                "south_west": {"credits": 2890, "avg_price": 11800, "trend": "+7.2%"},
                "east": {"credits": 2145, "avg_price": 12600, "trend": "+8.9%"},
                "north_west": {"credits": 1678, "avg_price": 10900, "trend": "+6.1%"},
                "other": {"credits": 1884, "avg_price": 11400, "trend": "+7.8%"}
            },
            "forecasts": {
                "next_quarter": {
                    "price_prediction": "+3.5%",
                    "demand_outlook": "High",
                    "supply_concerns": "Moderate shortage expected"
                },
                "next_year": {
                    "price_prediction": "+15-20%",
                    "market_maturity": "Rapidly developing",
                    "regulatory_changes": "Enhanced enforcement expected"
                }
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Market analytics failed: {str(e)}")

# Property data lookup endpoint (fixed)
@app.post("/api/property/lookup")
async def property_lookup(
    request: Request,
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Property data lookup with quota enforcement"""
    # Quota is enforced by middleware
    body = await request.json()
    address = body.get("address")
    if not address:
        raise HTTPException(status_code=400, detail="Address required")
    # TODO: Integrate with actual property data APIs
    return {
        "lookup_id": f"PROP-{datetime.now().strftime('%Y%m%d')}-{current_user['org_id']}",
        "address": address,
        "uprn": "123456789",
        "council_tax_band": "D",
        "epc_rating": "C",
        "energy_score": 72,
        "last_sale_price": "Â£285,000",
        "last_sale_date": "2021-03-15",
        "quota_used": True
    }

# Production API endpoints with proper authentication and quota enforcement

@app.post("/api/billing/create-checkout")
async def create_checkout_session(
    request: Request,
    current_user: dict = Depends(get_current_user), 
    db: Session = Depends(get_db)
):
    """Create Stripe checkout session for plan upgrade"""
    try:
        body = await request.json()
        plan_type = body.get("plan", "PRO")
        
        if plan_type not in ["PRO", "ENTERPRISE"]:
            raise HTTPException(status_code=400, detail="Invalid plan type")
        
        success_url = os.getenv('BILLING_SUCCESS_URL', f"{request.base_url}settings/billing?success=true")
        cancel_url = os.getenv('BILLING_CANCEL_URL', f"{request.base_url}settings/billing?cancelled=true")
        
        checkout_url = await StripeService.create_checkout_session(
            org_id=current_user["org_id"],
            plan=plan_type,
            success_url=success_url,
            cancel_url=cancel_url,
            db=db
        )
        
        return {"checkout_url": checkout_url}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/billing/portal")
async def get_billing_portal(
    request: Request,
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Get Stripe billing portal URL"""
    try:
        portal_url = await StripeService.get_billing_portal_url(
            org_id=current_user["org_id"],
            return_url=str(request.base_url) + "settings/billing",
            db=db
        )
        
        if not portal_url:
            raise HTTPException(status_code=404, detail="No billing account found")
            
        return {"portal_url": portal_url}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/billing/invoices")
async def get_invoices(
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Get organization invoices"""
    try:
        invoices = await StripeService.get_invoices(
            org_id=current_user["org_id"],
            db=db
        )
        return {"invoices": invoices}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/billing/usage")
async def get_usage(
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Get current usage and quotas"""
    try:
        org = db.query(Orgs).filter(Orgs.id == current_user["org_id"]).first()
        plan_quotas = QuotaService.get_plan_quotas(org.plan.value)
        
        from datetime import datetime
        current_month = datetime.now().strftime('%Y-%m')
        usage = db.query(UsageCounters).filter(
            UsageCounters.org_id == current_user["org_id"],
            UsageCounters.month == current_month
        ).first()
        
        current_usage = {
            'projects_used': usage.projects_used if usage else 0,
            'docs_used': usage.docs_used if usage else 0,
            'viability_runs': usage.viability_runs if usage else 0,
            'bng_runs': usage.bng_runs if usage else 0,
            'transport_runs': usage.transport_runs if usage else 0,
            'environment_runs': usage.environment_runs if usage else 0,
            'packs_created': usage.packs_created if usage else 0,
            'api_calls_used': usage.api_calls_used if usage else 0
        }
        
        return {
            "plan": org.plan.value,
            "quotas": plan_quotas,
            "usage": current_usage,
            "month": current_month
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/api/billing/webhook")
async def stripe_webhook(
    request: Request,
    db: Session = Depends(get_db)
):
    """Handle Stripe webhooks"""
    try:
        payload = await request.body()
        sig_header = request.headers.get('stripe-signature')
        webhook_secret = os.getenv('STRIPE_WEBHOOK_SECRET')
        
        event = stripe.Webhook.construct_event(
            payload, sig_header, webhook_secret
        )
        
        if event['type'] == 'checkout.session.completed':
            session = event['data']['object']
            org_id = int(session['metadata']['org_id'])
            plan = session['metadata']['plan']
            
            # Update organization plan
            org = db.query(Orgs).filter(Orgs.id == org_id).first()
            if org:
                org.plan = PlanType(plan)
                org.billing_customer_id = session['customer']
                db.commit()
                
                # Reset monthly quotas for upgraded plan
                await QuotaService.reset_monthly_quotas(db)
        
        elif event['type'] == 'invoice.paid':
            invoice = event['data']['object']
            # Handle successful payment
            pass
            
        elif event['type'] == 'invoice.payment_failed':
            invoice = event['data']['object']
            # Handle failed payment - could downgrade plan or send alerts
            pass
            
        elif event['type'] == 'customer.subscription.updated':
            subscription = event['data']['object']
            # Handle subscription changes
            pass
        
        elif event['type'] == 'payment_intent.succeeded':
            payment_intent = event['data']['object']
            contract_id = payment_intent['metadata'].get('contract_id')
            
            if contract_id:
                # Update contract status to completed
                contract = db.query(Contracts).filter(Contracts.id == int(contract_id)).first()
                if contract:
                    contract.status = ContractStatus.COMPLETED
                    db.commit()
                    
                    # Generate deal report
                    await ContractPaymentService.generate_deal_report(int(contract_id), db)
        
        elif event['type'] == 'transfer.paid':
            transfer = event['data']['object']
            # Handle successful transfer to landowner
            pass
        
        return {"received": True}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

# =====================================
# MARKETPLACE PAYOUTS (STRIPE CONNECT)
# =====================================

class StripeConnectService:
    @staticmethod
    async def create_connect_account(org_id: int, db: Session):
        """Create Stripe Connect Express account for landowner"""
        try:
            account = stripe.Account.create(
                type='express',
                country='GB',
                email=f"payouts@org{org_id}.domus.com",
                capabilities={
                    'transfers': {'requested': True},
                },
                business_type='company',
                metadata={'org_id': org_id}
            )
            
            # Store account ID in marketplace supply
            from models import MarketplaceSupply
            supply = db.query(MarketplaceSupply).filter(
                MarketplaceSupply.supplier_org_id == org_id
            ).first()
            
            if supply:
                supply.kyc_account_id = account.id
                db.commit()
            
            return account.id
        except Exception as e:
            raise Exception(f"Failed to create Connect account: {str(e)}")
    
    @staticmethod
    async def create_account_link(account_id: str, refresh_url: str, return_url: str):
        """Create Connect account onboarding link"""
        try:
            account_link = stripe.AccountLink.create(
                account=account_id,
                refresh_url=refresh_url,
                return_url=return_url,
                type='account_onboarding',
            )
            return account_link.url
        except Exception as e:
            raise Exception(f"Failed to create account link: {str(e)}")
    
    @staticmethod
    async def check_account_status(account_id: str):
        """Check Connect account verification status"""
        try:
            account = stripe.Account.retrieve(account_id)
            return {
                'charges_enabled': account.charges_enabled,
                'payouts_enabled': account.payouts_enabled,
                'details_submitted': account.details_submitted,
                'requirements': account.requirements.currently_due if account.requirements else []
            }
        except Exception as e:
            raise Exception(f"Failed to check account status: {str(e)}")

class ContractPaymentService:
    @staticmethod
    async def create_payment_intent(contract_id: int, amount: int, seller_account_id: str, db: Session):
        """Create PaymentIntent with application fee for marketplace transaction"""
        try:
            # Calculate 7% application fee
            app_fee_bps = int(os.getenv('APP_FEE_BPS', '700'))  # 7% = 700 basis points
            application_fee = int((amount * app_fee_bps) / 10000)
            
            payment_intent = stripe.PaymentIntent.create(
                amount=amount,  # Amount in pence
                currency='gbp',
                application_fee_amount=application_fee,
                transfer_data={
                    'destination': seller_account_id,
                },
                metadata={'contract_id': contract_id},
                payment_method_types=['card', 'bacs_debit']
            )
            
            # Update contract with payment intent ID
            from models import Contracts
            contract = db.query(Contracts).filter(Contracts.id == contract_id).first()
            if contract:
                contract.payment_intent_id = payment_intent.id
                contract.status = 'payment_pending'
                db.commit()
            
            return payment_intent.client_secret
        except Exception as e:
            raise Exception(f"Failed to create payment intent: {str(e)}")
    
    @staticmethod
    async def generate_deal_report(contract_id: int, db: Session):
        """Generate and store Deal Report for completed transaction"""
        try:
            from models import Contracts
            contract = db.query(Contracts).filter(Contracts.id == contract_id).first()
            
            if not contract:
                raise Exception("Contract not found")
            
            # Generate report data
            report_data = {
                'contract_id': contract_id,
                'buyer_org': contract.buyer_org_id,
                'seller_org': contract.seller_org_id,
                'amount': contract.total_price,
                'fee_collected': contract.total_price * 0.07,  # 7% fee
                'completed_at': datetime.now().isoformat(),
                'payment_intent_id': contract.payment_intent_id
            }
            
            # Store to S3 (mock implementation)
            report_url = f"https://s3.amazonaws.com/domus-reports/deal-{contract_id}.json"
            contract.deal_report_url = report_url
            contract.audit_json = report_data
            db.commit()
            
            return report_url
        except Exception as e:
            raise Exception(f"Failed to generate deal report: {str(e)}")

@app.post("/api/payouts/connect")
async def create_connect_account(
    request: Request,
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Create Stripe Connect account for landowner payouts"""
    try:
        account_id = await StripeConnectService.create_connect_account(
            org_id=current_user["org_id"],
            db=db
        )
        
        refresh_url = f"{request.base_url}marketplace/supply?setup=refresh"
        return_url = f"{request.base_url}marketplace/supply?setup=complete"
        
        onboarding_url = await StripeConnectService.create_account_link(
            account_id=account_id,
            refresh_url=refresh_url,
            return_url=return_url
        )
        
        return {"onboarding_url": onboarding_url, "account_id": account_id}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/payouts/status")
async def get_payout_status(
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Get Connect account verification status"""
    try:
        from models import MarketplaceSupply
        supply = db.query(MarketplaceSupply).filter(
            MarketplaceSupply.supplier_org_id == current_user["org_id"]
        ).first()
        
        if not supply or not supply.kyc_account_id:
            return {"connected": False, "account_id": None}
        
        status = await StripeConnectService.check_account_status(supply.kyc_account_id)
        
        return {
            "connected": True,
            "account_id": supply.kyc_account_id,
            "status": status
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.post("/api/contracts")
async def create_contract(
    request: Request,
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Create new marketplace contract"""
    try:
        body = await request.json()
        
        from models import Contracts
        contract = Contracts(
            buyer_org_id=current_user["org_id"],
            seller_org_id=body["seller_org_id"],
            supply_listing_id=body["supply_listing_id"],
            hectares_required=body["hectares_required"],
            unit_price=body["unit_price"],
            total_price=body["hectares_required"] * body["unit_price"],
            status='draft',
            created_at=datetime.now()
        )
        
        db.add(contract)
        db.commit()
        db.refresh(contract)
        
        return {"contract_id": contract.id, "status": "draft"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.patch("/api/contracts/{contract_id}")
async def update_contract(
    contract_id: int,
    request: Request,
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Update contract status and handle payments"""
    try:
        body = await request.json()
        action = body.get("action")
        
        from models import Contracts, MarketplaceSupply
        contract = db.query(Contracts).filter(Contracts.id == contract_id).first()
        
        if not contract:
            raise HTTPException(status_code=404, detail="Contract not found")
        
        # Verify user has access
        if contract.buyer_org_id != current_user["org_id"] and contract.seller_org_id != current_user["org_id"]:
            raise HTTPException(status_code=403, detail="Access denied")
        
        if action == "initiate_payment":
            # Get seller's Connect account
            seller_supply = db.query(MarketplaceSupply).filter(
                MarketplaceSupply.supplier_org_id == contract.seller_org_id
            ).first()
            
            if not seller_supply or not seller_supply.kyc_account_id:
                raise HTTPException(status_code=400, detail="Seller has not set up payouts")
            
            # Create payment intent
            client_secret = await ContractPaymentService.create_payment_intent(
                contract_id=contract_id,
                amount=int(contract.total_price * 100),  # Convert to pence
                seller_account_id=seller_supply.kyc_account_id,
                db=db
            )
            
            return {"client_secret": client_secret}
        
        elif action == "mark_completed":
            contract.status = 'completed'
            
            # Generate deal report
            report_url = await ContractPaymentService.generate_deal_report(contract_id, db)
            
            db.commit()
            
            return {"status": "completed", "deal_report_url": report_url}
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/dashboard/stats")
async def get_dashboard_stats(
    current_user: dict = Depends(get_current_user), 
    db: Session = Depends(get_db)
):
    """Get user dashboard statistics with usage data"""
    try:
        # Try to get real usage data
        if PRODUCTION_AUTH_AVAILABLE:
            from production_auth import get_current_usage
        
        try:
            from models import Usage, Organization
            from datetime import datetime
            
            # Get current month usage
            now = datetime.utcnow()
            month_start = datetime(now.year, now.month, 1)
            
            # Get usage counts
            site_analyses = db.query(Usage).filter(
                Usage.org_id == current_user["org_id"],
                Usage.resource_type == "site_analyses",
                Usage.created_at >= month_start
            ).count()
            
            documents = db.query(Usage).filter(
                Usage.org_id == current_user["org_id"],
                Usage.resource_type == "documents", 
                Usage.created_at >= month_start
            ).count()
            
            api_calls = db.query(Usage).filter(
                Usage.org_id == current_user["org_id"],
                Usage.resource_type == "api_calls",
                Usage.created_at >= month_start
            ).count()
            
            # Get organization for plan info
            org = db.query(Organization).filter(Organization.id == current_user["org_id"]).first()
            plan_type = org.plan_type.value if org else "enterprise"
            
        except Exception as db_error:
            print(f" Database query failed, using demo data: {db_error}")
            # Fallback to demo data
            site_analyses = 24
            documents = 156
            api_calls = 2847
            plan_type = "enterprise"
        
        # Calculate cost savings (estimated)
        cost_per_analysis = 1500  # Â£1,500 average consultant cost per analysis
        estimated_savings = site_analyses * cost_per_analysis
        
        return {
            "site_analyses": site_analyses,
            "documents": documents,
            "api_calls": api_calls,
            "estimated_savings": estimated_savings,
            "plan_type": plan_type,
            "usage": {
                "site_analyses": {
                    "current": site_analyses, 
                    "limit": "unlimited"
                },
                "documents": {
                    "current": documents, 
                    "limit": "unlimited"
                },
                "api_calls": {
                    "current": api_calls,
                    "limit": "unlimited"
                }
            }
        }
        
    except Exception as e:
        # Complete fallback
        return {
            "site_analyses": 24,
            "documents": 156,
            "api_calls": 2847,
            "estimated_savings": 36000,
            "plan_type": "enterprise",
            "usage": {
                "site_analyses": {"current": 24, "limit": "unlimited"},
                "documents": {"current": 156, "limit": "unlimited"},
                "api_calls": {"current": 2847, "limit": "unlimited"}
            }
        }

# =============================================================================
# PROJECTS MODULE - Core project management functionality
# =============================================================================

# Projects Page Routes
@app.get("/projects")
async def projects_page(request: Request):
    """Projects listing page"""
    return templates.TemplateResponse("projects_list.html", {"request": request})

@app.get("/projects/new")
async def new_project_page(request: Request):
    """New project creation page"""
    return templates.TemplateResponse("project_new.html", {"request": request})

@app.get("/projects/{project_id}")
async def project_detail_page(request: Request, project_id: str):
    """Individual project detail page"""
    return templates.TemplateResponse("project_detail.html", {"request": request, "project_id": project_id})

# Projects API Endpoints
@app.get("/api/projects")
async def get_projects(
    search: str = None,
    status: str = None,
    type: str = None,
    limit: int = 50,
    offset: int = 0
):
    """Get projects with optional filtering"""
    # Mock project data - in production this would query the database
    projects = [
        {
            "id": "proj_001",
            "name": "Residential Development - Oak Street",
            "address": "123 Oak Street, Manchester, M1 2AB",
            "type": "residential",
            "status": "planning",
            "ai_score": 78,
            "document_count": 5,
            "created_at": (datetime.now() - timedelta(days=7)).isoformat(),
            "updated_at": (datetime.now() - timedelta(hours=2)).isoformat(),
            "local_authority": "Manchester City Council",
            "site_area": 2.5,
            "units_proposed": 24,
            "latitude": 53.4808,
            "longitude": -2.2426
        },
        {
            "id": "proj_002", 
            "name": "Commercial Hub - City Centre",
            "address": "45 Market Street, Leeds, LS1 3AB",
            "type": "commercial",
            "status": "submitted",
            "ai_score": 65,
            "document_count": 8,
            "created_at": (datetime.now() - timedelta(days=14)).isoformat(),
            "updated_at": (datetime.now() - timedelta(days=3)).isoformat(),
            "local_authority": "Leeds City Council",
            "site_area": 1.2,
            "units_proposed": 0,
            "latitude": 53.7997,
            "longitude": -1.5492
        },
        {
            "id": "proj_003",
            "name": "Mixed Use Development - Riverside",
            "address": "78 Riverside Drive, Birmingham, B2 4AB",
            "type": "mixed_use",
            "status": "under_review",
            "ai_score": 82,
            "document_count": 12,
            "created_at": (datetime.now() - timedelta(days=21)).isoformat(),
            "updated_at": (datetime.now() - timedelta(days=1)).isoformat(),
            "local_authority": "Birmingham City Council",
            "site_area": 3.8,
            "units_proposed": 45,
            "latitude": 52.4862,
            "longitude": -1.8904
        }
    ]
    
    # Apply filters
    filtered_projects = projects
    
    if search:
        search_lower = search.lower()
        filtered_projects = [
            p for p in filtered_projects 
            if search_lower in p["name"].lower() or search_lower in p["address"].lower()
        ]
    
    if status:
        filtered_projects = [p for p in filtered_projects if p["status"] == status]
    
    if type:
        filtered_projects = [p for p in filtered_projects if p["type"] == type]
    
    # Apply pagination
    total = len(filtered_projects)
    filtered_projects = filtered_projects[offset:offset + limit]
    
    return {
        "projects": filtered_projects,
        "total": total,
        "limit": limit,
        "offset": offset
    }

@app.post("/api/projects")
async def create_project(project_data: dict):
    """Create a new project"""
    # TODO: Add proper validation and database storage
    # For now, return a mock response
    project_id = f"proj_{len(project_data.get('name', '').split())}{datetime.now().timestamp():.0f}"
    
    # Simulate project creation
    new_project = {
        "id": project_id,
        "name": project_data.get("name"),
        "address": project_data.get("address"),
        "type": project_data.get("type"),
        "status": project_data.get("status", "planning"),
        "description": project_data.get("description"),
        "local_authority": project_data.get("local_authority"),
        "site_area": project_data.get("site_area"),
        "units_proposed": project_data.get("units_proposed"),
        "floors": project_data.get("floors"),
        "parking_spaces": project_data.get("parking_spaces"),
        "latitude": project_data.get("latitude"),
        "longitude": project_data.get("longitude"),
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat(),
        "ai_score": None,
        "document_count": 0
    }
    
    return new_project

@app.get("/api/projects/{project_id}")
async def get_project(project_id: str):
    """Get a specific project by ID"""
    # Mock project data - in production this would query the database
    mock_projects = {
        "proj_001": {
            "id": "proj_001",
            "name": "Residential Development - Oak Street",
            "address": "123 Oak Street, Manchester, M1 2AB",
            "type": "residential",
            "status": "planning",
            "description": "A sustainable residential development featuring 24 affordable housing units with integrated green spaces and sustainable transport links.",
            "ai_score": 78,
            "document_count": 5,
            "created_at": (datetime.now() - timedelta(days=7)).isoformat(),
            "updated_at": (datetime.now() - timedelta(hours=2)).isoformat(),
            "local_authority": "Manchester City Council",
            "site_area": 2.5,
            "units_proposed": 24,
            "floors": 3,
            "parking_spaces": 18,
            "latitude": 53.4808,
            "longitude": -2.2426,
            "estimated_timeline": "18-24 months"
        }
    }
    
    if project_id not in mock_projects:
        raise HTTPException(status_code=404, detail="Project not found")
    
    return mock_projects[project_id]

@app.get("/api/projects/{project_id}/activity")
async def get_project_activity(project_id: str):
    """Get activity timeline for a project"""
    activity = [
        {
            "id": 1,
            "description": "Project created",
            "timestamp": (datetime.now() - timedelta(days=7)).isoformat(),
            "icon": "plus-circle"
        },
        {
            "id": 2,
            "description": "Site survey completed and uploaded",
            "timestamp": (datetime.now() - timedelta(days=5)).isoformat(),
            "icon": "file-upload"
        },
        {
            "id": 3,
            "description": "AI analysis completed - 78% approval probability",
            "timestamp": (datetime.now() - timedelta(days=3)).isoformat(),
            "icon": "brain"
        },
        {
            "id": 4,
            "description": "Planning documents generated",
            "timestamp": (datetime.now() - timedelta(hours=6)).isoformat(),
            "icon": "file-plus"
        }
    ]
    
    return activity

@app.get("/api/projects/{project_id}/ai-analysis")
async def get_project_ai_analysis(project_id: str):
    """Get AI analysis for a project"""
    analysis = {
        "score": 78,
        "positive_factors": [
            "Site located within designated development area",
            "Adequate transport infrastructure nearby",
            "Meets local housing density requirements",
            "Environmental impact assessment favorable"
        ],
        "risk_factors": [
            "Site partially within flood risk zone 2",
            "Heritage building 200m away - potential constraints",
            "Local parking capacity may be insufficient"
        ],
        "recommendations": [
            "Include sustainable drainage system (SuDS)",
            "Consider heritage impact assessment",
            "Propose additional cycle parking",
            "Engage early with local community"
        ],
        "policy_context": "The development aligns with the Local Plan's objectives for sustainable housing delivery. Key policy considerations include LP-H1 (Housing Delivery), LP-E3 (Environmental Protection), and LP-T2 (Transport Infrastructure). The site's location supports the council's strategic housing objectives while maintaining environmental standards."
    }
    
    return analysis

@app.get("/api/projects/{project_id}/documents")
async def get_project_documents(project_id: str):
    """Get documents for a project"""
    documents = [
        {
            "id": "doc_001",
            "name": "Site Survey Report",
            "type": "pdf",
            "size": "2.3 MB",
            "uploaded_at": (datetime.now() - timedelta(days=5)).isoformat()
        },
        {
            "id": "doc_002",
            "name": "Planning Application Form",
            "type": "pdf",
            "size": "1.8 MB", 
            "uploaded_at": (datetime.now() - timedelta(days=3)).isoformat()
        },
        {
            "id": "doc_003",
            "name": "Site Plans",
            "type": "dwg",
            "size": "5.2 MB",
            "uploaded_at": (datetime.now() - timedelta(days=2)).isoformat()
        },
        {
            "id": "doc_004",
            "name": "Environmental Impact Assessment",
            "type": "docx",
            "size": "3.1 MB",
            "uploaded_at": (datetime.now() - timedelta(hours=12)).isoformat()
        }
    ]
    
    return documents

@app.get("/api/projects/{project_id}/timeline")
async def get_project_timeline(project_id: str):
    """Get project timeline/milestones"""
    timeline = [
        {
            "title": "Project Initiation",
            "description": "Project created and initial data entered",
            "date": (datetime.now() - timedelta(days=7)).isoformat(),
            "completed": True
        },
        {
            "title": "Site Analysis",
            "description": "Site survey, constraints analysis, and AI assessment",
            "date": (datetime.now() - timedelta(days=3)).isoformat(),
            "completed": True
        },
        {
            "title": "Document Preparation",
            "description": "Planning application documents generation",
            "date": datetime.now().isoformat(),
            "completed": False
        },
        {
            "title": "Planning Submission",
            "description": "Submit planning application to local authority",
            "date": (datetime.now() + timedelta(days=14)).isoformat(),
            "completed": False
        },
        {
            "title": "Authority Review",
            "description": "Local authority review and consultation period",
            "date": (datetime.now() + timedelta(days=28)).isoformat(),
            "completed": False
        },
        {
            "title": "Decision",
            "description": "Planning decision received",
            "date": (datetime.now() + timedelta(days=56)).isoformat(),
            "completed": False
        }
    ]
    
    return timeline

# Planning AI and Constraints API
@app.get("/api/planning/constraints")
async def get_planning_constraints(lat: float, lng: float):
    """Get planning constraints for a location"""
    # Mock constraints data - in production this would query GIS services
    constraints = [
        {
            "name": "Conservation Area",
            "icon": "landmark",
            "severity": "medium",
            "distance": "150m away"
        },
        {
            "name": "Flood Risk Zone 2",
            "icon": "water",
            "severity": "high", 
            "distance": "Site partially affected"
        },
        {
            "name": "Green Belt",
            "icon": "tree",
            "severity": "low",
            "distance": "500m away"
        },
        {
            "name": "Tree Preservation Order",
            "icon": "leaf",
            "severity": "medium",
            "distance": "3 protected trees on site"
        }
    ]
    
    return constraints

@app.post("/api/planning/ai-analysis")
async def get_planning_ai_analysis(project_data: dict):
    """Get AI analysis for project data"""
    # Mock AI analysis - in production this would call actual AI service
    base_score = 60
    
    # Adjust score based on project characteristics
    score_adjustments = 0
    factors = []
    
    # Type adjustments
    if project_data.get("type") == "residential":
        score_adjustments += 10
        factors.append("residential development priority")
    elif project_data.get("type") == "affordable_housing":
        score_adjustments += 15
        factors.append("affordable housing need")
    
    # Size adjustments
    units = int(project_data.get("units_proposed", 0))
    if units > 0 and units <= 50:
        score_adjustments += 5
        factors.append("appropriate development scale")
    
    # Site area
    site_area = float(project_data.get("site_area", 0))
    if site_area > 0 and site_area < 5:
        score_adjustments += 8
        factors.append("suitable site size")
    
    final_score = min(100, base_score + score_adjustments)
    
    analysis = {
        "score": final_score,
        "factors": factors,
        "recommendations": "Consider sustainable design features and early community engagement"
    }
    
    return analysis

# ================================
# COMMUNICATIONS HUB SYSTEM
# ================================

class MessageRequest(BaseModel):
    to: str
    cc: Optional[str] = None
    subject: str
    message: str
    priority: str = "normal"
    attachments: Optional[List[str]] = []

class ConsultationRequest(BaseModel):
    title: str
    description: str
    consultation_type: str
    start_date: str
    end_date: str
    stakeholders: List[str]

class MeetingRequest(BaseModel):
    title: str
    description: str
    meeting_type: str
    date: str
    time: str
    duration: int
    attendees: List[str]
    location: str

@app.get("/communications-hub")
async def communications_hub(request: Request):
    """Communications Hub main page"""
    return templates.TemplateResponse("communications_hub.html", {"request": request})

@app.get("/communications")
async def communications(request: Request):
    """Communications alias route"""
    return templates.TemplateResponse("communications_hub.html", {"request": request})

@app.get("/api/communications/inbox")
async def get_inbox_messages():
    """Get inbox messages with filtering and pagination"""
    try:
        messages = [
            {
                "id": 1,
                "sender": "Sarah Johnson",
                "sender_email": "sarah.johnson@council.gov.uk",
                "avatar": "/api/placeholder/32/32",
                "subject": "Planning Application Update - Riverside Development",
                "preview": "The council has requested additional information for the Riverside Development project. We need to provide an updated flood risk assessment and transport impact study by Friday 15th November.",
                "content": """
                <p>Dear Planning Team,</p>
                <p>Following our review of the Riverside Development planning application (Ref: 2024/PL/001234), the planning committee has requested the following additional information:</p>
                <ul>
                    <li>Updated flood risk assessment incorporating latest Environment Agency data</li>
                    <li>Comprehensive transport impact study including junction capacity analysis</li>
                    <li>Biodiversity enhancement plan with specific net gain calculations</li>
                    <li>Community benefit statement addressing local concerns</li>
                </ul>
                <p>Please provide these documents by <strong>Friday 15th November 2024</strong> to maintain the application timeline.</p>
                <p>The next planning committee meeting is scheduled for 28th November where this application will be considered.</p>
                <p>Please don't hesitate to contact me if you need any clarification on these requirements.</p>
                <p>Best regards,<br>Sarah Johnson<br>Senior Planning Officer<br>Planning Department</p>
                """,
                "time": "10:30 AM",
                "date": "Today",
                "read": False,
                "urgent": True,
                "online": True,
                "attachments": 2,
                "attachment_list": [
                    {"name": "Additional_Info_Request.pdf", "size": "245 KB", "type": "pdf"},
                    {"name": "Committee_Schedule.pdf", "size": "156 KB", "type": "pdf"}
                ],
                "thread_id": "thread_001",
                "labels": ["Planning", "Urgent", "Council"]
            },
            {
                "id": 2,
                "sender": "Michael Brown",
                "sender_email": "m.brown@greenvallcy.co.uk",
                "avatar": "/api/placeholder/32/32",
                "subject": "Site Visit Confirmation - Green Valley Project",
                "preview": "Confirming our site visit scheduled for tomorrow at 2:00 PM for the Green Valley residential development. Please bring the latest architectural drawings and ecological survey results.",
                "content": """
                <p>Hi Team,</p>
                <p>Just confirming our site visit scheduled for <strong>tomorrow (Thursday) at 2:00 PM</strong> for the Green Valley project site assessment.</p>
                <p><strong>Meeting Details:</strong></p>
                <ul>
                    <li><strong>Location:</strong> Green Valley Site Office, Meadow Lane entrance</li>
                    <li><strong>Duration:</strong> Approximately 2 hours</li>
                    <li><strong>Purpose:</strong> Pre-application site assessment and constraint identification</li>
                </ul>
                <p><strong>Please bring:</strong></p>
                <ul>
                    <li>Latest architectural drawings (scaled prints)</li>
                    <li>Ecological survey results</li>
                    <li>Topographical survey data</li>
                    <li>PPE (hard hat, hi-vis, safety boots)</li>
                </ul>
                <p>We'll be meeting with the site manager and ecological consultant to discuss habitat management and construction phasing.</p>
                <p>Weather forecast looks clear, but please bring waterproofs just in case.</p>
                <p>Looking forward to seeing you there.</p>
                <p>Best regards,<br>Michael Brown<br>Project Manager<br>Green Valley Developments</p>
                """,
                "time": "9:15 AM",
                "date": "Today",
                "read": True,
                "urgent": False,
                "online": False,
                "attachments": 1,
                "attachment_list": [
                    {"name": "Site_Access_Map.pdf", "size": "890 KB", "type": "pdf"}
                ],
                "thread_id": "thread_002",
                "labels": ["Site Visit", "Client", "Green Valley"]
            },
            {
                "id": 3,
                "sender": "Emma Wilson",
                "sender_email": "emma@biodiversityoffsets.com",
                "avatar": "/api/placeholder/32/32",
                "subject": "BNG Credits Available - Westminster Commercial Development",
                "preview": "New biodiversity net gain credits are now available for the Westminster project. High-quality grassland and woodland habitats with excellent provider ratings and competitive pricing.",
                "content": """
                <p>Hello,</p>
                <p>I wanted to let you know that we have new biodiversity credits available that would be perfect for your Westminster Commercial Development project.</p>
                <p><strong>Available Credits:</strong></p>
                <ul>
                    <li><strong>Grassland Units:</strong> 15.8 units available at Â£12,200 per unit</li>
                    <li><strong>Woodland Units:</strong> 8.3 units available at Â£15,800 per unit</li>
                    <li><strong>Location:</strong> Within 5km of your development site</li>
                    <li><strong>Provider Rating:</strong> â­â­â­â­â­ (Excellent - 4.9/5)</li>
                </ul>
                <p><strong>Site Features:</strong></p>
                <ul>
                    <li>30-year management plan in place</li>
                    <li>Independent ecological monitoring</li>
                    <li>S106 agreement already secured</li>
                    <li>Local community engagement program</li>
                </ul>
                <p>These credits are in high demand due to their proximity to London and excellent habitat condition. I'd recommend securing them soon if they meet your requirements.</p>
                <p>I can arrange a site visit next week if you'd like to see the habitat creation work in progress.</p>
                <p>Please let me know if you need any additional information or would like to proceed with the purchase.</p>
                <p>Kind regards,<br>Emma Wilson<br>Senior Biodiversity Consultant<br>Biodiversity Offsets Ltd</p>
                """,
                "time": "2:45 PM",
                "date": "Yesterday",
                "read": False,
                "urgent": False,
                "online": True,
                "attachments": 3,
                "attachment_list": [
                    {"name": "BNG_Credits_Specification.pdf", "size": "1.2 MB", "type": "pdf"},
                    {"name": "Site_Photos.pdf", "size": "3.8 MB", "type": "pdf"},
                    {"name": "Management_Plan_Summary.pdf", "size": "654 KB", "type": "pdf"}
                ],
                "thread_id": "thread_003",
                "labels": ["BNG", "Credits", "Westminster"]
            }
        ]
        
        return {
            "success": True,
            "messages": messages,
            "total_count": len(messages),
            "unread_count": len([m for m in messages if not m["read"]]),
            "urgent_count": len([m for m in messages if m["urgent"]])
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch messages: {str(e)}")

@app.post("/api/communications/send-message")
async def send_message(message_request: MessageRequest):
    """Send a new message"""
    try:
        import re
        email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if not re.match(email_pattern, message_request.to):
            raise HTTPException(status_code=400, detail="Invalid email address")
        
        message_id = f"msg_{int(time.time())}"
        
        return {
            "success": True,
            "message_id": message_id,
            "sent_to": message_request.to,
            "subject": message_request.subject,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "delivery_status": "Sent",
            "priority_level": message_request.priority
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to send message: {str(e)}")

@app.get("/api/communications/templates")
async def get_message_templates():
    """Get message templates for quick composition"""
    try:
        templates = [
            {
                "id": 1,
                "name": "Welcome New Client",
                "description": "Initial welcome message for new planning clients",
                "category": "Client Management",
                "subject": "Welcome to Domus Planning Services",
                "content": "Dear [CLIENT_NAME],\n\nWelcome to Domus Planning Services. We're delighted to be working with you on your [PROJECT_TYPE] project.\n\nYour dedicated planning consultant is [CONSULTANT_NAME], who will be your main point of contact throughout the planning process.\n\nNext Steps:\nâ€¢ Initial consultation call scheduled for [DATE]\nâ€¢ Document review and site assessment\nâ€¢ Strategy development and timeline planning\nâ€¢ Regular progress updates and communication\n\nWe're committed to achieving the best possible outcome for your project. Please don't hesitate to contact us with any questions.\n\nBest regards,\nThe Domus Planning Team"
            },
            {
                "id": 2,
                "name": "Application Status Update",
                "description": "Regular update on planning application progress", 
                "category": "Application Management",
                "subject": "Planning Application Update - [PROJECT_NAME]",
                "content": "Dear [CLIENT_NAME],\n\nI wanted to update you on the progress of your planning application for [PROJECT_NAME] (Application Ref: [APP_REF]).\n\nCurrent Status: [STATUS]\n\nRecent Progress:\nâ€¢ [RECENT_ACTION_1]\nâ€¢ [RECENT_ACTION_2]\nâ€¢ [RECENT_ACTION_3]\n\nNext Steps:\nâ€¢ [NEXT_ACTION_1] - Target date: [DATE_1]\nâ€¢ [NEXT_ACTION_2] - Target date: [DATE_2]\n\nEstimated Timeline: [TIMELINE]\n\nPlease let me know if you have any questions or concerns.\n\nBest regards,\n[CONSULTANT_NAME]"
            }
        ]
        
        return {
            "success": True,
            "templates": templates,
            "categories": list(set([t["category"] for t in templates]))
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch templates: {str(e)}")

@app.get("/api/communications/consultations")
async def get_consultations():
    """Get active and upcoming public consultations"""
    try:
        consultations = [
            {
                "id": 1,
                "title": "Riverside Development Public Consultation",
                "description": "Mixed-use development comprising 50 residential units, ground floor commercial space, and community facilities including public green space and children's playground.",
                "status": "Active",
                "consultation_type": "Public",
                "start_date": "2024-10-01",
                "end_date": "2024-11-15",
                "closing_date": "15 Nov 2024",
                "responses": 23,
                "location": "Riverside Quarter, Meadowbank"
            },
            {
                "id": 2,
                "title": "Green Valley Homes Community Feedback",
                "description": "Affordable housing development with 75 units including 30% affordable homes, community centre, and enhanced public transport links.",
                "status": "Closing Soon",
                "consultation_type": "Stakeholder",
                "start_date": "2024-09-20",
                "end_date": "2024-10-08",
                "closing_date": "8 Oct 2024",
                "responses": 47,
                "location": "Green Valley, Westside"
            }
        ]
        
        return {
            "success": True,
            "consultations": consultations,
            "summary": {
                "active": len([c for c in consultations if c["status"] == "Active"]),
                "closing_soon": len([c for c in consultations if c["status"] == "Closing Soon"])
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch consultations: {str(e)}")

@app.post("/api/communications/create-consultation")
async def create_consultation(consultation_request: ConsultationRequest):
    """Create a new public consultation"""
    try:
        consultation_id = f"CONS_{int(time.time())}"
        
        return {
            "success": True,
            "consultation_id": consultation_id,
            "consultation": {
                "title": consultation_request.title,
                "description": consultation_request.description,
                "type": consultation_request.consultation_type,
                "start_date": consultation_request.start_date,
                "end_date": consultation_request.end_date,
                "stakeholders": consultation_request.stakeholders
            },
            "automated_actions": [
                "Stakeholder notification emails scheduled",
                "Consultation webpage created",
                "Calendar reminders set",
                "Progress tracking initiated"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create consultation: {str(e)}")

@app.get("/api/communications/calendar")
async def get_calendar_events():
    """Get upcoming calendar events and meetings"""
    try:
        events = [
            {
                "id": 1,
                "title": "Client Meeting - Riverside Development",
                "description": "Project review and next steps discussion",
                "type": "Client Meeting",
                "time": "Today, 2:00 PM",
                "location": "Office",
                "attendees": 4
            },
            {
                "id": 2,
                "title": "Council Planning Committee",
                "description": "Green Valley Homes application presentation",
                "type": "Council Meeting", 
                "time": "Tomorrow, 10:00 AM",
                "location": "Town Hall",
                "attendees": 12
            }
        ]
        
        return {
            "success": True,
            "events": events,
            "summary": {
                "total_events": len(events),
                "this_week": len(events),
                "client_meetings": len([e for e in events if e["type"] == "Client Meeting"])
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch calendar events: {str(e)}")

@app.post("/api/communications/schedule-meeting")
async def schedule_meeting(meeting_request: MeetingRequest):
    """Schedule a new meeting"""
    try:
        meeting_id = f"MTG_{int(time.time())}"
        
        return {
            "success": True,
            "meeting_id": meeting_id,
            "meeting": {
                "title": meeting_request.title,
                "description": meeting_request.description,
                "type": meeting_request.meeting_type,
                "date": meeting_request.date,
                "time": meeting_request.time,
                "duration": meeting_request.duration,
                "location": meeting_request.location,
                "attendees": meeting_request.attendees
            },
            "automated_actions": [
                "Calendar invitations sent to all attendees",
                "Meeting room booked (if office location)",
                "Reminder notifications scheduled"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to schedule meeting: {str(e)}")

@app.get("/api/communications/automation-stats")
async def get_automation_stats():
    """Get communications automation statistics"""
    try:
        stats = {
            "email_automation": {
                "total_sent": 1247,
                "this_month": 342,
                "delivery_rate": 94.2,
                "open_rate": 68.5,
                "automation_savings": "24.5 hours"
            },
            "consultation_automation": {
                "active_consultations": 5,
                "automated_reminders": 89,
                "response_tracking": "Real-time",
                "stakeholder_notifications": 156
            },
            "calendar_automation": {
                "meetings_scheduled": 78,
                "automatic_reminders": 234,
                "room_bookings": 45,
                "calendar_conflicts": 3
            }
        }
        
        return {
            "success": True,
            "stats": stats,
            "performance": {
                "efficiency_gain": "35% time saving",
                "accuracy_improvement": "92% reduction in missed communications",
                "client_satisfaction": "4.8/5 communication rating"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch automation stats: {str(e)}")

# ================================
# DOCUMENT MANAGEMENT SYSTEM
# ================================

class DocumentUpload(BaseModel):
    filename: str
    file_type: str
    file_size: int
    folder_id: Optional[str] = None
    description: Optional[str] = None

class DocumentShare(BaseModel):
    document_id: str
    user_emails: List[str]
    permission_level: str = "view"  # view, edit, admin
    message: Optional[str] = None

class WorkflowCreate(BaseModel):
    name: str
    document_type: str
    steps: List[dict]
    auto_assign: bool = False

class FolderCreate(BaseModel):
    name: str
    parent_id: Optional[str] = None
    description: Optional[str] = None

@app.get("/document-management")
async def document_management(request: Request):
    """Document Management main page"""
    return templates.TemplateResponse("document_management.html", {"request": request})

@app.get("/api/documents/library")
async def get_document_library():
    """Get document library with folder structure and files"""
    try:
        folder_structure = [
            {
                "id": "folder_001",
                "name": "Planning Applications",
                "count": 245,
                "expanded": True,
                "parent_id": None,
                "created_date": "2024-01-15",
                "modified_date": "2024-10-03",
                "children": [
                    {
                        "id": "folder_011",
                        "name": "Residential",
                        "count": 156,
                        "parent_id": "folder_001",
                        "description": "Residential development applications"
                    },
                    {
                        "id": "folder_012", 
                        "name": "Commercial",
                        "count": 67,
                        "parent_id": "folder_001",
                        "description": "Commercial development applications"
                    },
                    {
                        "id": "folder_013",
                        "name": "Mixed Use",
                        "count": 22,
                        "parent_id": "folder_001",
                        "description": "Mixed-use development applications"
                    }
                ]
            },
            {
                "id": "folder_002",
                "name": "Technical Reports",
                "count": 189,
                "expanded": False,
                "parent_id": None,
                "created_date": "2024-01-20",
                "modified_date": "2024-09-28",
                "children": [
                    {
                        "id": "folder_021",
                        "name": "Environmental",
                        "count": 89,
                        "parent_id": "folder_002",
                        "description": "Environmental impact assessments"
                    },
                    {
                        "id": "folder_022",
                        "name": "Transport",
                        "count": 56,
                        "parent_id": "folder_002",
                        "description": "Transport and traffic studies"
                    },
                    {
                        "id": "folder_023",
                        "name": "Heritage",
                        "count": 44,
                        "parent_id": "folder_002",
                        "description": "Heritage and archaeological assessments"
                    }
                ]
            },
            {
                "id": "folder_003",
                "name": "Legal Documents",
                "count": 134,
                "expanded": False,
                "parent_id": None,
                "created_date": "2024-02-01",
                "modified_date": "2024-09-25",
                "children": [
                    {
                        "id": "folder_031",
                        "name": "Contracts",
                        "count": 78,
                        "parent_id": "folder_003",
                        "description": "Client contracts and agreements"
                    },
                    {
                        "id": "folder_032",
                        "name": "Legal Opinions",
                        "count": 56,
                        "parent_id": "folder_003",
                        "description": "Legal advice and opinions"
                    }
                ]
            },
            {
                "id": "folder_004",
                "name": "Client Communications",
                "count": 298,
                "expanded": False,
                "parent_id": None,
                "created_date": "2024-01-10",
                "modified_date": "2024-10-03",
                "children": [
                    {
                        "id": "folder_041",
                        "name": "Correspondence",
                        "count": 156,
                        "parent_id": "folder_004",
                        "description": "Email and letter correspondence"
                    },
                    {
                        "id": "folder_042",
                        "name": "Meeting Notes",
                        "count": 142,
                        "parent_id": "folder_004",
                        "description": "Meeting minutes and notes"
                    }
                ]
            }
        ]
        
        documents = [
            {
                "id": "doc_001",
                "name": "Riverside Development - Planning Application",
                "file_type": "pdf",
                "file_size": "2.4 MB",
                "file_size_bytes": 2516582,
                "description": "Complete planning application for 50-unit residential development with supporting documents",
                "status": "Approved",
                "last_modified": "2024-10-03T14:30:00Z",
                "created_date": "2024-09-15T09:00:00Z",
                "version": "3.2",
                "has_new_version": False,
                "folder_id": "folder_011",
                "download_url": "/api/documents/doc_001/download",
                "preview_url": "/api/documents/doc_001/preview",
                "collaborators": [
                    {
                        "id": "user_001",
                        "name": "Sarah Johnson",
                        "email": "sarah@domus.com",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Lead Planner",
                        "last_accessed": "2024-10-03T14:30:00Z"
                    },
                    {
                        "id": "user_002", 
                        "name": "Michael Brown",
                        "email": "michael@domus.com",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Senior Consultant",
                        "last_accessed": "2024-10-03T12:15:00Z"
                    },
                    {
                        "id": "user_003",
                        "name": "Emma Wilson",
                        "email": "emma@domus.com",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Associate Planner",
                        "last_accessed": "2024-10-02T16:45:00Z"
                    }
                ],
                "tags": ["residential", "planning", "approved"],
                "access_permissions": {
                    "can_download": True,
                    "can_edit": True,
                    "can_share": True,
                    "can_delete": False
                }
            },
            {
                "id": "doc_002",
                "name": "Transport Assessment Report - Green Valley",
                "file_type": "docx",
                "file_size": "1.8 MB", 
                "file_size_bytes": 1887436,
                "description": "Comprehensive transport impact assessment including junction capacity analysis and parking provision",
                "status": "Pending Review",
                "last_modified": "2024-10-02T11:20:00Z",
                "created_date": "2024-09-28T14:00:00Z",
                "version": "2.1",
                "has_new_version": True,
                "folder_id": "folder_022",
                "download_url": "/api/documents/doc_002/download",
                "preview_url": "/api/documents/doc_002/preview",
                "collaborators": [
                    {
                        "id": "user_004",
                        "name": "David Chen",
                        "email": "david@transport.co.uk",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Transport Consultant",
                        "last_accessed": "2024-10-02T11:20:00Z"
                    },
                    {
                        "id": "user_005",
                        "name": "Lisa Park",
                        "email": "lisa@domus.com",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Project Manager",
                        "last_accessed": "2024-10-01T15:30:00Z"
                    }
                ],
                "tags": ["transport", "assessment", "pending"],
                "access_permissions": {
                    "can_download": True,
                    "can_edit": True,
                    "can_share": True,
                    "can_delete": False
                }
            },
            {
                "id": "doc_003",
                "name": "Architectural Plans - City Centre Plaza",
                "file_type": "dwg",
                "file_size": "15.6 MB",
                "file_size_bytes": 16351436,
                "description": "Complete architectural drawings including site plans, floor plans, elevations, and sections",
                "status": "Draft",
                "last_modified": "2024-09-30T16:45:00Z",
                "created_date": "2024-09-20T10:00:00Z",
                "version": "1.5",
                "has_new_version": False,
                "folder_id": "folder_012",
                "download_url": "/api/documents/doc_003/download",
                "preview_url": "/api/documents/doc_003/preview",
                "collaborators": [
                    {
                        "id": "user_006",
                        "name": "Tom Wilson",
                        "email": "tom@architects.co.uk",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Architect",
                        "last_accessed": "2024-09-30T16:45:00Z"
                    },
                    {
                        "id": "user_007",
                        "name": "Amy Rodriguez",
                        "email": "amy@domus.com",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Design Coordinator",
                        "last_accessed": "2024-09-30T14:20:00Z"
                    }
                ],
                "tags": ["architecture", "plans", "draft"],
                "access_permissions": {
                    "can_download": True,
                    "can_edit": True,
                    "can_share": False,
                    "can_delete": True
                }
            },
            {
                "id": "doc_004",
                "name": "Environmental Impact Assessment",
                "file_type": "pdf",
                "file_size": "4.2 MB",
                "file_size_bytes": 4404019,
                "description": "Detailed environmental assessment covering ecology, air quality, noise, and contamination",
                "status": "Approved",
                "last_modified": "2024-09-25T13:10:00Z",
                "created_date": "2024-08-15T09:30:00Z",
                "version": "2.3",
                "has_new_version": False,
                "folder_id": "folder_021",
                "download_url": "/api/documents/doc_004/download",
                "preview_url": "/api/documents/doc_004/preview",
                "collaborators": [
                    {
                        "id": "user_008",
                        "name": "Rachel Green",
                        "email": "rachel@environmental.co.uk",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Environmental Consultant",
                        "last_accessed": "2024-09-25T13:10:00Z"
                    },
                    {
                        "id": "user_009",
                        "name": "Mark Johnson",
                        "email": "mark@domus.com",
                        "avatar": "/api/placeholder/32/32",
                        "role": "Senior Associate",
                        "last_accessed": "2024-09-24T11:45:00Z"
                    }
                ],
                "tags": ["environmental", "assessment", "approved"],
                "access_permissions": {
                    "can_download": True,
                    "can_edit": False,
                    "can_share": True,
                    "can_delete": False
                }
            }
        ]
        
        return {
            "success": True,
            "folder_structure": folder_structure,
            "documents": documents,
            "statistics": {
                "total_documents": len(documents),
                "total_folders": sum(len(folder["children"]) for folder in folder_structure) + len(folder_structure),
                "storage_used": "24.0 MB",
                "storage_used_bytes": 25159473,
                "storage_limit": "100 GB",
                "storage_limit_bytes": 107374182400
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch document library: {str(e)}")

@app.post("/api/documents/upload")
async def upload_document(document: DocumentUpload):
    """Upload a new document"""
    try:
        document_id = f"doc_{int(time.time())}"
        
        # Validate file type
        allowed_types = ['pdf', 'docx', 'xlsx', 'pptx', 'dwg', 'txt', 'jpg', 'png']
        if document.file_type not in allowed_types:
            raise HTTPException(status_code=400, detail=f"File type {document.file_type} not allowed")
        
        # Check file size (50MB limit)
        if document.file_size > 52428800:  # 50MB in bytes
            raise HTTPException(status_code=400, detail="File size exceeds 50MB limit")
        
        # Generate file processing workflow
        processing_steps = []
        if document.file_type == 'pdf':
            processing_steps.extend([
                "Text extraction and indexing",
                "Thumbnail generation",
                "Metadata extraction"
            ])
        elif document.file_type in ['docx', 'xlsx', 'pptx']:
            processing_steps.extend([
                "Office document conversion",
                "Content analysis", 
                "Version tracking setup"
            ])
        elif document.file_type == 'dwg':
            processing_steps.extend([
                "CAD file validation",
                "Drawing preview generation",
                "Layer analysis"
            ])
        
        return {
            "success": True,
            "document_id": document_id,
            "upload_status": "Processing",
            "filename": document.filename,
            "file_type": document.file_type,
            "file_size": document.file_size,
            "folder_id": document.folder_id,
            "description": document.description,
            "processing_steps": processing_steps,
            "estimated_completion": "2-5 minutes",
            "upload_url": f"/api/documents/{document_id}/content",
            "preview_available": "After processing",
            "auto_actions": [
                "Document indexed for search",
                "Virus scan initiated",
                "Backup copy created",
                "Access permissions inherited from folder"
            ],
            "next_steps": [
                "Complete file upload via upload_url",
                "Add document tags and metadata",
                "Configure sharing permissions",
                "Set up approval workflow if required"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to process upload: {str(e)}")

@app.get("/api/documents/templates")
async def get_document_templates():
    """Get available document templates"""
    try:
        templates = [
            {
                "id": "template_001",
                "name": "Planning Application Template",
                "description": "Comprehensive template for UK planning applications including all required sections and guidance",
                "category": "Planning Applications",
                "file_type": "docx",
                "file_size": "145 KB",
                "downloads": 234,
                "rating": 4.8,
                "last_updated": "2024-09-15",
                "created_by": "Domus Planning Team",
                "preview_url": "/api/templates/template_001/preview",
                "download_url": "/api/templates/template_001/download",
                "variables": [
                    "APPLICATION_SITE",
                    "APPLICANT_NAME", 
                    "PROPOSAL_DESCRIPTION",
                    "LOCAL_AUTHORITY",
                    "SUBMISSION_DATE"
                ],
                "sections": [
                    "Application Form",
                    "Design & Access Statement",
                    "Planning Statement",
                    "Supporting Documents Checklist"
                ]
            },
            {
                "id": "template_002",
                "name": "Design & Access Statement Template",
                "description": "Professional D&A statement template complying with latest planning requirements",
                "category": "Planning Applications",
                "file_type": "docx",
                "file_size": "89 KB",
                "downloads": 189,
                "rating": 4.6,
                "last_updated": "2024-08-22",
                "created_by": "Urban Design Specialists",
                "preview_url": "/api/templates/template_002/preview",
                "download_url": "/api/templates/template_002/download",
                "variables": [
                    "SITE_CONTEXT",
                    "DESIGN_PRINCIPLES",
                    "ACCESS_STRATEGY",
                    "SUSTAINABILITY_MEASURES"
                ],
                "sections": [
                    "Site Analysis",
                    "Design Evolution",
                    "Access Arrangements",
                    "Sustainability"
                ]
            },
            {
                "id": "template_003",
                "name": "Heritage Statement Template",
                "description": "Comprehensive heritage assessment template for conservation areas and listed buildings",
                "category": "Technical Reports",
                "file_type": "docx",
                "file_size": "112 KB",
                "downloads": 156,
                "rating": 4.9,
                "last_updated": "2024-09-01",
                "created_by": "Heritage Consultants Ltd",
                "preview_url": "/api/templates/template_003/preview",
                "download_url": "/api/templates/template_003/download",
                "variables": [
                    "HERITAGE_ASSETS",
                    "SIGNIFICANCE_ASSESSMENT",
                    "IMPACT_EVALUATION",
                    "MITIGATION_MEASURES"
                ],
                "sections": [
                    "Heritage Baseline",
                    "Significance Assessment",
                    "Impact Analysis",
                    "Mitigation Strategy"
                ]
            },
            {
                "id": "template_004",
                "name": "Transport Assessment Template",
                "description": "Traffic impact assessment template with calculation spreadsheets",
                "category": "Technical Reports",
                "file_type": "xlsx",
                "file_size": "234 KB",
                "downloads": 145,
                "rating": 4.7,
                "last_updated": "2024-09-10",
                "created_by": "Transport Planning Associates",
                "preview_url": "/api/templates/template_004/preview",
                "download_url": "/api/templates/template_004/download",
                "variables": [
                    "DEVELOPMENT_TYPE",
                    "TRIP_GENERATION",
                    "CAPACITY_ANALYSIS",
                    "MITIGATION_PROPOSALS"
                ],
                "sections": [
                    "Baseline Conditions",
                    "Trip Generation",
                    "Impact Assessment",
                    "Mitigation Measures"
                ]
            },
            {
                "id": "template_005",
                "name": "Client Meeting Minutes Template",
                "description": "Professional meeting minutes template for client consultations",
                "category": "Communications",
                "file_type": "docx",
                "file_size": "45 KB",
                "downloads": 298,
                "rating": 4.5,
                "last_updated": "2024-07-30",
                "created_by": "Domus Admin Team",
                "preview_url": "/api/templates/template_005/preview", 
                "download_url": "/api/templates/template_005/download",
                "variables": [
                    "MEETING_DATE",
                    "ATTENDEES",
                    "PROJECT_NAME",
                    "ACTION_ITEMS"
                ],
                "sections": [
                    "Meeting Details",
                    "Discussion Points",
                    "Decisions Made",
                    "Action Items"
                ]
            }
        ]
        
        categories = list(set([template["category"] for template in templates]))
        
        return {
            "success": True,
            "templates": templates,
            "categories": categories,
            "statistics": {
                "total_templates": len(templates),
                "total_downloads": sum(template["downloads"] for template in templates),
                "average_rating": round(sum(template["rating"] for template in templates) / len(templates), 1),
                "most_popular": max(templates, key=lambda x: x["downloads"])["name"]
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch templates: {str(e)}")

@app.get("/api/documents/workflows")
async def get_approval_workflows():
    """Get active approval workflows"""
    try:
        workflows = [
            {
                "id": "workflow_001",
                "document_id": "doc_002",
                "document_name": "Green Valley Transport Assessment",
                "workflow_name": "Technical Review Process",
                "workflow_type": "Technical Review",
                "status": "In Progress",
                "created_date": "2024-10-01T09:00:00Z",
                "due_date": "2024-10-15T17:00:00Z",
                "priority": "High",
                "current_step": 2,
                "total_steps": 4,
                "current_approver": {
                    "id": "user_010",
                    "name": "Sarah Johnson",
                    "email": "sarah@domus.com",
                    "avatar": "/api/placeholder/32/32",
                    "role": "Senior Technical Reviewer"
                },
                "steps": [
                    {
                        "step_number": 1,
                        "name": "Initial Draft",
                        "description": "Document preparation and initial review",
                        "assignee": "David Chen",
                        "status": "Completed",
                        "completed_date": "2024-10-01T14:30:00Z",
                        "comments": "Initial draft completed with all required sections"
                    },
                    {
                        "step_number": 2,
                        "name": "Technical Review",
                        "description": "Senior technical review and validation",
                        "assignee": "Sarah Johnson",
                        "status": "In Progress",
                        "started_date": "2024-10-02T09:00:00Z",
                        "comments": "Under review - some calculations need verification"
                    },
                    {
                        "step_number": 3,
                        "name": "Client Review",
                        "description": "Client feedback and approval",
                        "assignee": "Michael Brown",
                        "status": "Pending",
                        "comments": None
                    },
                    {
                        "step_number": 4,
                        "name": "Final Approval",
                        "description": "Final sign-off and document publication",
                        "assignee": "Emma Wilson",
                        "status": "Pending",
                        "comments": None
                    }
                ],
                "notifications": {
                    "email_reminders": True,
                    "deadline_alerts": True,
                    "status_updates": True
                }
            },
            {
                "id": "workflow_002",
                "document_id": "doc_003",
                "document_name": "City Centre Plaza Architectural Plans",
                "workflow_name": "Design Review Process",
                "workflow_type": "Design Review",
                "status": "Completed",
                "created_date": "2024-09-20T10:00:00Z",
                "due_date": "2024-09-30T17:00:00Z",
                "priority": "Medium",
                "current_step": 4,
                "total_steps": 4,
                "current_approver": {
                    "id": "user_011",
                    "name": "Tom Wilson",
                    "email": "tom@architects.co.uk",
                    "avatar": "/api/placeholder/32/32",
                    "role": "Lead Architect"
                },
                "steps": [
                    {
                        "step_number": 1,
                        "name": "Concept Design",
                        "description": "Initial design concept and layouts",
                        "assignee": "Tom Wilson",
                        "status": "Completed",
                        "completed_date": "2024-09-22T16:00:00Z",
                        "comments": "Concept approved with minor revisions"
                    },
                    {
                        "step_number": 2,
                        "name": "Planning Review",
                        "description": "Planning compliance check",
                        "assignee": "Amy Rodriguez",
                        "status": "Completed",
                        "completed_date": "2024-09-25T11:30:00Z",
                        "comments": "Planning requirements satisfied"
                    },
                    {
                        "step_number": 3,
                        "name": "Technical Review",
                        "description": "Technical feasibility and building regulations",
                        "assignee": "James Taylor",
                        "status": "Completed",
                        "completed_date": "2024-09-28T15:45:00Z",
                        "comments": "Technical aspects approved"
                    },
                    {
                        "step_number": 4,
                        "name": "Final Approval",
                        "description": "Final design approval and documentation",
                        "assignee": "Kate Miller",
                        "status": "Completed",
                        "completed_date": "2024-09-30T16:45:00Z",
                        "comments": "Design approved for planning submission"
                    }
                ],
                "notifications": {
                    "email_reminders": True,
                    "deadline_alerts": False,
                    "status_updates": True
                }
            }
        ]
        
        return {
            "success": True,
            "workflows": workflows,
            "summary": {
                "total_workflows": len(workflows),
                "active_workflows": len([w for w in workflows if w["status"] == "In Progress"]),
                "completed_workflows": len([w for w in workflows if w["status"] == "Completed"]),
                "overdue_workflows": 0,
                "average_completion_time": "8.5 days"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch workflows: {str(e)}")

@app.post("/api/documents/share")
async def share_document(share_request: DocumentShare):
    """Share document with collaborators"""
    try:
        share_id = f"share_{int(time.time())}"
        
        # Validate permission level
        valid_permissions = ["view", "edit", "admin"]
        if share_request.permission_level not in valid_permissions:
            raise HTTPException(status_code=400, detail="Invalid permission level")
        
        # Generate sharing notifications
        notifications = []
        for email in share_request.user_emails:
            notifications.append({
                "recipient": email,
                "type": "document_shared",
                "status": "sent",
                "sent_time": datetime.now().isoformat()
            })
        
        return {
            "success": True,
            "share_id": share_id,
            "document_id": share_request.document_id,
            "shared_with": share_request.user_emails,
            "permission_level": share_request.permission_level,
            "share_url": f"https://domus.com/documents/shared/{share_id}",
            "expiry_date": (datetime.now() + timedelta(days=30)).isoformat(),
            "notifications_sent": len(notifications),
            "notifications": notifications,
            "access_tracking": {
                "track_downloads": True,
                "track_views": True,
                "track_edits": True,
                "email_activity_digest": "Weekly"
            },
            "security_features": [
                "Password protection available",
                "Download restrictions configurable",
                "Access expiry date set",
                "Activity logging enabled"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to share document: {str(e)}")

@app.post("/api/documents/workflows")
async def create_workflow(workflow: WorkflowCreate):
    """Create a new approval workflow"""
    try:
        workflow_id = f"workflow_{int(time.time())}"
        
        # Validate workflow steps
        if not workflow.steps or len(workflow.steps) == 0:
            raise HTTPException(status_code=400, detail="Workflow must have at least one step")
        
        # Process workflow steps
        processed_steps = []
        for i, step in enumerate(workflow.steps):
            processed_steps.append({
                "step_number": i + 1,
                "name": step.get("name", f"Step {i + 1}"),
                "description": step.get("description", ""),
                "assignee": step.get("assignee", ""),
                "role_required": step.get("role_required", "reviewer"),
                "auto_approve": step.get("auto_approve", False),
                "deadline_days": step.get("deadline_days", 3),
                "status": "Pending"
            })
        
        return {
            "success": True,
            "workflow_id": workflow_id,
            "workflow": {
                "name": workflow.name,
                "document_type": workflow.document_type,
                "auto_assign": workflow.auto_assign,
                "total_steps": len(processed_steps),
                "estimated_duration": f"{sum(step.get('deadline_days', 3) for step in workflow.steps)} days"
            },
            "steps": processed_steps,
            "automation_features": [
                "Automatic step progression on approval",
                "Email notifications at each step",
                "Deadline reminder system",
                "Status tracking and reporting"
            ] if workflow.auto_assign else [
                "Manual step progression",
                "Email notifications at each step", 
                "Deadline reminder system",
                "Status tracking and reporting"
            ],
            "next_steps": [
                "Assign workflow to specific documents",
                "Configure notification preferences",
                "Set up approval criteria for each step",
                "Test workflow with sample document"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create workflow: {str(e)}")

@app.post("/api/documents/folders")
async def create_folder(folder: FolderCreate):
    """Create a new folder"""
    try:
        folder_id = f"folder_{int(time.time())}"
        
        return {
            "success": True,
            "folder_id": folder_id,
            "folder": {
                "name": folder.name,
                "parent_id": folder.parent_id,
                "description": folder.description,
                "created_date": datetime.now().isoformat(),
                "permissions": {
                    "can_upload": True,
                    "can_create_subfolders": True,
                    "can_share": True,
                    "can_delete": True
                }
            },
            "auto_actions": [
                "Folder indexed for search",
                "Permissions inherited from parent",
                "Backup location configured",
                "Activity tracking enabled"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create folder: {str(e)}")

@app.get("/api/documents/analytics")
async def get_document_analytics():
    """Get document usage and collaboration analytics"""
    try:
        analytics = {
            "usage_statistics": {
                "total_documents": 1247,
                "documents_created_this_month": 89,
                "documents_accessed_today": 156,
                "most_accessed_document": "Riverside Development - Planning Application",
                "storage_growth_rate": "12% monthly",
                "average_document_size": "3.2 MB"
            },
            "collaboration_metrics": {
                "active_collaborators": 23,
                "documents_shared_this_week": 34,
                "average_collaborators_per_document": 2.8,
                "most_collaborative_project": "Green Valley Development",
                "external_shares": 12,
                "internal_shares": 67
            },
            "workflow_performance": {
                "active_workflows": 8,
                "completed_workflows_this_month": 23,
                "average_approval_time": "4.2 days",
                "workflow_efficiency": "87%",
                "bottleneck_step": "Technical Review",
                "fastest_workflow": "Document Upload Approval"
            },
            "document_types": [
                {"type": "PDF", "count": 456, "percentage": 36.6},
                {"type": "Word", "count": 334, "percentage": 26.8},
                {"type": "Excel", "count": 189, "percentage": 15.2},
                {"type": "CAD", "count": 156, "percentage": 12.5},
                {"type": "PowerPoint", "count": 89, "percentage": 7.1},
                {"type": "Other", "count": 23, "percentage": 1.8}
            ],
            "access_patterns": {
                "peak_usage_hours": "9-11 AM, 2-4 PM",
                "busiest_day": "Tuesday",
                "download_to_view_ratio": "1:4.3",
                "mobile_access_percentage": 23.4,
                "external_access_percentage": 8.7
            }
        }
        
        return {
            "success": True,
            "analytics": analytics,
            "generated_at": datetime.now().isoformat(),
            "reporting_period": "Last 30 days"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch analytics: {str(e)}")

# ================================
# TASK MANAGEMENT SYSTEM
# ================================

class TaskCreate(BaseModel):
    title: str
    description: Optional[str] = None
    priority: str = "medium"  # low, medium, high
    status: str = "todo"  # todo, in-progress, review, completed, blocked
    assignee_id: Optional[str] = None
    project_id: Optional[str] = None
    category: str = "general"
    due_date: Optional[str] = None
    tags: List[str] = []
    estimated_hours: Optional[int] = None

class TaskUpdate(BaseModel):
    title: Optional[str] = None
    description: Optional[str] = None
    priority: Optional[str] = None
    status: Optional[str] = None
    assignee_id: Optional[str] = None
    project_id: Optional[str] = None
    category: Optional[str] = None
    due_date: Optional[str] = None
    tags: Optional[List[str]] = None
    estimated_hours: Optional[int] = None
    actual_hours: Optional[int] = None

class WorkflowTemplateCreate(BaseModel):
    name: str
    description: Optional[str] = None
    category: str = "general"
    steps: List[dict]
    auto_progression: bool = False
    notification_settings: dict = {}

class TaskComment(BaseModel):
    task_id: str
    comment: str
    comment_type: str = "general"  # general, status_change, assignment, attachment

@app.get("/task-management")
async def task_management(request: Request):
    """Task Management main page"""
    return templates.TemplateResponse("task_management.html", {"request": request})

@app.get("/tasks")
async def tasks(request: Request):
    """Tasks alias route"""
    return templates.TemplateResponse("task_management.html", {"request": request})

@app.get("/api/tasks/list")
async def get_tasks_list():
    """Get comprehensive task list with filtering and sorting"""
    try:
        tasks = [
            {
                "id": "task_001",
                "title": "Review Planning Application - Riverside Development",
                "description": "Complete technical review of planning application including compliance checks, policy analysis, and recommendation preparation",
                "priority": "high",
                "status": "in-progress",
                "category": "planning",
                "assignee_id": "user_001",
                "assignee_name": "Sarah Johnson",
                "assignee_email": "sarah@domus.com",
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_001",
                "project_name": "Riverside Residential Development",
                "created_date": "2024-09-28T09:00:00Z",
                "updated_at": "2024-10-03T14:30:00Z",
                "due_date": "2024-10-07T17:00:00Z",
                "estimated_hours": 16,
                "actual_hours": 12,
                "progress_percentage": 75,
                "tags": ["urgent", "planning", "residential"],
                "overdue": False,
                "blocked": False,
                "dependencies": ["task_002"],
                "subtasks_count": 4,
                "subtasks_completed": 3,
                "comments_count": 8,
                "attachments_count": 3,
                "watchers": ["user_002", "user_003"],
                "last_activity": "Updated status from 'todo' to 'in-progress'",
                "workflow_id": "workflow_001",
                "workflow_step": 2
            },
            {
                "id": "task_002",
                "title": "Prepare Environmental Impact Assessment",
                "description": "Conduct comprehensive environmental assessment covering ecology, air quality, noise impact, and contamination analysis",
                "priority": "high",
                "status": "review",
                "category": "environmental",
                "assignee_id": "user_004",
                "assignee_name": "Rachel Green",
                "assignee_email": "rachel@environmental.co.uk",
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_001",
                "project_name": "Riverside Residential Development",
                "created_date": "2024-09-20T10:00:00Z",
                "updated_at": "2024-10-02T11:15:00Z",
                "due_date": "2024-10-05T17:00:00Z",
                "estimated_hours": 32,
                "actual_hours": 28,
                "progress_percentage": 90,
                "tags": ["environmental", "assessment", "critical"],
                "overdue": False,
                "blocked": False,
                "dependencies": [],
                "subtasks_count": 6,
                "subtasks_completed": 5,
                "comments_count": 12,
                "attachments_count": 7,
                "watchers": ["user_001", "user_005"],
                "last_activity": "Submitted for final review",
                "workflow_id": "workflow_002",
                "workflow_step": 4
            },
            {
                "id": "task_003",
                "title": "Design & Access Statement Creation",
                "description": "Develop comprehensive design and access statement addressing site context, design evolution, access arrangements, and sustainability",
                "priority": "medium",
                "status": "todo",
                "category": "design",
                "assignee_id": "user_006",
                "assignee_name": "Tom Wilson",
                "assignee_email": "tom@architects.co.uk",
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_002",
                "project_name": "City Centre Plaza",
                "created_date": "2024-10-01T14:00:00Z",
                "updated_at": "2024-10-01T14:00:00Z",
                "due_date": "2024-10-10T17:00:00Z",
                "estimated_hours": 20,
                "actual_hours": 0,
                "progress_percentage": 0,
                "tags": ["design", "statement", "architecture"],
                "overdue": False,
                "blocked": False,
                "dependencies": ["task_004"],
                "subtasks_count": 3,
                "subtasks_completed": 0,
                "comments_count": 2,
                "attachments_count": 1,
                "watchers": ["user_007"],
                "last_activity": "Task created and assigned",
                "workflow_id": "workflow_003",
                "workflow_step": 1
            },
            {
                "id": "task_004",
                "title": "Site Survey and Analysis",
                "description": "Complete topographical survey, boundary verification, and site constraints analysis including utilities, access, and environmental factors",
                "priority": "high",
                "status": "completed",
                "category": "survey",
                "assignee_id": "user_008",
                "assignee_name": "David Chen",
                "assignee_email": "david@surveyors.co.uk",
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_002",
                "project_name": "City Centre Plaza",
                "created_date": "2024-09-15T09:00:00Z",
                "updated_at": "2024-09-30T16:45:00Z",
                "due_date": "2024-09-30T17:00:00Z",
                "estimated_hours": 24,
                "actual_hours": 22,
                "progress_percentage": 100,
                "tags": ["survey", "analysis", "completed"],
                "overdue": False,
                "blocked": False,
                "dependencies": [],
                "subtasks_count": 5,
                "subtasks_completed": 5,
                "comments_count": 6,
                "attachments_count": 9,
                "watchers": ["user_006", "user_009"],
                "last_activity": "Task completed successfully",
                "workflow_id": "workflow_004",
                "workflow_step": 5
            },
            {
                "id": "task_005",
                "title": "Transport Impact Assessment",
                "description": "Analyze traffic generation, junction capacity, parking provision, and sustainable transport measures for the development",
                "priority": "medium",
                "status": "blocked",
                "category": "transport",
                "assignee_id": "user_010",
                "assignee_name": "Lisa Park",
                "assignee_email": "lisa@transport.co.uk",
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_003",
                "project_name": "Green Valley Mixed Use",
                "created_date": "2024-09-25T11:00:00Z",
                "updated_at": "2024-10-01T09:30:00Z",
                "due_date": "2024-10-12T17:00:00Z",
                "estimated_hours": 28,
                "actual_hours": 8,
                "progress_percentage": 25,
                "tags": ["transport", "assessment", "blocked"],
                "overdue": False,
                "blocked": True,
                "blocking_reason": "Waiting for traffic count data from local authority",
                "dependencies": ["task_006"],
                "subtasks_count": 4,
                "subtasks_completed": 1,
                "comments_count": 5,
                "attachments_count": 2,
                "watchers": ["user_011"],
                "last_activity": "Task blocked - awaiting data",
                "workflow_id": "workflow_005",
                "workflow_step": 2
            },
            {
                "id": "task_006",
                "title": "Heritage Impact Assessment",
                "description": "Evaluate impact on nearby conservation area and listed buildings, including significance assessment and mitigation proposals",
                "priority": "low",
                "status": "todo",
                "category": "heritage",
                "assignee_id": "user_012",
                "assignee_name": "Emma Wilson",
                "assignee_email": "emma@heritage.co.uk",
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_003",
                "project_name": "Green Valley Mixed Use",
                "created_date": "2024-09-30T15:00:00Z",
                "updated_at": "2024-09-30T15:00:00Z",
                "due_date": "2024-10-15T17:00:00Z",
                "estimated_hours": 16,
                "actual_hours": 0,
                "progress_percentage": 0,
                "tags": ["heritage", "conservation", "assessment"],
                "overdue": False,
                "blocked": False,
                "dependencies": [],
                "subtasks_count": 3,
                "subtasks_completed": 0,
                "comments_count": 1,
                "attachments_count": 0,
                "watchers": ["user_013"],
                "last_activity": "Task created",
                "workflow_id": "workflow_006",
                "workflow_step": 1
            },
            {
                "id": "task_007",
                "title": "Client Presentation Preparation",
                "description": "Prepare comprehensive presentation materials including project overview, design proposals, timeline, and next steps",
                "priority": "medium",
                "status": "in-progress",
                "category": "presentation",
                "assignee_id": "user_014",
                "assignee_name": "Michael Brown",
                "assignee_email": "michael@domus.com",
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_004",
                "project_name": "Retail Park Expansion",
                "created_date": "2024-10-02T10:00:00Z",
                "updated_at": "2024-10-03T13:20:00Z",
                "due_date": "2024-10-04T12:00:00Z",
                "estimated_hours": 8,
                "actual_hours": 5,
                "progress_percentage": 60,
                "tags": ["presentation", "client", "urgent"],
                "overdue": False,
                "blocked": False,
                "dependencies": [],
                "subtasks_count": 4,
                "subtasks_completed": 2,
                "comments_count": 3,
                "attachments_count": 5,
                "watchers": ["user_015"],
                "last_activity": "Added presentation slides",
                "workflow_id": "workflow_007",
                "workflow_step": 3
            },
            {
                "id": "task_008",
                "title": "Planning Policy Review",
                "description": "Review latest local planning policies, supplementary planning documents, and neighborhood plans affecting the development",
                "priority": "high",
                "status": "overdue",
                "category": "policy",
                "assignee_id": "user_001",
                "assignee_name": "Sarah Johnson",
                "assignee_email": "sarah@domus.com", 
                "assignee_avatar": "/api/placeholder/32/32",
                "project_id": "project_005",
                "project_name": "Industrial Estate Redevelopment",
                "created_date": "2024-09-18T08:00:00Z",
                "updated_at": "2024-09-28T16:00:00Z",
                "due_date": "2024-10-01T17:00:00Z",
                "estimated_hours": 12,
                "actual_hours": 8,
                "progress_percentage": 70,
                "tags": ["policy", "review", "overdue"],
                "overdue": True,
                "blocked": False,
                "dependencies": [],
                "subtasks_count": 3,
                "subtasks_completed": 2,
                "comments_count": 4,
                "attachments_count": 6,
                "watchers": ["user_016"],
                "last_activity": "50% complete - needs escalation",
                "workflow_id": "workflow_008",
                "workflow_step": 2
            }
        ]
        
        return {
            "success": True,
            "tasks": tasks,
            "statistics": {
                "total_tasks": len(tasks),
                "by_status": {
                    "todo": len([t for t in tasks if t["status"] == "todo"]),
                    "in_progress": len([t for t in tasks if t["status"] == "in-progress"]),
                    "review": len([t for t in tasks if t["status"] == "review"]),
                    "completed": len([t for t in tasks if t["status"] == "completed"]),
                    "blocked": len([t for t in tasks if t["status"] == "blocked"]),
                    "overdue": len([t for t in tasks if t.get("overdue", False)])
                },
                "by_priority": {
                    "high": len([t for t in tasks if t["priority"] == "high"]),
                    "medium": len([t for t in tasks if t["priority"] == "medium"]),
                    "low": len([t for t in tasks if t["priority"] == "low"])
                },
                "productivity_metrics": {
                    "average_completion_time": "4.2 days",
                    "task_velocity": "12 tasks/week",
                    "completion_rate": "87%",
                    "team_utilization": "78%"
                }
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch tasks: {str(e)}")

@app.post("/api/tasks/create")
async def create_task(task: TaskCreate):
    """Create a new task"""
    try:
        task_id = f"task_{int(time.time())}"
        
        # Validate task data
        valid_priorities = ["low", "medium", "high"]
        valid_statuses = ["todo", "in-progress", "review", "completed", "blocked"]
        
        if task.priority not in valid_priorities:
            raise HTTPException(status_code=400, detail="Invalid priority level")
        
        if task.status not in valid_statuses:
            raise HTTPException(status_code=400, detail="Invalid task status")
        
        # Auto-assign workflow if category matches
        workflow_mapping = {
            "planning": "workflow_001",
            "environmental": "workflow_002", 
            "design": "workflow_003",
            "survey": "workflow_004",
            "transport": "workflow_005",
            "heritage": "workflow_006"
        }
        
        assigned_workflow = workflow_mapping.get(task.category, "workflow_general")
        
        return {
            "success": True,
            "task_id": task_id,
            "task": {
                "title": task.title,
                "description": task.description,
                "priority": task.priority,
                "status": task.status,
                "category": task.category,
                "assignee_id": task.assignee_id,
                "project_id": task.project_id,
                "due_date": task.due_date,
                "tags": task.tags,
                "estimated_hours": task.estimated_hours,
                "workflow_id": assigned_workflow,
                "created_date": datetime.now().isoformat(),
                "progress_percentage": 0
            },
            "auto_actions": [
                f"Task assigned to workflow: {assigned_workflow}",
                "Notification sent to assignee",
                "Task indexed for search",
                "Dependencies analyzed",
                "Timeline updated"
            ],
            "next_steps": [
                "Add subtasks if needed",
                "Upload relevant documents",
                "Set up time tracking",
                "Configure notifications"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create task: {str(e)}")

@app.put("/api/tasks/{task_id}")
async def update_task(task_id: str, task_update: TaskUpdate):
    """Update an existing task"""
    try:
        # Simulate task update
        updated_fields = []
        changes_log = []
        
        if task_update.title:
            updated_fields.append("title")
            changes_log.append(f"Title updated to: {task_update.title}")
        
        if task_update.status:
            updated_fields.append("status")
            changes_log.append(f"Status changed to: {task_update.status}")
            
            # Auto-progress workflow if status changed
            if task_update.status == "completed":
                changes_log.append("Workflow step marked as completed")
                changes_log.append("Next workflow step activated")
        
        if task_update.assignee_id:
            updated_fields.append("assignee")
            changes_log.append("Task reassigned")
        
        if task_update.priority:
            updated_fields.append("priority")
            changes_log.append(f"Priority changed to: {task_update.priority}")
        
        if task_update.due_date:
            updated_fields.append("due_date")
            changes_log.append(f"Due date updated to: {task_update.due_date}")
        
        return {
            "success": True,
            "task_id": task_id,
            "updated_fields": updated_fields,
            "changes_log": changes_log,
            "update_time": datetime.now().isoformat(),
            "notifications_sent": len(updated_fields),
            "workflow_progression": task_update.status == "completed",
            "dependencies_updated": "status" in updated_fields,
            "timeline_recalculated": "due_date" in updated_fields
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to update task: {str(e)}")

@app.get("/api/tasks/workflows")
async def get_task_workflows():
    """Get available task workflow templates"""
    try:
        workflows = [
            {
                "id": "workflow_001",
                "name": "Planning Application Review",
                "description": "Standard workflow for planning application review and approval process",
                "category": "planning",
                "active": True,
                "task_count": 34,
                "avg_completion_time": "12 days",
                "success_rate": "94%",
                "auto_progression": True,
                "steps": [
                    {
                        "id": "step_001",
                        "name": "Initial Review",
                        "description": "Preliminary application assessment and validation",
                        "role_required": "Planning Officer",
                        "estimated_duration": "2 days",
                        "status": "active",
                        "auto_approve_conditions": ["All documents present", "Fee paid"]
                    },
                    {
                        "id": "step_002",
                        "name": "Technical Assessment",
                        "description": "Detailed technical review of proposals",
                        "role_required": "Senior Planner",
                        "estimated_duration": "5 days",
                        "status": "pending",
                        "dependencies": ["step_001"]
                    },
                    {
                        "id": "step_003",
                        "name": "Consultation Review",
                        "description": "Analysis of consultation responses",
                        "role_required": "Planning Manager",
                        "estimated_duration": "3 days",
                        "status": "pending",
                        "dependencies": ["step_002"]
                    },
                    {
                        "id": "step_004",
                        "name": "Final Decision",
                        "description": "Decision notice preparation and approval",
                        "role_required": "Director",
                        "estimated_duration": "2 days",
                        "status": "pending",
                        "dependencies": ["step_003"]
                    }
                ],
                "triggers": {
                    "auto_start": ["task_created", "category_planning"],
                    "escalation": ["overdue_3_days", "high_priority"],
                    "notifications": ["status_change", "step_completion", "deadline_approaching"]
                }
            },
            {
                "id": "workflow_002",
                "name": "Environmental Assessment",
                "description": "Comprehensive environmental impact assessment workflow",
                "category": "environmental",
                "active": True,
                "task_count": 18,
                "avg_completion_time": "18 days",
                "success_rate": "91%",
                "auto_progression": False,
                "steps": [
                    {
                        "id": "step_011",
                        "name": "Scoping Study",
                        "description": "Define assessment scope and methodology",
                        "role_required": "Environmental Consultant",
                        "estimated_duration": "3 days",
                        "status": "active"
                    },
                    {
                        "id": "step_012",
                        "name": "Baseline Survey",
                        "description": "Conduct site surveys and data collection",
                        "role_required": "Ecologist",
                        "estimated_duration": "7 days",
                        "status": "pending",
                        "dependencies": ["step_011"]
                    },
                    {
                        "id": "step_013",
                        "name": "Impact Analysis",
                        "description": "Analyze potential environmental impacts",
                        "role_required": "Environmental Consultant",
                        "estimated_duration": "5 days",
                        "status": "pending",
                        "dependencies": ["step_012"]
                    },
                    {
                        "id": "step_014",
                        "name": "Mitigation Planning",
                        "description": "Develop mitigation and enhancement measures",
                        "role_required": "Senior Environmental Consultant",
                        "estimated_duration": "3 days",
                        "status": "pending",
                        "dependencies": ["step_013"]
                    }
                ],
                "triggers": {
                    "auto_start": ["task_created", "category_environmental"],
                    "quality_gates": ["peer_review_required", "client_approval_needed"],
                    "compliance_checks": ["statutory_deadlines", "regulation_requirements"]
                }
            },
            {
                "id": "workflow_003",
                "name": "Design Review Process",
                "description": "Architectural and design review workflow with multiple approval stages",
                "category": "design",
                "active": True,
                "task_count": 27,
                "avg_completion_time": "15 days",
                "success_rate": "96%",
                "auto_progression": True,
                "steps": [
                    {
                        "id": "step_021",
                        "name": "Concept Review",
                        "description": "Initial design concept evaluation",
                        "role_required": "Design Manager",
                        "estimated_duration": "2 days",
                        "status": "active"
                    },
                    {
                        "id": "step_022",
                        "name": "Technical Review",
                        "description": "Technical feasibility and compliance check",
                        "role_required": "Technical Director",
                        "estimated_duration": "4 days",
                        "status": "pending"
                    },
                    {
                        "id": "step_023",
                        "name": "Client Approval",
                        "description": "Client presentation and approval",
                        "role_required": "Project Manager",
                        "estimated_duration": "3 days",
                        "status": "pending"
                    },
                    {
                        "id": "step_024",
                        "name": "Final Documentation",
                        "description": "Prepare final design documentation",
                        "role_required": "Senior Architect",
                        "estimated_duration": "6 days",
                        "status": "pending"
                    }
                ]
            }
        ]
        
        return {
            "success": True,
            "workflows": workflows,
            "statistics": {
                "total_workflows": len(workflows),
                "active_workflows": len([w for w in workflows if w["active"]]),
                "total_tasks_in_workflows": sum(w["task_count"] for w in workflows),
                "average_completion_time": "15 days",
                "overall_success_rate": "94%"
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch workflows: {str(e)}")

@app.post("/api/tasks/workflows")
async def create_workflow_template(workflow: WorkflowTemplateCreate):
    """Create a new workflow template"""
    try:
        workflow_id = f"workflow_{int(time.time())}"
        
        # Validate workflow steps
        if not workflow.steps or len(workflow.steps) == 0:
            raise HTTPException(status_code=400, detail="Workflow must have at least one step")
        
        # Process and validate steps
        processed_steps = []
        for i, step in enumerate(workflow.steps):
            processed_steps.append({
                "id": f"step_{workflow_id}_{i+1}",
                "name": step.get("name", f"Step {i+1}"),
                "description": step.get("description", ""),
                "role_required": step.get("role_required", "team_member"),
                "estimated_duration": step.get("estimated_duration", "1 day"),
                "auto_approve_conditions": step.get("auto_approve_conditions", []),
                "dependencies": step.get("dependencies", [])
            })
        
        return {
            "success": True,
            "workflow_id": workflow_id,
            "workflow": {
                "name": workflow.name,
                "description": workflow.description,
                "category": workflow.category,
                "auto_progression": workflow.auto_progression,
                "steps_count": len(processed_steps),
                "estimated_total_duration": f"{len(processed_steps) * 2} days"
            },
            "steps": processed_steps,
            "features": [
                "Automatic task routing",
                "Progress tracking",
                "Deadline management",
                "Notification system",
                "Performance analytics"
            ],
            "next_steps": [
                "Test workflow with sample task",
                "Configure notification templates",
                "Set up approval criteria",
                "Train team on new workflow"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create workflow: {str(e)}")

@app.get("/api/tasks/analytics")
async def get_task_analytics():
    """Get comprehensive task management analytics"""
    try:
        analytics = {
            "performance_metrics": {
                "tasks_completed_this_month": 167,
                "average_completion_time": "4.2 days",
                "team_velocity": "12.3 tasks/week",
                "completion_rate": "87%",
                "on_time_delivery": "82%",
                "quality_score": "94%"
            },
            "productivity_trends": {
                "daily_completions": [8, 12, 9, 15, 11, 7, 3],  # Last 7 days
                "weekly_velocity": [45, 52, 48, 56, 49],  # Last 5 weeks
                "monthly_growth": "+12%",
                "efficiency_improvement": "+8% from last quarter"
            },
            "team_performance": {
                "top_performers": [
                    {
                        "user_id": "user_001",
                        "name": "Sarah Johnson",
                        "tasks_completed": 23,
                        "completion_rate": "96%",
                        "average_time": "3.8 days",
                        "quality_score": "98%"
                    },
                    {
                        "user_id": "user_004",
                        "name": "Rachel Green",
                        "tasks_completed": 19,
                        "completion_rate": "94%",
                        "average_time": "4.1 days",
                        "quality_score": "95%"
                    },
                    {
                        "user_id": "user_008",
                        "name": "David Chen",
                        "tasks_completed": 17,
                        "completion_rate": "89%",
                        "average_time": "4.5 days",
                        "quality_score": "92%"
                    }
                ],
                "team_utilization": "78%",
                "workload_distribution": "Balanced",
                "collaboration_score": "91%"
            },
            "workflow_efficiency": {
                "workflow_001": {
                    "name": "Planning Application Review",
                    "completion_rate": "94%",
                    "average_duration": "12 days",
                    "bottleneck_step": "Technical Assessment",
                    "improvement_suggestion": "Add parallel review tracks"
                },
                "workflow_002": {
                    "name": "Environmental Assessment",
                    "completion_rate": "91%",
                    "average_duration": "18 days",
                    "bottleneck_step": "Impact Analysis",
                    "improvement_suggestion": "Standardize analysis templates"
                },
                "workflow_003": {
                    "name": "Design Review Process",
                    "completion_rate": "96%",
                    "average_duration": "15 days",
                    "bottleneck_step": "Client Approval",
                    "improvement_suggestion": "Implement automated reminders"
                }
            },
            "category_breakdown": {
                "planning": {"count": 89, "avg_duration": "8.2 days", "success_rate": "92%"},
                "environmental": {"count": 34, "avg_duration": "14.1 days", "success_rate": "88%"},
                "design": {"count": 56, "avg_duration": "6.7 days", "success_rate": "95%"},
                "survey": {"count": 23, "avg_duration": "5.4 days", "success_rate": "98%"},
                "transport": {"count": 18, "avg_duration": "9.8 days", "success_rate": "85%"},
                "heritage": {"count": 12, "avg_duration": "7.3 days", "success_rate": "90%"}
            },
            "risk_indicators": {
                "overdue_tasks": 3,
                "blocked_tasks": 2,
                "high_risk_projects": 1,
                "capacity_warnings": ["Transport team at 95% capacity"],
                "deadline_alerts": ["5 tasks due this week", "2 critical deadlines approaching"]
            },
            "quality_metrics": {
                "task_acceptance_rate": "94%",
                "rework_percentage": "6%",
                "client_satisfaction": "4.7/5",
                "error_rate": "2.1%",
                "process_compliance": "97%"
            }
        }
        
        return {
            "success": True,
            "analytics": analytics,
            "generated_at": datetime.now().isoformat(),
            "reporting_period": "Last 30 days",
            "next_update": (datetime.now() + timedelta(hours=1)).isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch task analytics: {str(e)}")

@app.post("/api/tasks/{task_id}/comments")
async def add_task_comment(task_id: str, comment: TaskComment):
    """Add comment to a task"""
    try:
        comment_id = f"comment_{int(time.time())}"
        
        return {
            "success": True,
            "comment_id": comment_id,
            "task_id": task_id,
            "comment": {
                "content": comment.comment,
                "type": comment.comment_type,
                "author": "Current User",
                "timestamp": datetime.now().isoformat(),
                "mentions": [],
                "attachments": []
            },
            "notifications_sent": 1,
            "task_updated": True
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to add comment: {str(e)}")

@app.get("/api/tasks/dashboard")
async def get_task_dashboard():
    """Get task management dashboard data"""
    try:
        dashboard_data = {
            "quick_stats": {
                "total_tasks": 247,
                "active_tasks": 89,
                "completed_this_week": 34,
                "overdue_tasks": 3,
                "team_velocity": "12.3 tasks/week",
                "completion_rate": "87%"
            },
            "recent_activity": [
                {
                    "id": "activity_001",
                    "type": "task_completed",
                    "description": "Sarah Johnson completed 'Site Survey and Analysis'",
                    "timestamp": "2024-10-03T16:45:00Z",
                    "user_name": "Sarah Johnson",
                    "user_avatar": "/api/placeholder/32/32"
                },
                {
                    "id": "activity_002",
                    "type": "task_assigned",
                    "description": "Michael Brown assigned 'Client Presentation' to Lisa Park",
                    "timestamp": "2024-10-03T15:30:00Z",
                    "user_name": "Michael Brown",
                    "user_avatar": "/api/placeholder/32/32"
                },
                {
                    "id": "activity_003",
                    "type": "workflow_progress",
                    "description": "Environmental Assessment moved to review stage",
                    "timestamp": "2024-10-03T14:15:00Z",
                    "user_name": "System",
                    "user_avatar": "/api/placeholder/32/32"
                }
            ],
            "upcoming_deadlines": [
                {
                    "task_id": "task_007",
                    "title": "Client Presentation Preparation",
                    "due_date": "2024-10-04T12:00:00Z",
                    "priority": "high",
                    "assignee": "Michael Brown",
                    "project": "Retail Park Expansion"
                },
                {
                    "task_id": "task_002",
                    "title": "Environmental Impact Assessment",
                    "due_date": "2024-10-05T17:00:00Z",
                    "priority": "high",
                    "assignee": "Rachel Green",
                    "project": "Riverside Development"
                }
            ],
            "workload_distribution": {
                "Sarah Johnson": {"active": 4, "capacity": 85},
                "Rachel Green": {"active": 3, "capacity": 70},
                "Tom Wilson": {"active": 2, "capacity": 45},
                "David Chen": {"active": 5, "capacity": 95},
                "Lisa Park": {"active": 3, "capacity": 60}
            }
        }
        
        return {
            "success": True,
            "dashboard": dashboard_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch dashboard: {str(e)}")

# ================================
# REPORTING & ANALYTICS SYSTEM
# ================================

class CustomReportCreate(BaseModel):
    name: str
    description: Optional[str] = None
    data_sources: List[str] = []
    schedule: str = "manual"  # manual, daily, weekly, monthly
    recipients: List[str] = []
    chart_types: List[str] = []
    filters: dict = {}

class ReportExportRequest(BaseModel):
    report_type: str
    format: str = "pdf"  # pdf, excel, csv
    date_range: dict = {}
    filters: dict = {}

@app.get("/reporting-analytics")
async def reporting_analytics(request: Request):
    """Reporting & Analytics main page"""
    return templates.TemplateResponse("reporting_analytics.html", {"request": request})

@app.get("/reporting")
async def reporting(request: Request):
    """Reporting alias route"""
    return templates.TemplateResponse("reporting_analytics.html", {"request": request})

@app.get("/api/analytics/overview")
async def get_analytics_overview():
    """Get comprehensive analytics overview data"""
    try:
        overview_data = {
            "key_metrics": {
                "total_revenue": {
                    "value": 2340000,
                    "formatted": "Â£2.34M",
                    "change_percentage": 23.4,
                    "change_direction": "up",
                    "period": "vs last month"
                },
                "active_projects": {
                    "value": 187,
                    "change_percentage": 6.8,
                    "change_direction": "up",
                    "change_absolute": 12,
                    "period": "new this month"
                },
                "client_satisfaction": {
                    "value": 94,
                    "formatted": "94%",
                    "change_percentage": 2.1,
                    "change_direction": "up",
                    "target": 95,
                    "period": "improvement"
                },
                "team_efficiency": {
                    "value": 87,
                    "formatted": "87%",
                    "change_percentage": -3.2,
                    "change_direction": "down",
                    "target": 90,
                    "period": "below target"
                }
            },
            "kpi_dashboard": {
                "monthly_recurring_revenue": {
                    "value": 89200,
                    "formatted": "Â£89.2K",
                    "growth_rate": 15.3,
                    "trend": "up",
                    "target": 95000
                },
                "planning_applications": {
                    "value": 67,
                    "period": "this month",
                    "growth": 8,
                    "trend": "up",
                    "completion_rate": 94
                },
                "avg_project_duration": {
                    "value": 4.2,
                    "unit": "weeks",
                    "improvement": 2,
                    "trend": "down",
                    "target": 4.0
                },
                "client_rating": {
                    "value": 4.7,
                    "max": 5.0,
                    "reviews_count": 156,
                    "trend": "stable",
                    "distribution": {
                        "5_star": 78,
                        "4_star": 67,
                        "3_star": 9,
                        "2_star": 2,
                        "1_star": 0
                    }
                }
            },
            "revenue_trends": {
                "monthly_data": [
                    {"month": "Jan", "revenue": 180000, "projects": 15},
                    {"month": "Feb", "revenue": 195000, "projects": 18},
                    {"month": "Mar", "revenue": 210000, "projects": 22},
                    {"month": "Apr", "revenue": 185000, "projects": 16},
                    {"month": "May", "revenue": 220000, "projects": 25},
                    {"month": "Jun", "revenue": 235000, "projects": 28},
                    {"month": "Jul", "revenue": 245000, "projects": 30},
                    {"month": "Aug", "revenue": 225000, "projects": 26},
                    {"month": "Sep", "revenue": 260000, "projects": 32}
                ],
                "forecast": {
                    "oct": 275000,
                    "nov": 290000,
                    "dec": 310000
                }
            },
            "project_distribution": {
                "planning_applications": {"count": 84, "percentage": 45, "revenue": 1053000},
                "design_projects": {"count": 47, "percentage": 25, "revenue": 585000},
                "consultancy": {"count": 37, "percentage": 20, "revenue": 468000},
                "environmental": {"count": 19, "percentage": 10, "revenue": 234000}
            },
            "performance_alerts": [
                {
                    "type": "warning",
                    "title": "Team Efficiency Below Target",
                    "message": "Current efficiency at 87%, target is 90%. Consider workload redistribution.",
                    "priority": "medium"
                },
                {
                    "type": "success",
                    "title": "Revenue Target Exceeded",
                    "message": "September revenue exceeded target by 23%. Strong performance in planning applications.",
                    "priority": "low"
                }
            ]
        }
        
        return {
            "success": True,
            "overview": overview_data,
            "last_updated": datetime.now().isoformat(),
            "refresh_interval": 300  # 5 minutes
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch overview analytics: {str(e)}")

@app.get("/api/analytics/financial")
async def get_financial_analytics():
    """Get comprehensive financial analytics data"""
    try:
        financial_data = {
            "revenue_metrics": {
                "total_revenue": {
                    "current_period": 2340000,
                    "previous_period": 1895000,
                    "growth_percentage": 23.5,
                    "annual_target": 2900000,
                    "target_achievement": 80.7
                },
                "outstanding_invoices": {
                    "total": 456000,
                    "aging": {
                        "0_30_days": 289000,
                        "31_60_days": 123000,
                        "61_90_days": 32000,
                        "over_90_days": 12000
                    },
                    "collection_rate": 94.2
                },
                "profit_margins": {
                    "gross_margin": 68.5,
                    "net_margin": 23.8,
                    "operating_margin": 28.4,
                    "benchmark_comparison": {
                        "industry_average": 22.1,
                        "performance": "above_average"
                    }
                }
            },
            "cash_flow": {
                "monthly_data": [
                    {"month": "Jan", "inflow": 195000, "outflow": 145000, "net": 50000},
                    {"month": "Feb", "inflow": 210000, "outflow": 158000, "net": 52000},
                    {"month": "Mar", "inflow": 225000, "outflow": 167000, "net": 58000},
                    {"month": "Apr", "inflow": 198000, "outflow": 152000, "net": 46000},
                    {"month": "May", "inflow": 235000, "outflow": 172000, "net": 63000},
                    {"month": "Jun", "inflow": 250000, "outflow": 181000, "net": 69000},
                    {"month": "Jul", "inflow": 260000, "outflow": 189000, "net": 71000},
                    {"month": "Aug", "inflow": 240000, "outflow": 175000, "net": 65000},
                    {"month": "Sep", "inflow": 275000, "outflow": 195000, "net": 80000}
                ],
                "forecast": {
                    "next_quarter": {
                        "projected_inflow": 825000,
                        "projected_outflow": 592000,
                        "projected_net": 233000
                    }
                }
            },
            "expense_breakdown": {
                "personnel": {"amount": 1245000, "percentage": 53.2},
                "overhead": {"amount": 387000, "percentage": 16.5},
                "technology": {"amount": 156000, "percentage": 6.7},
                "marketing": {"amount": 89000, "percentage": 3.8},
                "professional_services": {"amount": 123000, "percentage": 5.3},
                "other": {"amount": 340000, "percentage": 14.5}
            },
            "financial_ratios": {
                "liquidity": {
                    "current_ratio": 2.8,
                    "quick_ratio": 2.1,
                    "cash_ratio": 1.4
                },
                "efficiency": {
                    "asset_turnover": 1.8,
                    "receivables_turnover": 8.2,
                    "inventory_turnover": "N/A"
                },
                "profitability": {
                    "roi": 34.7,
                    "roe": 28.9,
                    "roa": 19.3
                }
            },
            "budget_performance": {
                "revenue": {
                    "budgeted": 2200000,
                    "actual": 2340000,
                    "variance": 140000,
                    "variance_percentage": 6.4
                },
                "expenses": {
                    "budgeted": 1680000,
                    "actual": 1785000,
                    "variance": -105000,
                    "variance_percentage": -6.3
                },
                "profit": {
                    "budgeted": 520000,
                    "actual": 555000,
                    "variance": 35000,
                    "variance_percentage": 6.7
                }
            }
        }
        
        return {
            "success": True,
            "financial": financial_data,
            "currency": "GBP",
            "period": "September 2024",
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch financial analytics: {str(e)}")

@app.get("/api/analytics/projects")
async def get_project_analytics():
    """Get comprehensive project analytics data"""
    try:
        project_data = {
            "project_overview": {
                "total_projects": 187,
                "active_projects": 89,
                "completed_this_month": 23,
                "overdue_projects": 5,
                "average_duration": 4.2,
                "success_rate": 94.7
            },
            "project_status_distribution": {
                "planning": {"count": 34, "percentage": 18.2},
                "in_progress": {"count": 89, "percentage": 47.6},
                "review": {"count": 27, "percentage": 14.4},
                "completed": {"count": 32, "percentage": 17.1},
                "on_hold": {"count": 5, "percentage": 2.7}
            },
            "project_types": {
                "residential_planning": {"count": 67, "avg_duration": 3.8, "success_rate": 96.2},
                "commercial_planning": {"count": 45, "avg_duration": 5.1, "success_rate": 92.4},
                "mixed_use": {"count": 28, "avg_duration": 6.3, "success_rate": 89.7},
                "infrastructure": {"count": 23, "avg_duration": 8.2, "success_rate": 91.3},
                "environmental": {"count": 24, "avg_duration": 4.7, "success_rate": 95.8}
            },
            "timeline_performance": {
                "on_time": {"count": 154, "percentage": 82.4},
                "ahead_of_schedule": {"count": 18, "percentage": 9.6},
                "behind_schedule": {"count": 15, "percentage": 8.0}
            },
            "budget_performance": {
                "under_budget": {"count": 78, "percentage": 41.7, "avg_savings": 8.3},
                "on_budget": {"count": 89, "percentage": 47.6},
                "over_budget": {"count": 20, "percentage": 10.7, "avg_overrun": 12.4}
            },
            "client_satisfaction_by_project": {
                "excellent": {"count": 89, "percentage": 47.6},
                "very_good": {"count": 67, "percentage": 35.8},
                "good": {"count": 23, "percentage": 12.3},
                "fair": {"count": 6, "percentage": 3.2},
                "poor": {"count": 2, "percentage": 1.1}
            },
            "top_performing_projects": [
                {
                    "id": "proj_001",
                    "name": "Riverside Residential Development",
                    "client": "Green Valley Homes",
                    "type": "Residential Planning",
                    "status": "Completed",
                    "performance_score": 98.5,
                    "budget_variance": -5.2,
                    "timeline_variance": -8,
                    "client_satisfaction": 5.0
                },
                {
                    "id": "proj_002", 
                    "name": "City Centre Plaza",
                    "client": "Urban Developments Ltd",
                    "type": "Commercial Planning",
                    "status": "In Progress",
                    "performance_score": 96.8,
                    "budget_variance": 2.1,
                    "timeline_variance": -3,
                    "client_satisfaction": 4.8
                },
                {
                    "id": "proj_003",
                    "name": "Heritage Conservation Project",
                    "client": "Historic Buildings Trust",
                    "type": "Environmental",
                    "status": "Review",
                    "performance_score": 95.2,
                    "budget_variance": -12.3,
                    "timeline_variance": 5,
                    "client_satisfaction": 4.9
                }
            ],
            "resource_utilization": {
                "team_capacity": 85.7,
                "equipment_utilization": 78.3,
                "subcontractor_efficiency": 91.2,
                "bottlenecks": [
                    "Senior Planning Officer availability",
                    "Environmental assessment backlog"
                ]
            },
            "monthly_trends": {
                "new_projects": [12, 15, 18, 14, 21, 19, 23, 17, 20],
                "completed_projects": [8, 11, 16, 12, 18, 15, 19, 14, 23],
                "revenue_per_project": [12500, 13200, 14100, 11800, 15600, 14900, 16200, 13800, 16800]
            }
        }
        
        return {
            "success": True,
            "projects": project_data,
            "analysis_period": "Last 12 months",
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch project analytics: {str(e)}")

@app.get("/api/analytics/performance")
async def get_performance_analytics():
    """Get comprehensive team and operational performance analytics"""
    try:
        performance_data = {
            "team_performance": {
                "overall_efficiency": 87.3,
                "productivity_score": 92.1,
                "quality_rating": 94.7,
                "collaboration_index": 89.6,
                "individual_performance": [
                    {
                        "employee_id": "emp_001",
                        "name": "Sarah Johnson",
                        "role": "Senior Planning Officer",
                        "efficiency": 96.2,
                        "quality": 98.1,
                        "projects_completed": 34,
                        "client_rating": 4.9,
                        "performance_trend": "up"
                    },
                    {
                        "employee_id": "emp_002",
                        "name": "Michael Brown",
                        "role": "Project Manager",
                        "efficiency": 91.8,
                        "quality": 93.4,
                        "projects_completed": 28,
                        "client_rating": 4.7,
                        "performance_trend": "stable"
                    },
                    {
                        "employee_id": "emp_003",
                        "name": "Emma Wilson",
                        "role": "Environmental Consultant",
                        "efficiency": 88.7,
                        "quality": 96.2,
                        "projects_completed": 19,
                        "client_rating": 4.8,
                        "performance_trend": "up"
                    }
                ]
            },
            "operational_metrics": {
                "process_efficiency": {
                    "application_processing": 82.4,
                    "client_communication": 91.7,
                    "document_management": 88.9,
                    "quality_assurance": 94.3,
                    "project_delivery": 87.1
                },
                "time_to_completion": {
                    "planning_applications": 3.8,
                    "environmental_assessments": 5.2,
                    "design_reviews": 2.9,
                    "consultation_reports": 4.1,
                    "compliance_checks": 1.7
                },
                "error_rates": {
                    "documentation_errors": 2.1,
                    "calculation_errors": 0.8,
                    "communication_errors": 1.4,
                    "process_deviations": 3.2,
                    "client_complaints": 1.1
                }
            },
            "quality_metrics": {
                "client_satisfaction": {
                    "overall_rating": 4.7,
                    "response_time_rating": 4.5,
                    "quality_rating": 4.8,
                    "communication_rating": 4.6,
                    "value_rating": 4.7,
                    "nps_score": 67
                },
                "internal_quality": {
                    "peer_review_scores": 94.3,
                    "compliance_rate": 98.7,
                    "rework_percentage": 4.2,
                    "first_time_right": 91.8
                },
                "continuous_improvement": {
                    "suggestions_implemented": 23,
                    "process_improvements": 12,
                    "training_completion": 96.4,
                    "certification_maintenance": 100.0
                }
            },
            "efficiency_trends": {
                "monthly_efficiency": [85.2, 86.1, 87.8, 84.9, 88.3, 89.1, 90.2, 87.6, 89.4],
                "productivity_trends": [88.7, 90.2, 91.5, 89.8, 92.3, 93.1, 94.2, 91.8, 92.1],
                "quality_trends": [92.1, 93.4, 94.2, 93.8, 94.9, 95.1, 94.7, 94.3, 94.7]
            },
            "benchmarking": {
                "industry_comparison": {
                    "efficiency": {"our_score": 87.3, "industry_average": 82.1, "top_quartile": 91.5},
                    "quality": {"our_score": 94.7, "industry_average": 89.3, "top_quartile": 96.2},
                    "client_satisfaction": {"our_score": 4.7, "industry_average": 4.2, "top_quartile": 4.8},
                    "profitability": {"our_score": 23.8, "industry_average": 18.5, "top_quartile": 26.3}
                }
            },
            "improvement_opportunities": [
                {
                    "area": "Team Efficiency",
                    "current_score": 87.3,
                    "target_score": 90.0,
                    "improvement_potential": 2.7,
                    "recommended_actions": [
                        "Implement workflow automation",
                        "Reduce meeting time by 20%",
                        "Streamline approval processes"
                    ]
                },
                {
                    "area": "Technology Adoption",
                    "current_score": 78.4,
                    "target_score": 85.0,
                    "improvement_potential": 6.6,
                    "recommended_actions": [
                        "Upgrade project management tools",
                        "Implement AI-assisted document review",
                        "Deploy mobile field applications"
                    ]
                }
            ]
        }
        
        return {
            "success": True,
            "performance": performance_data,
            "evaluation_period": "Last 12 months",
            "benchmarks_updated": "Q3 2024",
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch performance analytics: {str(e)}")

@app.get("/api/analytics/clients")
async def get_client_analytics():
    """Get comprehensive client analytics data"""
    try:
        client_data = {
            "client_overview": {
                "total_clients": 156,
                "active_clients": 89,
                "new_clients_this_month": 12,
                "client_retention_rate": 89.7,
                "average_client_value": 15600,
                "lifetime_value": 67800
            },
            "client_acquisition": {
                "monthly_data": [
                    {"month": "Jan", "new_clients": 8, "referrals": 3, "marketing": 5},
                    {"month": "Feb", "new_clients": 11, "referrals": 5, "marketing": 6},
                    {"month": "Mar", "new_clients": 15, "referrals": 7, "marketing": 8},
                    {"month": "Apr", "new_clients": 9, "referrals": 4, "marketing": 5},
                    {"month": "May", "new_clients": 13, "referrals": 6, "marketing": 7},
                    {"month": "Jun", "new_clients": 16, "referrals": 8, "marketing": 8},
                    {"month": "Jul", "new_clients": 18, "referrals": 9, "marketing": 9},
                    {"month": "Aug", "new_clients": 14, "referrals": 6, "marketing": 8},
                    {"month": "Sep", "new_clients": 12, "referrals": 5, "marketing": 7}
                ],
                "acquisition_channels": {
                    "referrals": {"count": 53, "percentage": 45.7, "cost_per_acquisition": 250},
                    "website": {"count": 28, "percentage": 24.1, "cost_per_acquisition": 180},
                    "social_media": {"count": 18, "percentage": 15.5, "cost_per_acquisition": 320},
                    "professional_network": {"count": 12, "percentage": 10.3, "cost_per_acquisition": 150},
                    "events": {"count": 5, "percentage": 4.3, "cost_per_acquisition": 480}
                }
            },
            "client_retention": {
                "retention_by_year": {
                    "year_1": 94.2,
                    "year_2": 87.8,
                    "year_3": 82.1,
                    "year_4": 78.6,
                    "year_5_plus": 74.3
                },
                "churn_analysis": {
                    "total_churn_rate": 10.3,
                    "churn_reasons": {
                        "cost_concerns": 34.6,
                        "service_quality": 12.8,
                        "business_closure": 23.1,
                        "competitor_switch": 15.4,
                        "project_completion": 14.1
                    },
                    "at_risk_clients": 8,
                    "prevention_actions": [
                        "Regular check-ins with high-value clients",
                        "Proactive service quality monitoring",
                        "Competitive pricing reviews"
                    ]
                }
            },
            "client_segmentation": {
                "by_value": {
                    "high_value": {"count": 23, "avg_revenue": 45600, "total_revenue": 1048800},
                    "medium_value": {"count": 67, "avg_revenue": 18200, "total_revenue": 1219400},
                    "low_value": {"count": 66, "avg_revenue": 6800, "total_revenue": 448800}
                },
                "by_type": {
                    "property_developers": {"count": 45, "avg_project_value": 28900},
                    "local_authorities": {"count": 12, "avg_project_value": 67500},
                    "private_individuals": {"count": 67, "avg_project_value": 8400},
                    "commercial_entities": {"count": 32, "avg_project_value": 34200}
                },
                "by_geography": {
                    "london": {"count": 34, "revenue": 678900},
                    "south_east": {"count": 28, "revenue": 456700},
                    "south_west": {"count": 23, "revenue": 389200},
                    "midlands": {"count": 18, "revenue": 298600},
                    "north": {"count": 15, "revenue": 234500},
                    "other": {"count": 38, "revenue": 659100}
                }
            },
            "client_satisfaction": {
                "overall_satisfaction": 4.7,
                "satisfaction_distribution": {
                    "5_stars": 78,
                    "4_stars": 56,
                    "3_stars": 18,
                    "2_stars": 3,
                    "1_star": 1
                },
                "satisfaction_by_service": {
                    "planning_applications": 4.8,
                    "environmental_assessments": 4.6,
                    "design_consultancy": 4.7,
                    "project_management": 4.5,
                    "compliance_support": 4.9
                },
                "nps_analysis": {
                    "net_promoter_score": 67,
                    "promoters": 89,
                    "passives": 56,
                    "detractors": 11,
                    "industry_benchmark": 52
                }
            },
            "top_clients": [
                {
                    "id": "client_001",
                    "name": "Green Valley Developments",
                    "projects": 23,
                    "total_revenue": 456700,
                    "satisfaction": 4.9,
                    "retention_years": 5.2,
                    "last_project": "2024-09-15",
                    "status": "Active"
                },
                {
                    "id": "client_002",
                    "name": "Urban Planning Associates",
                    "projects": 18,
                    "total_revenue": 387200,
                    "satisfaction": 4.8,
                    "retention_years": 3.8,
                    "last_project": "2024-09-28",
                    "status": "Active"
                },
                {
                    "id": "client_003",
                    "name": "Heritage Construction Ltd",
                    "projects": 15,
                    "total_revenue": 298600,
                    "satisfaction": 4.6,
                    "retention_years": 4.1,
                    "last_project": "2024-08-22",
                    "status": "Active"
                }
            ],
            "client_feedback_analysis": {
                "common_praise": [
                    "Professional and knowledgeable team",
                    "Excellent communication throughout projects",
                    "Delivers on time and within budget",
                    "Proactive problem solving"
                ],
                "areas_for_improvement": [
                    "Initial response time could be faster",
                    "More frequent project updates requested",
                    "Clearer pricing structure needed"
                ],
                "recent_testimonials": [
                    {
                        "client": "Sarah Mitchell, Planning Director",
                        "company": "Riverside Developments",
                        "text": "Domus delivered exceptional results on our complex heritage site. Their expertise made the difference.",
                        "rating": 5
                    },
                    {
                        "client": "Mark Thompson, CEO",
                        "company": "Thompson Estates",
                        "text": "Outstanding service from start to finish. Highly recommend for any planning challenges.",
                        "rating": 5
                    }
                ]
            }
        }
        
        return {
            "success": True,
            "clients": client_data,
            "analysis_period": "Last 24 months",
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch client analytics: {str(e)}")

@app.get("/api/analytics/custom-reports")
async def get_custom_reports():
    """Get list of custom reports"""
    try:
        custom_reports = [
            {
                "id": "report_001",
                "name": "Monthly Executive Summary",
                "description": "Comprehensive monthly overview for executive team including KPIs, financial performance, and strategic insights",
                "schedule": "Monthly",
                "last_run": "2024-10-01",
                "next_run": "2024-11-01",
                "data_points": 47,
                "recipients": 5,
                "status": "Active",
                "data_sources": ["financial", "projects", "clients"],
                "charts": ["revenue_trend", "project_status", "client_satisfaction"],
                "created_by": "Admin",
                "created_date": "2024-01-15"
            },
            {
                "id": "report_002",
                "name": "Project Performance Dashboard",
                "description": "Weekly project performance tracking with timeline, budget, and quality metrics",
                "schedule": "Weekly",
                "last_run": "2024-09-30",
                "next_run": "2024-10-07",
                "data_points": 23,
                "recipients": 8,
                "status": "Active",
                "data_sources": ["projects", "tasks"],
                "charts": ["timeline_performance", "budget_variance", "quality_scores"],
                "created_by": "Project Manager",
                "created_date": "2024-02-20"
            },
            {
                "id": "report_003",
                "name": "Client Satisfaction Analysis",
                "description": "Quarterly client satisfaction trends with NPS analysis and improvement recommendations",
                "schedule": "Quarterly",
                "last_run": "2024-07-01",
                "next_run": "2024-10-01",
                "data_points": 18,
                "recipients": 6,
                "status": "Active",
                "data_sources": ["clients", "communications"],
                "charts": ["satisfaction_trends", "nps_analysis", "feedback_sentiment"],
                "created_by": "Client Success Manager",
                "created_date": "2024-01-30"
            },
            {
                "id": "report_004",
                "name": "Financial Compliance Report",
                "description": "Monthly financial compliance and audit preparation report",
                "schedule": "Monthly",
                "last_run": "2024-09-30",
                "next_run": "2024-10-31",
                "data_points": 31,
                "recipients": 3,
                "status": "Active",
                "data_sources": ["financial"],
                "charts": ["compliance_metrics", "audit_readiness", "risk_indicators"],
                "created_by": "Finance Director",
                "created_date": "2024-03-10"
            },
            {
                "id": "report_005",
                "name": "Team Performance Review",
                "description": "Bi-weekly team performance analysis with productivity and efficiency metrics",
                "schedule": "Bi-weekly",
                "last_run": "2024-09-28",
                "next_run": "2024-10-12",
                "data_points": 15,
                "recipients": 4,
                "status": "Draft",
                "data_sources": ["performance", "tasks"],
                "charts": ["team_efficiency", "individual_performance", "workload_distribution"],
                "created_by": "HR Manager",
                "created_date": "2024-09-15"
            }
        ]
        
        report_templates = [
            {
                "id": "template_001",
                "name": "Executive Dashboard",
                "description": "High-level KPIs and strategic metrics",
                "category": "Executive",
                "data_sources": ["financial", "projects", "clients", "performance"],
                "default_charts": ["revenue_trend", "project_overview", "client_satisfaction"]
            },
            {
                "id": "template_002",
                "name": "Operational Report",
                "description": "Detailed operational metrics and performance indicators",
                "category": "Operations",
                "data_sources": ["projects", "tasks", "performance"],
                "default_charts": ["project_timeline", "team_utilization", "efficiency_metrics"]
            },
            {
                "id": "template_003",
                "name": "Financial Analysis",
                "description": "Comprehensive financial performance and forecasting",
                "category": "Finance",
                "data_sources": ["financial"],
                "default_charts": ["cash_flow", "profit_margins", "budget_variance"]
            }
        ]
        
        return {
            "success": True,
            "reports": custom_reports,
            "templates": report_templates,
            "statistics": {
                "total_reports": len(custom_reports),
                "active_reports": len([r for r in custom_reports if r["status"] == "Active"]),
                "scheduled_reports": len([r for r in custom_reports if r["schedule"] != "Manual"]),
                "total_recipients": sum(r["recipients"] for r in custom_reports)
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch custom reports: {str(e)}")

@app.post("/api/analytics/custom-reports")
async def create_custom_report(report: CustomReportCreate):
    """Create a new custom report"""
    try:
        report_id = f"report_{int(time.time())}"
        
        # Validate data sources
        valid_sources = ["financial", "projects", "clients", "performance", "tasks", "communications"]
        invalid_sources = [src for src in report.data_sources if src not in valid_sources]
        if invalid_sources:
            raise HTTPException(status_code=400, detail=f"Invalid data sources: {invalid_sources}")
        
        # Calculate estimated data points
        data_points = len(report.data_sources) * 10 + len(report.chart_types) * 5
        
        return {
            "success": True,
            "report_id": report_id,
            "report": {
                "name": report.name,
                "description": report.description,
                "data_sources": report.data_sources,
                "schedule": report.schedule,
                "recipients": report.recipients,
                "estimated_data_points": data_points,
                "created_date": datetime.now().isoformat()
            },
            "next_steps": [
                "Configure chart layouts and visualizations",
                "Set up data filters and parameters",
                "Test report generation",
                "Schedule automated delivery"
            ],
            "estimated_setup_time": "15-30 minutes"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create custom report: {str(e)}")

@app.post("/api/analytics/export")
async def export_report(export_request: ReportExportRequest):
    """Export analytics report in specified format"""
    try:
        # Validate export format
        valid_formats = ["pdf", "excel", "csv", "json"]
        if export_request.format not in valid_formats:
            raise HTTPException(status_code=400, detail=f"Invalid export format: {export_request.format}")
        
        # Generate export file
        export_id = f"export_{int(time.time())}"
        filename = f"{export_request.report_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{export_request.format}"
        
        return {
            "success": True,
            "export_id": export_id,
            "filename": filename,
            "download_url": f"/api/analytics/downloads/{export_id}",
            "file_size": "2.4 MB",
            "expires_at": (datetime.now() + timedelta(hours=24)).isoformat(),
            "format": export_request.format,
            "includes": [
                "Executive summary",
                "Key performance indicators",
                "Detailed analytics data",
                "Charts and visualizations",
                "Recommendations"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to export report: {str(e)}")

@app.get("/api/analytics/insights")
async def get_analytics_insights():
    """Get AI-powered business insights and recommendations"""
    try:
        insights = {
            "key_insights": [
                {
                    "category": "Revenue",
                    "insight": "Revenue growth has accelerated 23% this month, driven primarily by an increase in high-value commercial planning projects",
                    "confidence": 94,
                    "impact": "High",
                    "recommendation": "Consider expanding commercial planning team capacity to meet growing demand"
                },
                {
                    "category": "Efficiency",
                    "insight": "Team efficiency is 3% below target, with bottlenecks identified in the technical review process",
                    "confidence": 87,
                    "impact": "Medium",
                    "recommendation": "Implement parallel review workflows for non-critical technical assessments"
                },
                {
                    "category": "Client Satisfaction",
                    "insight": "Client satisfaction scores show strong correlation with project communication frequency",
                    "confidence": 91,
                    "impact": "Medium",
                    "recommendation": "Standardize weekly client update protocols across all projects"
                }
            ],
            "predictions": {
                "revenue_forecast": {
                    "next_month": {"value": 275000, "confidence": 89},
                    "next_quarter": {"value": 825000, "confidence": 82},
                    "year_end": {"value": 3200000, "confidence": 75}
                },
                "client_churn_risk": {
                    "high_risk_clients": 3,
                    "predicted_churn": 2.8,
                    "prevention_success_rate": 78
                }
            },
            "anomaly_detection": [
                {
                    "metric": "Project completion time",
                    "anomaly": "Environmental assessments taking 32% longer than historical average",
                    "severity": "Medium",
                    "suggested_investigation": "Review environmental assessment workflow for bottlenecks"
                }
            ]
        }
        
        return {
            "success": True,
            "insights": insights,
            "generated_at": datetime.now().isoformat(),
            "ai_model_version": "v2.1.3"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch insights: {str(e)}")

# ================================
# INTEGRATION ECOSYSTEM SYSTEM
# ================================

class IntegrationConfig(BaseModel):
    name: str
    type: str  # planning_portal, government_api, mapping_service, financial_system, crm, etc.
    endpoint_url: str
    authentication_method: str = "api_key"  # api_key, oauth2, basic_auth
    api_key: Optional[str] = None
    client_id: Optional[str] = None
    client_secret: Optional[str] = None
    enabled: bool = True
    rate_limit: Optional[int] = None
    timeout: int = 30
    retry_attempts: int = 3

class WebhookConfig(BaseModel):
    url: str
    events: List[str]
    secret: Optional[str] = None
    enabled: bool = True

class APITestRequest(BaseModel):
    integration_id: str
    endpoint: str
    method: str = "GET"
    headers: dict = {}
    payload: dict = {}

@app.get("/integration-ecosystem")
async def integration_ecosystem(request: Request):
    """Integration Ecosystem main page"""
    return templates.TemplateResponse("integration_ecosystem.html", {"request": request})

@app.get("/api/integrations/overview")
async def get_integrations_overview():
    """Get comprehensive integrations overview data"""
    try:
        overview_data = {
            "statistics": {
                "total_integrations": 24,
                "active_connections": 18,
                "failed_connections": 3,
                "pending_setup": 3,
                "monthly_api_calls": 47234,
                "average_response_time": 2.1,
                "success_rate": 99.7,
                "monthly_costs": 1247.50,
                "uptime_percentage": 99.8
            },
            "integration_health": {
                "excellent": 15,
                "good": 3,
                "warning": 4,
                "critical": 2
            },
            "top_integrations_by_usage": [
                {
                    "name": "Ordnance Survey",
                    "type": "mapping_service",
                    "monthly_calls": 18942,
                    "cost": 287.50,
                    "health": "excellent"
                },
                {
                    "name": "Planning Portal",
                    "type": "planning_portal",
                    "monthly_calls": 8432,
                    "cost": 156.30,
                    "health": "excellent"
                },
                {
                    "name": "Companies House",
                    "type": "government_api",
                    "monthly_calls": 6234,
                    "cost": 89.20,
                    "health": "good"
                }
            ],
            "recent_activity": [
                {
                    "timestamp": "2024-10-03T14:45:23Z",
                    "integration": "Ordnance Survey",
                    "action": "Property lookup completed",
                    "status": "success",
                    "response_time": 1.2
                },
                {
                    "timestamp": "2024-10-03T14:44:18Z",
                    "integration": "Planning Portal",
                    "action": "Application submitted",
                    "status": "success",
                    "response_time": 3.4
                },
                {
                    "timestamp": "2024-10-03T14:43:42Z",
                    "integration": "Companies House",
                    "action": "Company search",
                    "status": "rate_limited",
                    "response_time": 0.5
                }
            ],
            "alerts": [
                {
                    "type": "warning",
                    "title": "Rate Limit Approaching",
                    "message": "Companies House API approaching daily rate limit (85% used)",
                    "timestamp": "2024-10-03T14:30:00Z"
                },
                {
                    "type": "error",
                    "title": "Connection Failed",
                    "message": "HubSpot CRM authentication failed - requires reconnection",
                    "timestamp": "2024-10-03T13:15:00Z"
                }
            ]
        }
        
        return {
            "success": True,
            "overview": overview_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch integrations overview: {str(e)}")

@app.get("/api/integrations")
async def get_all_integrations():
    """Get list of all configured integrations"""
    try:
        integrations = [
            {
                "id": "planning_portal_uk",
                "name": "UK Planning Portal",
                "type": "planning_portal",
                "category": "Government Portal",
                "status": "connected",
                "health": "excellent",
                "uptime": 99.9,
                "last_sync": "2024-10-03T14:30:00Z",
                "monthly_calls": 8432,
                "success_rate": 94.2,
                "average_response_time": 2.8,
                "configuration": {
                    "endpoint": "https://www.planningportal.co.uk/api/v1",
                    "auth_method": "oauth2",
                    "auto_submit": True,
                    "retry_failed": True
                },
                "metrics": {
                    "applications_submitted": 1247,
                    "success_rate": 94.2,
                    "avg_processing_time": "3.2 days"
                }
            },
            {
                "id": "ordnance_survey",
                "name": "Ordnance Survey",
                "type": "mapping_service",
                "category": "Mapping Service",
                "status": "connected",
                "health": "excellent",
                "uptime": 98.7,
                "last_sync": "2024-10-03T14:45:00Z",
                "monthly_calls": 18942,
                "success_rate": 99.1,
                "average_response_time": 2.1,
                "configuration": {
                    "license_type": "premium",
                    "api_key": "os_***********",
                    "quota_limit": 50000,
                    "quota_used": 24567
                },
                "metrics": {
                    "map_requests": 18942,
                    "quota_usage": "49.1%",
                    "cost_this_month": 287.50
                }
            },
            {
                "id": "companies_house",
                "name": "Companies House",
                "type": "government_api",
                "category": "Government API",
                "status": "connected",
                "health": "good",
                "uptime": 99.5,
                "last_sync": "2024-10-03T14:40:00Z",
                "monthly_calls": 6234,
                "success_rate": 97.8,
                "average_response_time": 1.8,
                "configuration": {
                    "api_key": "ch_***********",
                    "rate_limit": 600,
                    "cache_duration": 3600
                },
                "metrics": {
                    "company_lookups": 6234,
                    "director_searches": 1847,
                    "filing_checks": 892
                }
            },
            {
                "id": "stripe_payments",
                "name": "Stripe",
                "type": "financial_system",
                "category": "Payment Gateway",
                "status": "connected",
                "health": "excellent",
                "uptime": 99.9,
                "last_sync": "2024-10-03T14:50:00Z",
                "monthly_calls": 3456,
                "success_rate": 99.8,
                "average_response_time": 1.2,
                "configuration": {
                    "mode": "live",
                    "webhook_enabled": True,
                    "auto_capture": True
                },
                "metrics": {
                    "transactions_processed": 847,
                    "total_amount": 247000,
                    "fees_paid": 6892.50
                }
            },
            {
                "id": "sendgrid_email",
                "name": "SendGrid",
                "type": "communication",
                "category": "Email Service",
                "status": "pending",
                "health": "warning",
                "uptime": 98.2,
                "last_sync": "2024-10-03T12:15:00Z",
                "monthly_calls": 2847,
                "success_rate": 96.4,
                "average_response_time": 3.1,
                "configuration": {
                    "api_key": "sg_***********",
                    "template_engine": "handlebars",
                    "tracking_enabled": True
                },
                "metrics": {
                    "emails_sent": 12456,
                    "delivery_rate": 96.4,
                    "open_rate": 23.7
                },
                "issues": ["API key requires renewal"]
            },
            {
                "id": "hubspot_crm",
                "name": "HubSpot CRM",
                "type": "crm",
                "category": "CRM Platform",
                "status": "disconnected",
                "health": "error",
                "uptime": 0,
                "last_sync": "2024-10-01T16:30:00Z",
                "monthly_calls": 0,
                "success_rate": 0,
                "average_response_time": 0,
                "configuration": {
                    "client_id": "hs_***********",
                    "scopes": ["contacts", "companies", "deals"],
                    "webhook_url": "/webhooks/hubspot"
                },
                "metrics": {
                    "contacts_synced": 2847,
                    "last_successful_sync": "2024-10-01T16:30:00Z"
                },
                "issues": ["OAuth token expired", "Requires re-authentication"]
            }
        ]
        
        return {
            "success": True,
            "integrations": integrations,
            "summary": {
                "total": len(integrations),
                "connected": len([i for i in integrations if i["status"] == "connected"]),
                "pending": len([i for i in integrations if i["status"] == "pending"]),
                "disconnected": len([i for i in integrations if i["status"] == "disconnected"])
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch integrations: {str(e)}")

@app.get("/api/integrations/planning-portals")
async def get_planning_portals():
    """Get planning portal integrations data"""
    try:
        planning_data = {
            "primary_portal": {
                "name": "UK Planning Portal",
                "status": "connected",
                "applications_submitted": 1247,
                "success_rate": 94.2,
                "average_processing_time": "3.2 days",
                "supported_authorities": 348,
                "api_version": "v1.2",
                "last_submission": "2024-10-03T14:32:15Z"
            },
            "local_authorities": [
                {
                    "name": "Westminster City Council",
                    "code": "E09000033",
                    "status": "connected",
                    "applications": 156,
                    "success_rate": 97.4,
                    "avg_decision_time": "8.2 weeks",
                    "last_submission": "2024-10-03T14:32:15Z"
                },
                {
                    "name": "Camden Council",
                    "code": "E09000007",
                    "status": "connected",
                    "applications": 134,
                    "success_rate": 92.5,
                    "avg_decision_time": "7.8 weeks",
                    "last_submission": "2024-10-03T13:15:42Z"
                },
                {
                    "name": "Tower Hamlets",
                    "code": "E09000030",
                    "status": "connected",
                    "applications": 98,
                    "success_rate": 89.8,
                    "avg_decision_time": "9.1 weeks",
                    "last_submission": "2024-10-03T11:45:23Z"
                },
                {
                    "name": "Southwark Council",
                    "code": "E09000028",
                    "status": "warning",
                    "applications": 87,
                    "success_rate": 91.2,
                    "avg_decision_time": "8.7 weeks",
                    "last_submission": "2024-10-02T16:30:12Z",
                    "issues": ["Intermittent connection timeouts"]
                }
            ],
            "submission_statistics": {
                "total_applications": 1247,
                "approved": 734,
                "rejected": 189,
                "pending": 284,
                "withdrawn": 40,
                "approval_rate": 79.5,
                "avg_processing_time": "8.4 weeks"
            },
            "recent_activity": [
                {
                    "timestamp": "2024-10-03T14:32:15Z",
                    "action": "Application submitted",
                    "reference": "PLN/2024/0847",
                    "authority": "Westminster City Council",
                    "status": "success"
                },
                {
                    "timestamp": "2024-10-03T14:28:42Z",
                    "action": "Status update received",
                    "reference": "PLN/2024/0834",
                    "authority": "Camden Council",
                    "status": "under_review"
                },
                {
                    "timestamp": "2024-10-03T13:54:18Z",
                    "action": "Document upload",
                    "reference": "PLN/2024/0841",
                    "authority": "Tower Hamlets",
                    "status": "success"
                }
            ],
            "configuration": {
                "auto_submit_enabled": True,
                "notification_webhooks": True,
                "document_auto_upload": True,
                "status_polling_interval": 3600,
                "backup_submission_method": "manual_portal"
            }
        }
        
        return {
            "success": True,
            "planning_portals": planning_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch planning portals data: {str(e)}")

@app.get("/api/integrations/government-apis")
async def get_government_apis():
    """Get government API integrations data"""
    try:
        government_data = {
            "active_apis": [
                {
                    "name": "Companies House API",
                    "endpoint": "https://api.company-information.service.gov.uk",
                    "status": "connected",
                    "api_version": "v1",
                    "rate_limit": 600,
                    "rate_used": 468,
                    "monthly_calls": 6234,
                    "success_rate": 97.8,
                    "average_response_time": 1.8,
                    "data_types": ["company_profile", "officers", "filing_history", "charges"],
                    "cost_per_call": 0.00,
                    "last_call": "2024-10-03T14:40:00Z"
                },
                {
                    "name": "Environment Agency API",
                    "endpoint": "https://environment.data.gov.uk/flood-monitoring",
                    "status": "connected",
                    "api_version": "v1",
                    "rate_limit": 1000,
                    "rate_used": 234,
                    "monthly_calls": 4231,
                    "success_rate": 98.9,
                    "average_response_time": 2.3,
                    "data_types": ["flood_warnings", "water_levels", "pollution_incidents"],
                    "cost_per_call": 0.00,
                    "last_call": "2024-10-03T14:15:00Z"
                },
                {
                    "name": "Land Registry API",
                    "endpoint": "https://landregistry.data.gov.uk",
                    "status": "pending_authorization",
                    "api_version": "v1",
                    "application_date": "2024-09-28",
                    "estimated_approval": "2024-10-15",
                    "data_types": ["property_prices", "ownership_data", "land_boundaries"],
                    "cost_per_call": 0.05,
                    "use_cases": ["property_valuation", "due_diligence", "market_analysis"]
                },
                {
                    "name": "ONS Postcode Directory",
                    "endpoint": "https://api.postcodes.io",
                    "status": "connected",
                    "api_version": "v1",
                    "rate_limit": 1000,
                    "rate_used": 156,
                    "monthly_calls": 3847,
                    "success_rate": 99.2,
                    "average_response_time": 0.8,
                    "data_types": ["postcode_lookup", "coordinates", "administrative_areas"],
                    "cost_per_call": 0.00,
                    "last_call": "2024-10-03T14:30:00Z"
                }
            ],
            "usage_statistics": {
                "total_monthly_calls": 14312,
                "total_cost": 187.50,
                "average_response_time": 1.7,
                "overall_success_rate": 98.2,
                "data_freshness": "Real-time"
            },
            "compliance_status": {
                "gdpr_compliant": True,
                "data_retention_policy": "12 months",
                "audit_trail_enabled": True,
                "encryption_in_transit": True,
                "encryption_at_rest": True
            },
            "pending_integrations": [
                {
                    "name": "HMRC VAT API",
                    "purpose": "VAT number validation",
                    "status": "application_submitted",
                    "estimated_completion": "2024-10-20"
                },
                {
                    "name": "NHS Postcode Lookup",
                    "purpose": "Healthcare facility mapping",
                    "status": "awaiting_approval",
                    "estimated_completion": "2024-11-05"
                }
            ]
        }
        
        return {
            "success": True,
            "government_apis": government_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch government APIs data: {str(e)}")

@app.get("/api/integrations/mapping-services")
async def get_mapping_services():
    """Get mapping services integrations data"""
    try:
        mapping_data = {
            "primary_services": [
                {
                    "name": "Ordnance Survey",
                    "type": "UK National Mapping",
                    "status": "connected",
                    "license_type": "Premium",
                    "monthly_quota": 50000,
                    "quota_used": 24567,
                    "quota_percentage": 49.1,
                    "cost_this_month": 287.50,
                    "services_used": ["OS Maps API", "Places API", "Routing API"],
                    "data_layers": ["base_maps", "aerial_imagery", "height_data", "boundaries"],
                    "accuracy": "Sub-meter",
                    "update_frequency": "Daily",
                    "coverage": "United Kingdom"
                },
                {
                    "name": "Google Maps Platform",
                    "type": "Global Mapping",
                    "status": "connected",
                    "api_keys": 3,
                    "monthly_quota": 100000,
                    "quota_used": 18942,
                    "quota_percentage": 18.9,
                    "cost_this_month": 234.70,
                    "services_used": ["Maps JavaScript API", "Geocoding API", "Places API"],
                    "features": ["satellite_imagery", "street_view", "traffic_data", "business_listings"],
                    "accuracy": "Building-level",
                    "update_frequency": "Real-time",
                    "coverage": "Global"
                },
                {
                    "name": "ESRI ArcGIS",
                    "type": "Professional GIS",
                    "status": "license_expired",
                    "license_expiry": "2024-09-30",
                    "renewal_cost": 1200.00,
                    "last_used": "2024-09-29T16:45:00Z",
                    "services_used": ["World Geocoding Service", "Analysis Services", "Basemap Services"],
                    "features": ["advanced_analytics", "spatial_analysis", "3d_mapping", "network_analysis"],
                    "accuracy": "Survey-grade",
                    "coverage": "Global"
                }
            ],
            "usage_analytics": {
                "total_map_requests": 43509,
                "geocoding_requests": 18942,
                "routing_requests": 8734,
                "places_searches": 5621,
                "aerial_imagery_requests": 10212,
                "average_response_time": 2.1,
                "success_rate": 98.7,
                "total_monthly_cost": 522.20
            },
            "performance_metrics": {
                "fastest_service": "Google Maps Geocoding (0.8s avg)",
                "most_reliable": "Ordnance Survey (99.9% uptime)",
                "most_cost_effective": "OS Maps API (Â£0.006 per request)",
                "highest_accuracy": "Ordnance Survey (sub-meter precision)"
            },
            "geographic_coverage": {
                "uk_requests": 78.3,
                "europe_requests": 15.2,
                "global_requests": 6.5
            },
            "integration_features": {
                "caching_enabled": True,
                "fallback_providers": True,
                "load_balancing": True,
                "request_optimization": True,
                "batch_processing": True
            }
        }
        
        return {
            "success": True,
            "mapping_services": mapping_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch mapping services data: {str(e)}")

@app.get("/api/integrations/financial-systems")
async def get_financial_systems():
    """Get financial systems integrations data"""
    try:
        financial_data = {
            "payment_processors": [
                {
                    "name": "Stripe",
                    "type": "Payment Gateway",
                    "status": "connected",
                    "environment": "live",
                    "monthly_volume": 247000,
                    "transaction_count": 847,
                    "success_rate": 99.8,
                    "average_processing_time": 1.2,
                    "fees_this_month": 6892.50,
                    "supported_methods": ["card", "apple_pay", "google_pay", "sepa", "bacs"],
                    "features": ["subscriptions", "invoicing", "marketplace", "connect"],
                    "webhook_events": 34,
                    "last_transaction": "2024-10-03T14:50:00Z"
                },
                {
                    "name": "PayPal",
                    "type": "Payment Gateway",
                    "status": "connected",
                    "environment": "live",
                    "monthly_volume": 89300,
                    "transaction_count": 234,
                    "success_rate": 97.4,
                    "average_processing_time": 2.8,
                    "fees_this_month": 2634.70,
                    "supported_methods": ["paypal", "card", "pay_in_4"],
                    "features": ["express_checkout", "subscriptions", "invoicing"],
                    "webhook_events": 12,
                    "last_transaction": "2024-10-03T13:20:00Z"
                }
            ],
            "accounting_software": [
                {
                    "name": "Xero",
                    "type": "Cloud Accounting",
                    "status": "connected",
                    "sync_frequency": "4 hours",
                    "last_sync": "2024-10-03T12:00:00Z",
                    "invoices_synced": 1847,
                    "contacts_synced": 456,
                    "transactions_synced": 3421,
                    "bank_accounts_connected": 3,
                    "features": ["invoicing", "expense_management", "bank_reconciliation", "reporting"],
                    "sync_status": "healthy",
                    "data_lag": "2.3 hours"
                },
                {
                    "name": "QuickBooks Online",
                    "type": "Cloud Accounting",
                    "status": "disconnected",
                    "last_sync": "2024-09-15T10:30:00Z",
                    "reason": "Subscription expired",
                    "renewal_date": "2024-10-15",
                    "features": ["invoicing", "payroll", "tax_preparation", "inventory"],
                    "migration_status": "data_exported"
                }
            ],
            "banking_apis": [
                {
                    "name": "Open Banking",
                    "type": "Banking API",
                    "status": "setup_required",
                    "supported_banks": ["Barclays", "HSBC", "Lloyds", "NatWest", "Santander"],
                    "features": ["account_information", "payment_initiation", "balance_checking"],
                    "compliance": "PSD2 compliant",
                    "setup_progress": 25
                }
            ],
            "financial_metrics": {
                "total_processed": 336300,
                "total_fees": 9527.20,
                "average_transaction_value": 311.50,
                "reconciliation_accuracy": 98.7,
                "automated_entries": 89.3,
                "cash_flow_forecast_accuracy": 94.2
            },
            "integration_health": {
                "stripe": "excellent",
                "paypal": "good",
                "xero": "excellent",
                "quickbooks": "disconnected",
                "open_banking": "pending_setup"
            }
        }
        
        return {
            "success": True,
            "financial_systems": financial_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch financial systems data: {str(e)}")

@app.get("/api/integrations/marketplace")
async def get_integration_marketplace():
    """Get available integrations from marketplace"""
    try:
        marketplace_data = {
            "featured_integrations": [
                {
                    "id": "autocad_integration",
                    "name": "AutoCAD Integration",
                    "category": "Design Tools",
                    "description": "Import and export CAD drawings directly from AutoCAD. Streamline your design workflow with automatic file conversion.",
                    "publisher": "Autodesk",
                    "version": "2.1.4",
                    "rating": 4.8,
                    "reviews": 127,
                    "downloads": 2847,
                    "price": "Â£29.99/month",
                    "featured": True,
                    "tags": ["cad", "design", "drawings", "autocad"],
                    "screenshots": 5,
                    "documentation_url": "/docs/autocad-integration",
                    "support_url": "/support/autocad"
                },
                {
                    "id": "microsoft_teams",
                    "name": "Microsoft Teams",
                    "category": "Communication",
                    "description": "Send notifications and updates directly to Microsoft Teams channels. Keep your team informed in real-time.",
                    "publisher": "Microsoft",
                    "version": "1.8.2",
                    "rating": 4.6,
                    "reviews": 89,
                    "downloads": 1653,
                    "price": "Free",
                    "featured": False,
                    "tags": ["teams", "notifications", "communication", "microsoft"],
                    "screenshots": 3,
                    "documentation_url": "/docs/teams-integration",
                    "support_url": "/support/teams"
                },
                {
                    "id": "slack_integration",
                    "name": "Slack Integration",
                    "category": "Communication",
                    "description": "Connect with Slack for team communication and automated notifications about project updates and deadlines.",
                    "publisher": "Slack Technologies",
                    "version": "3.2.1",
                    "rating": 4.9,
                    "reviews": 203,
                    "downloads": 3421,
                    "price": "Free",
                    "featured": False,
                    "tags": ["slack", "chat", "notifications", "team"],
                    "screenshots": 4,
                    "documentation_url": "/docs/slack-integration",
                    "support_url": "/support/slack"
                }
            ],
            "categories": [
                {"name": "Communication", "count": 12, "popular": True},
                {"name": "Design Tools", "count": 8, "popular": True},
                {"name": "Financial", "count": 15, "popular": True},
                {"name": "Mapping", "count": 6, "popular": False},
                {"name": "Government APIs", "count": 9, "popular": False},
                {"name": "CRM", "count": 11, "popular": True},
                {"name": "Document Management", "count": 7, "popular": False},
                {"name": "Analytics", "count": 5, "popular": False}
            ],
            "recently_added": [
                {
                    "name": "DocuSign",
                    "category": "Document Management",
                    "rating": 4.7,
                    "price": "Â£15.99/month",
                    "added_date": "2024-09-28"
                },
                {
                    "name": "Mailchimp",
                    "category": "Marketing",
                    "rating": 4.4,
                    "price": "Free tier available",
                    "added_date": "2024-09-25"
                }
            ],
            "installation_stats": {
                "total_available": 68,
                "most_downloaded": "Slack Integration",
                "highest_rated": "Slack Integration (4.9â˜…)",
                "newest": "DocuSign (28 Sep 2024)",
                "trending": "AutoCAD Integration (+45% this month)"
            }
        }
        
        return {
            "success": True,
            "marketplace": marketplace_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch marketplace data: {str(e)}")

@app.post("/api/integrations")
async def create_integration(integration: IntegrationConfig):
    """Create a new integration configuration"""
    try:
        integration_id = f"integration_{int(time.time())}"
        
        # Validate configuration
        if integration.authentication_method == "api_key" and not integration.api_key:
            raise HTTPException(status_code=400, detail="API key required for API key authentication")
        
        if integration.authentication_method == "oauth2" and (not integration.client_id or not integration.client_secret):
            raise HTTPException(status_code=400, detail="Client ID and secret required for OAuth2 authentication")
        
        return {
            "success": True,
            "integration_id": integration_id,
            "integration": {
                "name": integration.name,
                "type": integration.type,
                "endpoint_url": integration.endpoint_url,
                "authentication_method": integration.authentication_method,
                "enabled": integration.enabled,
                "timeout": integration.timeout,
                "retry_attempts": integration.retry_attempts,
                "created_at": datetime.now().isoformat()
            },
            "next_steps": [
                "Test connection to verify configuration",
                "Configure webhooks if supported",
                "Set up monitoring and alerts",
                "Enable production mode"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create integration: {str(e)}")

@app.post("/api/integrations/{integration_id}/test")
async def test_integration(integration_id: str, test_request: APITestRequest):
    """Test an integration connection"""
    try:
        # Simulate API test
        test_results = {
            "integration_id": integration_id,
            "test_timestamp": datetime.now().isoformat(),
            "connection_status": "success",
            "response_time": 1.234,
            "status_code": 200,
            "response_size": 2048,
            "authentication": "valid",
            "rate_limit_status": {
                "limit": 1000,
                "remaining": 847,
                "reset_time": (datetime.now() + timedelta(hours=1)).isoformat()
            },
            "endpoint_health": "healthy",
            "ssl_certificate": "valid",
            "api_version": "v1.2.3"
        }
        
        return {
            "success": True,
            "test_results": test_results,
            "recommendations": [
                "Connection is healthy and responsive",
                "Authentication is working correctly",
                "Rate limits are within acceptable range"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to test integration: {str(e)}")

@app.get("/api/integrations/{integration_id}/logs")
async def get_integration_logs(integration_id: str, limit: int = 50):
    """Get logs for a specific integration"""
    try:
        logs = [
            {
                "timestamp": "2024-10-03T14:45:23Z",
                "level": "info",
                "method": "GET",
                "endpoint": "/api/property/lookup",
                "status_code": 200,
                "response_time": 1.2,
                "message": "Property lookup completed successfully"
            },
            {
                "timestamp": "2024-10-03T14:44:18Z",
                "level": "info",
                "method": "POST",
                "endpoint": "/api/planning/submit",
                "status_code": 201,
                "response_time": 3.4,
                "message": "Planning application submitted"
            },
            {
                "timestamp": "2024-10-03T14:43:42Z",
                "level": "warning",
                "method": "GET",
                "endpoint": "/api/companies/search",
                "status_code": 429,
                "response_time": 0.5,
                "message": "Rate limit exceeded, retrying in 60 seconds"
            },
            {
                "timestamp": "2024-10-03T14:42:15Z",
                "level": "info",
                "method": "POST",
                "endpoint": "/api/payments/create",
                "status_code": 200,
                "response_time": 2.1,
                "message": "Payment processed successfully"
            },
            {
                "timestamp": "2024-10-03T14:41:33Z",
                "level": "error",
                "method": "GET",
                "endpoint": "/api/maps/geocode",
                "status_code": 503,
                "response_time": 30.0,
                "message": "Service temporarily unavailable"
            }
        ]
        
        return {
            "success": True,
            "integration_id": integration_id,
            "logs": logs[:limit],
            "total_logs": len(logs),
            "log_levels": {
                "info": len([l for l in logs if l["level"] == "info"]),
                "warning": len([l for l in logs if l["level"] == "warning"]),
                "error": len([l for l in logs if l["level"] == "error"])
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch integration logs: {str(e)}")

@app.post("/api/integrations/{integration_id}/webhooks")
async def configure_webhook(integration_id: str, webhook: WebhookConfig):
    """Configure webhook for an integration"""
    try:
        webhook_id = f"webhook_{int(time.time())}"
        
        return {
            "success": True,
            "webhook_id": webhook_id,
            "integration_id": integration_id,
            "webhook": {
                "url": webhook.url,
                "events": webhook.events,
                "enabled": webhook.enabled,
                "created_at": datetime.now().isoformat()
            },
            "verification": {
                "challenge_sent": True,
                "verification_status": "pending",
                "retry_count": 0
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to configure webhook: {str(e)}")

# ================================
# MOBILE OPTIMIZATION & PWA SYSTEM
# ================================

class PushSubscription(BaseModel):
    endpoint: str
    keys: dict
    user_id: Optional[str] = None

class NotificationPayload(BaseModel):
    title: str
    body: str
    icon: Optional[str] = "/static/icons/icon-192x192.png"
    badge: Optional[str] = "/static/icons/badge-72x72.png"
    type: Optional[str] = None
    data: dict = {}
    actions: List[dict] = []
    vibrate: List[int] = [100, 50, 100]
    require_interaction: bool = False

@app.get("/mobile-optimization")
async def mobile_optimization(request: Request):
    """Mobile Optimization main page"""
    return templates.TemplateResponse("mobile_optimization.html", {"request": request})

@app.get("/manifest.json")
async def get_manifest():
    """Serve PWA manifest file"""
    try:
        with open("static/manifest.json", "r") as f:
            manifest_data = json.load(f)
        return manifest_data
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load manifest: {str(e)}")

@app.get("/offline")
async def offline_page(request: Request):
    """Offline fallback page"""
    return templates.TemplateResponse("offline.html", {"request": request})

@app.get("/api/pwa/status")
async def get_pwa_status():
    """Get PWA installation and feature status"""
    try:
        pwa_status = {
            "pwa_enabled": True,
            "service_worker_registered": True,
            "manifest_valid": True,
            "installation_prompt_available": True,
            "features": {
                "offline_support": True,
                "background_sync": True,
                "push_notifications": True,
                "add_to_homescreen": True,
                "full_screen_mode": True,
                "orientation_lock": True,
                "theme_color": True,
                "splash_screen": True
            },
            "performance_metrics": {
                "lighthouse_pwa_score": 98,
                "first_contentful_paint": 1.2,
                "largest_contentful_paint": 1.8,
                "first_input_delay": 0.1,
                "cumulative_layout_shift": 0.05,
                "time_to_interactive": 2.1
            },
            "cache_statistics": {
                "cached_resources": 247,
                "cache_size_mb": 5.4,
                "cache_hit_rate": 94.7,
                "offline_pages_available": 12,
                "last_cache_update": datetime.now().isoformat()
            },
            "installation_stats": {
                "total_installs": 1847,
                "active_installs": 1234,
                "install_conversion_rate": 23.4,
                "average_session_duration": "8m 42s",
                "retention_rate_7_day": 78.9
            }
        }
        
        return {
            "success": True,
            "pwa_status": pwa_status,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch PWA status: {str(e)}")

@app.get("/api/mobile/performance")
async def get_mobile_performance():
    """Get mobile performance metrics and optimization data"""
    try:
        performance_data = {
            "core_web_vitals": {
                "largest_contentful_paint": {
                    "value": 1.2,
                    "rating": "good",
                    "threshold_good": 2.5,
                    "threshold_poor": 4.0
                },
                "first_input_delay": {
                    "value": 0.1,
                    "rating": "good",
                    "threshold_good": 0.1,
                    "threshold_poor": 0.3
                },
                "cumulative_layout_shift": {
                    "value": 0.05,
                    "rating": "good",
                    "threshold_good": 0.1,
                    "threshold_poor": 0.25
                },
                "first_contentful_paint": {
                    "value": 1.0,
                    "rating": "good",
                    "threshold_good": 1.8,
                    "threshold_poor": 3.0
                }
            },
            "lighthouse_scores": {
                "performance": 98,
                "accessibility": 95,
                "best_practices": 92,
                "seo": 96,
                "pwa": 98,
                "overall_score": 95.8
            },
            "resource_optimization": {
                "total_resources": 67,
                "compressed_resources": 64,
                "cached_resources": 58,
                "lazy_loaded_images": 23,
                "webp_images": 31,
                "minified_css": True,
                "minified_js": True,
                "gzip_compression": True
            },
            "bundle_analysis": {
                "total_bundle_size": "342KB",
                "main_bundle": "187KB",
                "vendor_bundle": "155KB",
                "code_splitting_enabled": True,
                "tree_shaking_enabled": True,
                "unused_code_elimination": 89.3
            },
            "network_optimization": {
                "http2_enabled": True,
                "cdn_usage": True,
                "preload_critical_resources": True,
                "dns_prefetch": True,
                "resource_hints": True,
                "critical_css_inlined": True
            },
            "device_compatibility": {
                "responsive_design": True,
                "touch_friendly": True,
                "safe_area_support": True,
                "orientation_support": True,
                "high_dpi_support": True,
                "dark_mode_support": True
            },
            "performance_monitoring": {
                "real_user_monitoring": True,
                "synthetic_monitoring": True,
                "error_tracking": True,
                "performance_budget": True,
                "alerts_configured": True
            }
        }
        
        return {
            "success": True,
            "performance": performance_data,
            "measurement_timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch performance data: {str(e)}")

@app.get("/api/mobile/offline")
async def get_offline_capabilities():
    """Get offline functionality and cached content information"""
    try:
        offline_data = {
            "offline_status": {
                "service_worker_active": True,
                "cache_enabled": True,
                "background_sync_enabled": True,
                "offline_pages_available": True,
                "offline_functionality_score": 94.2
            },
            "cached_content": {
                "pages": [
                    {"url": "/", "title": "Dashboard", "size": "124KB", "last_updated": "2024-10-03T14:30:00Z"},
                    {"url": "/projects", "title": "Projects", "size": "89KB", "last_updated": "2024-10-03T14:25:00Z"},
                    {"url": "/planning-ai", "title": "Planning AI", "size": "156KB", "last_updated": "2024-10-03T14:20:00Z"},
                    {"url": "/tasks", "title": "Tasks", "size": "78KB", "last_updated": "2024-10-03T14:15:00Z"},
                    {"url": "/communications", "title": "Communications", "size": "92KB", "last_updated": "2024-10-03T14:10:00Z"},
                    {"url": "/documents", "title": "Documents", "size": "134KB", "last_updated": "2024-10-03T14:05:00Z"}
                ],
                "static_assets": {
                    "css_files": 12,
                    "js_files": 18,
                    "images": 45,
                    "fonts": 6,
                    "total_size": "2.8MB"
                },
                "api_cache": {
                    "dashboard_data": "2024-10-03T14:30:00Z",
                    "project_list": "2024-10-03T14:25:00Z",
                    "notifications": "2024-10-03T14:20:00Z",
                    "user_profile": "2024-10-03T13:45:00Z"
                }
            },
            "offline_features": {
                "view_projects": {
                    "available": True,
                    "functionality": "Full read access to cached projects",
                    "limitations": "Cannot create new projects offline"
                },
                "task_management": {
                    "available": True,
                    "functionality": "View and mark tasks complete (syncs when online)",
                    "limitations": "Cannot assign tasks or add comments offline"
                },
                "document_access": {
                    "available": True,
                    "functionality": "Access to downloaded/cached documents",
                    "limitations": "Cannot upload new documents offline"
                },
                "communications": {
                    "available": True,
                    "functionality": "Read cached messages and compose drafts",
                    "limitations": "Messages sent when back online"
                },
                "reporting": {
                    "available": False,
                    "functionality": "Limited to cached report data",
                    "limitations": "Real-time analytics require internet connection"
                }
            },
            "sync_strategy": {
                "background_sync_enabled": True,
                "sync_on_reconnect": True,
                "conflict_resolution": "last_write_wins",
                "retry_attempts": 3,
                "retry_intervals": [30, 300, 1800],
                "pending_sync_queue": 0
            },
            "storage_management": {
                "total_quota": "100MB",
                "used_storage": "5.4MB",
                "available_storage": "94.6MB",
                "auto_cleanup_enabled": True,
                "cache_ttl": "7 days",
                "priority_caching": True
            }
        }
        
        return {
            "success": True,
            "offline": offline_data,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch offline data: {str(e)}")

@app.post("/api/mobile/notifications/subscribe")
async def subscribe_to_notifications(subscription: PushSubscription):
    """Subscribe user to push notifications"""
    try:
        subscription_id = f"sub_{int(time.time())}"
        
        # In a real implementation, store subscription in database
        # and associate with user account
        
        return {
            "success": True,
            "subscription_id": subscription_id,
            "subscription": {
                "endpoint": subscription.endpoint,
                "user_id": subscription.user_id,
                "created_at": datetime.now().isoformat(),
                "status": "active"
            },
            "notification_types": [
                "project_updates",
                "task_assignments", 
                "planning_status",
                "document_approvals",
                "communications",
                "system_alerts"
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to subscribe to notifications: {str(e)}")

@app.post("/api/mobile/notifications/send")
async def send_push_notification(notification: NotificationPayload):
    """Send push notification to subscribed users"""
    try:
        notification_id = f"notif_{int(time.time())}"
        
        # In a real implementation, this would:
        # 1. Get all subscribed users
        # 2. Send push notifications via Web Push protocol
        # 3. Handle failed deliveries and update subscription status
        
        return {
            "success": True,
            "notification_id": notification_id,
            "notification": {
                "title": notification.title,
                "body": notification.body,
                "type": notification.type,
                "sent_at": datetime.now().isoformat()
            },
            "delivery_stats": {
                "total_subscribers": 1234,
                "successful_deliveries": 1189,
                "failed_deliveries": 45,
                "delivery_rate": 96.4
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to send notification: {str(e)}")

@app.get("/api/mobile/notifications/history")
async def get_notification_history(limit: int = 50):
    """Get notification history for the user"""
    try:
        notifications = [
            {
                "id": "notif_001",
                "title": "Project Update",
                "body": "Riverside Development project status changed to 'In Review'",
                "type": "project_update",
                "read": True,
                "sent_at": "2024-10-03T14:30:00Z",
                "data": {"project_id": "proj_001"}
            },
            {
                "id": "notif_002",
                "title": "New Task Assigned",
                "body": "You have been assigned to review environmental impact assessment",
                "type": "task_assignment",
                "read": False,
                "sent_at": "2024-10-03T13:45:00Z",
                "data": {"task_id": "task_234"}
            },
            {
                "id": "notif_003",
                "title": "Planning Application Approved",
                "body": "Application PLN/2024/0847 has been approved by Westminster Council",
                "type": "planning_status",
                "read": True,
                "sent_at": "2024-10-03T12:20:00Z",
                "data": {"application_id": "PLN/2024/0847"}
            },
            {
                "id": "notif_004",
                "title": "Document Ready for Review",
                "body": "Heritage Conservation Report requires your approval",
                "type": "document_approval",
                "read": False,
                "sent_at": "2024-10-03T11:15:00Z",
                "data": {"document_id": "doc_456"}
            },
            {
                "id": "notif_005",
                "title": "New Message",
                "body": "Sarah Johnson sent you a message about the City Centre Plaza project",
                "type": "communication",
                "read": False,
                "sent_at": "2024-10-03T10:30:00Z",
                "data": {"message_id": "msg_789"}
            }
        ]
        
        return {
            "success": True,
            "notifications": notifications[:limit],
            "total_count": len(notifications),
            "unread_count": len([n for n in notifications if not n["read"]]),
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch notification history: {str(e)}")

@app.post("/api/mobile/cache/clear")
async def clear_mobile_cache():
    """Clear mobile app cache"""
    try:
        # In a real implementation, this would trigger cache clearing
        # via service worker messaging
        
        return {
            "success": True,
            "cache_cleared": True,
            "freed_space": "5.4MB",
            "cleared_items": {
                "pages": 12,
                "api_responses": 45,
                "static_assets": 67,
                "images": 31
            },
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to clear cache: {str(e)}")

@app.post("/api/mobile/offline/download")
async def download_offline_content():
    """Download content for offline access"""
    try:
        # In a real implementation, this would trigger the service worker
        # to download and cache additional content
        
        return {
            "success": True,
            "download_started": True,
            "estimated_size": "12.8MB",
            "estimated_time": "2-3 minutes",
            "content_types": [
                "Recent project data",
                "Task assignments",
                "Cached documents",
                "Communication history",
                "Application templates"
            ],
            "download_id": f"download_{int(time.time())}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start offline download: {str(e)}")

@app.get("/api/mobile/device-info")
async def get_device_info(request: Request):
    """Get device and browser capability information"""
    try:
        user_agent = request.headers.get("user-agent", "")
        
        device_info = {
            "user_agent": user_agent,
            "capabilities": {
                "service_worker": True,
                "push_notifications": True,
                "background_sync": True,
                "web_app_manifest": True,
                "add_to_homescreen": True,
                "fullscreen_api": True,
                "orientation_api": True,
                "vibration_api": True,
                "geolocation": True,
                "camera_access": True,
                "local_storage": True,
                "indexed_db": True,
                "web_share_api": True
            },
            "pwa_features": {
                "standalone_mode": True,
                "theme_color": True,
                "splash_screen": True,
                "app_shortcuts": True,
                "share_target": True,
                "background_fetch": True,
                "periodic_sync": True,
                "badging_api": True
            },
            "performance_apis": {
                "performance_observer": True,
                "navigation_timing": True,
                "resource_timing": True,
                "paint_timing": True,
                "layout_instability": True,
                "largest_contentful_paint": True,
                "first_input_delay": True
            },
            "security_features": {
                "https_required": True,
                "secure_context": True,
                "content_security_policy": True,
                "permissions_api": True,
                "credential_management": True
            }
        }
        
        return {
            "success": True,
            "device_info": device_info,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get device info: {str(e)}")

# =======================================
# ADVANCED SECURITY & COMPLIANCE SYSTEM
# =======================================

class SecurityEvent(BaseModel):
    event_type: str
    severity: str
    description: str
    source_ip: Optional[str] = None
    user_id: Optional[str] = None
    resource: Optional[str] = None
    metadata: dict = {}

class ComplianceAssessment(BaseModel):
    regulation: str
    status: str
    score: float
    findings: List[str] = []
    recommendations: List[str] = []
    last_assessment: str

class AuditLogQuery(BaseModel):
    start_date: Optional[str] = None
    end_date: Optional[str] = None
    event_type: Optional[str] = None
    user_id: Optional[str] = None
    limit: int = 100

@app.get("/security-compliance")
async def security_compliance(request: Request):
    """Security & Compliance main dashboard"""
    return templates.TemplateResponse("security_compliance.html", {"request": request})

@app.get("/enterprise-management")
async def enterprise_management(request: Request):
    """Enterprise Management main dashboard"""
    return templates.TemplateResponse("enterprise_management.html", {"request": request})

@app.get("/api/security/overview")
async def get_security_overview():
    """Get comprehensive security status overview"""
    try:
        security_overview = {
            "overall_security_score": 94.2,
            "compliance_status": {
                "gdpr": {
                    "status": "compliant",
                    "score": 98.4,
                    "last_assessment": "2024-09-15",
                    "next_review": "2024-12-15"
                },
                "iso27001": {
                    "status": "compliant", 
                    "score": 96.8,
                    "last_assessment": "2024-08-20",
                    "next_review": "2025-02-20"
                },
                "uk_data_protection": {
                    "status": "compliant",
                    "score": 97.2,
                    "last_assessment": "2024-09-30",
                    "next_review": "2024-12-30"
                },
                "cyber_essentials": {
                    "status": "certified",
                    "score": 100.0,
                    "last_assessment": "2024-07-10",
                    "next_review": "2025-07-10"
                }
            },
            "security_metrics": {
                "active_threats": 0,
                "blocked_attacks_today": 47,
                "failed_login_attempts": 23,
                "security_incidents_month": 2,
                "uptime_percentage": 99.94,
                "encryption_coverage": 100.0,
                "backup_success_rate": 100.0,
                "vulnerability_score": 8.2
            },
            "audit_statistics": {
                "events_logged_today": 156847,
                "total_audit_events": 24567891,
                "retention_period_days": 2555,
                "storage_used_gb": 847.3,
                "compliance_queries_month": 156
            },
            "access_control_stats": {
                "total_users": 247,
                "active_sessions": 89,
                "roles_configured": 12,
                "permissions_total": 156,
                "mfa_enabled_percentage": 94.7,
                "password_policy_compliance": 97.8
            },
            "data_protection": {
                "data_encrypted_percentage": 100.0,
                "classification_coverage": 96.4,
                "retention_policies_active": 23,
                "data_subject_requests_month": 12,
                "breach_incidents_year": 0,
                "privacy_impact_assessments": 8
            },
            "monitoring_alerts": [
                {
                    "id": "alert_001",
                    "severity": "medium",
                    "type": "unusual_access_pattern",
                    "description": "2 users accessed data outside normal business hours",
                    "timestamp": "2024-10-03T02:15:00Z",
                    "status": "investigating"
                },
                {
                    "id": "alert_002", 
                    "severity": "low",
                    "type": "password_expiry",
                    "description": "5 users have passwords expiring within 7 days",
                    "timestamp": "2024-10-03T09:00:00Z",
                    "status": "pending_action"
                }
            ]
        }
        
        return {
            "success": True,
            "security_overview": security_overview,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch security overview: {str(e)}")

@app.get("/api/security/gdpr-compliance")
async def get_gdpr_compliance():
    """Get detailed GDPR compliance status and metrics"""
    try:
        gdpr_compliance = {
            "overall_score": 98.4,
            "compliance_areas": {
                "lawful_basis": {
                    "score": 100.0,
                    "status": "compliant",
                    "description": "All processing activities have documented legal basis",
                    "evidence": [
                        "Consent management system implemented",
                        "Legal basis register maintained",
                        "Privacy notices updated and accessible"
                    ]
                },
                "data_subject_rights": {
                    "score": 96.8,
                    "status": "compliant", 
                    "description": "Automated systems for handling subject access requests",
                    "evidence": [
                        "SAR portal implemented",
                        "Data portability tools available",
                        "Right to erasure automated"
                    ]
                },
                "privacy_by_design": {
                    "score": 94.2,
                    "status": "compliant",
                    "description": "Privacy controls integrated into system design",
                    "evidence": [
                        "Data minimization principles applied",
                        "Privacy impact assessments completed",
                        "Default privacy settings configured"
                    ]
                },
                "breach_notification": {
                    "score": 100.0,
                    "status": "compliant",
                    "description": "Automated breach detection and notification",
                    "evidence": [
                        "Breach detection systems active",
                        "72-hour notification procedures",
                        "Incident response plan tested"
                    ]
                },
                "international_transfers": {
                    "score": 98.5,
                    "status": "compliant",
                    "description": "Adequate safeguards for international data transfers",
                    "evidence": [
                        "Standard contractual clauses in place",
                        "Adequacy decisions verified",
                        "Transfer impact assessments completed"
                    ]
                },
                "accountability": {
                    "score": 97.1,
                    "status": "compliant",
                    "description": "Comprehensive documentation and governance",
                    "evidence": [
                        "Data protection policies documented",
                        "Regular compliance audits conducted", 
                        "Staff training programs implemented"
                    ]
                }
            },
            "data_subject_requests": {
                "total_requests_year": 247,
                "access_requests": 156,
                "rectification_requests": 34,
                "erasure_requests": 28,
                "portability_requests": 18,
                "objection_requests": 11,
                "average_response_time_hours": 18.4,
                "compliance_rate_percentage": 99.2
            },
            "consent_management": {
                "active_consents": 2847,
                "consent_withdrawal_rate": 2.3,
                "granular_consent_options": 12,
                "consent_refresh_rate": 94.7,
                "marketing_consent_rate": 67.8
            },
            "privacy_impact_assessments": [
                {
                    "assessment_id": "PIA-2024-001",
                    "title": "AI Planning Analysis System",
                    "date_completed": "2024-08-15",
                    "risk_level": "medium",
                    "mitigation_status": "complete"
                },
                {
                    "assessment_id": "PIA-2024-002", 
                    "title": "Document Management Integration",
                    "date_completed": "2024-07-20",
                    "risk_level": "low",
                    "mitigation_status": "complete"
                },
                {
                    "assessment_id": "PIA-2024-003",
                    "title": "Communications Hub System",
                    "date_completed": "2024-09-10",
                    "risk_level": "medium",
                    "mitigation_status": "in_progress"
                }
            ],
            "data_retention": {
                "policies_active": 23,
                "automated_deletion_enabled": True,
                "retention_schedule_compliance": 96.8,
                "data_categories_managed": 45,
                "storage_optimization_percentage": 23.4
            }
        }
        
        return {
            "success": True,
            "gdpr_compliance": gdpr_compliance,
            "assessment_date": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch GDPR compliance data: {str(e)}")

@app.post("/api/security/audit-logs")
async def query_audit_logs(query: AuditLogQuery):
    """Query security audit logs with filters"""
    try:
        # In a real implementation, this would query the audit database
        audit_logs = [
            {
                "id": "audit_001",
                "timestamp": "2024-10-03T14:32:15Z",
                "event_type": "authentication",
                "user_id": "user_sarah_johnson",
                "user_email": "sarah.johnson@example.com",
                "action": "user_login",
                "resource": "login_portal",
                "source_ip": "192.168.1.145",
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "status": "success",
                "session_id": "sess_a1b2c3d4e5f6",
                "geolocation": "London, UK",
                "risk_score": 2.1,
                "metadata": {
                    "mfa_used": True,
                    "device_trusted": True,
                    "login_method": "email_password_mfa"
                }
            },
            {
                "id": "audit_002",
                "timestamp": "2024-10-03T14:31:42Z",
                "event_type": "data_access",
                "user_id": "user_mike_chen",
                "user_email": "mike.chen@example.com",
                "action": "view_project_details",
                "resource": "project_PLN_2024_0847",
                "source_ip": "10.0.0.23",
                "user_agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
                "status": "success",
                "session_id": "sess_x9y8z7w6v5u4",
                "geolocation": "Manchester, UK",
                "risk_score": 1.5,
                "metadata": {
                    "data_classification": "sensitive",
                    "access_reason": "project_review",
                    "approval_required": False
                }
            },
            {
                "id": "audit_003",
                "timestamp": "2024-10-03T14:30:18Z",
                "event_type": "administrative",
                "user_id": "admin_platform",
                "user_email": "admin@domusplatform.com",
                "action": "role_assignment",
                "resource": "user_permissions",
                "source_ip": "172.16.0.5",
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "status": "success",
                "session_id": "sess_p9o8i7u6y5t4",
                "geolocation": "Birmingham, UK",
                "risk_score": 3.2,
                "metadata": {
                    "target_user": "user_emma_wilson",
                    "role_assigned": "senior_planner",
                    "approval_workflow": "completed"
                }
            },
            {
                "id": "audit_004",
                "timestamp": "2024-10-03T14:29:33Z",
                "event_type": "security_event",
                "user_id": "unknown",
                "user_email": None,
                "action": "failed_login_attempt",
                "resource": "login_portal",
                "source_ip": "203.0.113.12",
                "user_agent": "python-requests/2.28.1",
                "status": "failed",
                "session_id": None,
                "geolocation": "Unknown",
                "risk_score": 8.7,
                "metadata": {
                    "failure_reason": "invalid_credentials",
                    "attempt_count": 5,
                    "blocked": True,
                    "threat_level": "medium"
                }
            },
            {
                "id": "audit_005",
                "timestamp": "2024-10-03T14:28:07Z",
                "event_type": "data_export",
                "user_id": "user_emma_wilson",
                "user_email": "emma.wilson@example.com",
                "action": "export_pdf_report",
                "resource": "planning_reports",
                "source_ip": "192.168.1.87",
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "status": "success",
                "session_id": "sess_q1w2e3r4t5y6",
                "geolocation": "Leeds, UK",
                "risk_score": 2.8,
                "metadata": {
                    "export_format": "pdf",
                    "report_type": "planning_assessment",
                    "data_sensitivity": "confidential",
                    "retention_required": True
                }
            }
        ]
        
        # Apply filters (simplified for demo)
        filtered_logs = audit_logs[:query.limit] if query.limit else audit_logs
        
        return {
            "success": True,
            "audit_logs": filtered_logs,
            "total_count": len(audit_logs),
            "query_parameters": query.dict(),
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to query audit logs: {str(e)}")

@app.get("/api/security/threat-monitoring")
async def get_threat_monitoring():
    """Get real-time threat monitoring and security alerts"""
    try:
        threat_monitoring = {
            "threat_level": "low",
            "active_threats": 0,
            "threats_blocked_today": 47,
            "threat_categories": {
                "malware": {
                    "threats_detected": 12,
                    "threats_blocked": 12,
                    "last_detection": "2024-10-03T11:45:00Z"
                },
                "phishing": {
                    "threats_detected": 8,
                    "threats_blocked": 8,
                    "last_detection": "2024-10-03T13:20:00Z"
                },
                "brute_force": {
                    "threats_detected": 15,
                    "threats_blocked": 15,
                    "last_detection": "2024-10-03T14:29:33Z"
                },
                "ddos": {
                    "threats_detected": 3,
                    "threats_blocked": 3,
                    "last_detection": "2024-10-03T08:15:00Z"
                },
                "sql_injection": {
                    "threats_detected": 9,
                    "threats_blocked": 9,
                    "last_detection": "2024-10-03T12:08:00Z"
                }
            },
            "security_alerts": [
                {
                    "alert_id": "ALT-2024-10-03-001",
                    "severity": "medium",
                    "type": "unusual_access_pattern",
                    "title": "After-hours data access detected",
                    "description": "2 users accessed sensitive project data outside normal business hours (22:00-06:00)",
                    "affected_resources": ["project_PLN_2024_0847", "project_PLN_2024_0851"],
                    "users_involved": ["mike.chen@example.com", "sarah.johnson@example.com"],
                    "detection_time": "2024-10-03T02:15:00Z",
                    "status": "investigating",
                    "risk_score": 6.2,
                    "recommended_actions": [
                        "Verify legitimate business purpose",
                        "Review access logs for anomalies", 
                        "Contact users for verification"
                    ]
                },
                {
                    "alert_id": "ALT-2024-10-03-002",
                    "severity": "low",
                    "type": "password_policy",
                    "title": "Password expiry notifications",
                    "description": "5 users have passwords expiring within 7 days",
                    "affected_resources": ["user_accounts"],
                    "users_involved": [
                        "john.smith@example.com",
                        "lisa.brown@example.com", 
                        "david.jones@example.com",
                        "anna.taylor@example.com",
                        "mark.wilson@example.com"
                    ],
                    "detection_time": "2024-10-03T09:00:00Z",
                    "status": "pending_action",
                    "risk_score": 2.1,
                    "recommended_actions": [
                        "Send password reset notifications",
                        "Enforce password rotation policy",
                        "Review password strength requirements"
                    ]
                }
            ],
            "vulnerability_assessment": {
                "last_scan_date": "2024-10-01T03:00:00Z",
                "next_scan_date": "2024-10-08T03:00:00Z",
                "vulnerabilities_found": {
                    "critical": 0,
                    "high": 1,
                    "medium": 3,
                    "low": 7,
                    "informational": 12
                },
                "remediation_status": {
                    "patched": 18,
                    "in_progress": 4,
                    "accepted_risk": 1,
                    "false_positive": 0
                },
                "overall_score": 8.2
            },
            "network_security": {
                "firewall_status": "active",
                "intrusion_detection": "active",
                "dns_filtering": "active",
                "traffic_analysis": {
                    "total_requests": 2847563,
                    "blocked_requests": 12847,
                    "suspicious_patterns": 47,
                    "geoblocking_hits": 234
                },
                "ssl_certificate_status": {
                    "valid": True,
                    "expires": "2025-04-15T23:59:59Z",
                    "days_until_expiry": 194,
                    "certificate_authority": "Let's Encrypt"
                }
            },
            "incident_response": {
                "response_team_on_call": True,
                "escalation_procedures": "active",
                "communication_channels": "operational",
                "backup_systems": "standby",
                "recovery_time_objective": "4 hours",
                "recovery_point_objective": "1 hour"
            }
        }
        
        return {
            "success": True,
            "threat_monitoring": threat_monitoring,
            "monitoring_timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch threat monitoring data: {str(e)}")

@app.get("/api/security/access-controls")
async def get_access_controls():
    """Get access control and RBAC information"""
    try:
        access_controls = {
            "rbac_status": "active",
            "total_users": 247,
            "active_sessions": 89,
            "roles_defined": 12,
            "permissions_total": 156,
            "role_definitions": [
                {
                    "role_id": "super_admin",
                    "role_name": "Super Administrator",
                    "user_count": 2,
                    "permissions": [
                        "system_administration",
                        "user_management", 
                        "security_configuration",
                        "audit_access",
                        "all_data_access",
                        "emergency_access"
                    ],
                    "risk_level": "critical",
                    "mfa_required": True,
                    "session_timeout": 30
                },
                {
                    "role_id": "planning_manager",
                    "role_name": "Planning Manager",
                    "user_count": 8,
                    "permissions": [
                        "project_management",
                        "team_oversight",
                        "report_generation",
                        "client_communication",
                        "budget_management",
                        "resource_allocation"
                    ],
                    "risk_level": "high",
                    "mfa_required": True,
                    "session_timeout": 60
                },
                {
                    "role_id": "senior_planner",
                    "role_name": "Senior Planner",
                    "user_count": 15,
                    "permissions": [
                        "advanced_planning_tools",
                        "ai_analysis_access",
                        "document_generation",
                        "stakeholder_communication",
                        "project_approval",
                        "mentoring_access"
                    ],
                    "risk_level": "medium",
                    "mfa_required": True,
                    "session_timeout": 120
                },
                {
                    "role_id": "planning_consultant",
                    "role_name": "Planning Consultant",
                    "user_count": 34,
                    "permissions": [
                        "project_access",
                        "basic_reporting",
                        "document_viewing",
                        "limited_modification",
                        "client_interaction",
                        "standard_tools"
                    ],
                    "risk_level": "medium",
                    "mfa_required": False,
                    "session_timeout": 240
                },
                {
                    "role_id": "client_user",
                    "role_name": "Client User",
                    "user_count": 156,
                    "permissions": [
                        "project_viewing",
                        "status_updates",
                        "document_downloads",
                        "communication_access",
                        "basic_reporting",
                        "profile_management"
                    ],
                    "risk_level": "low",
                    "mfa_required": False,
                    "session_timeout": 480
                },
                {
                    "role_id": "external_auditor",
                    "role_name": "External Auditor",
                    "user_count": 3,
                    "permissions": [
                        "audit_log_access",
                        "compliance_reports",
                        "security_documentation",
                        "read_only_system_access",
                        "assessment_tools"
                    ],
                    "risk_level": "medium",
                    "mfa_required": True,
                    "session_timeout": 120
                }
            ],
            "permission_matrix": {
                "create_project": ["super_admin", "planning_manager", "senior_planner"],
                "view_project": ["super_admin", "planning_manager", "senior_planner", "planning_consultant", "client_user"],
                "edit_project": ["super_admin", "planning_manager", "senior_planner"],
                "delete_project": ["super_admin", "planning_manager"],
                "generate_reports": ["super_admin", "planning_manager", "senior_planner", "planning_consultant"],
                "manage_users": ["super_admin"],
                "view_audit_logs": ["super_admin", "external_auditor"],
                "configure_security": ["super_admin"],
                "access_ai_tools": ["super_admin", "planning_manager", "senior_planner"],
                "export_data": ["super_admin", "planning_manager", "senior_planner", "external_auditor"]
            },
            "authentication_methods": {
                "password_only": 13,
                "password_mfa": 234,
                "sso_enabled": 89,
                "biometric_enabled": 12,
                "hardware_tokens": 5
            },
            "session_management": {
                "active_sessions": 89,
                "concurrent_session_limit": 3,
                "idle_timeout_minutes": 30,
                "absolute_timeout_hours": 8,
                "session_monitoring": True,
                "geographic_restrictions": False
            },
            "privileged_access": {
                "privileged_users": 25,
                "privileged_sessions_active": 3,
                "privileged_access_monitoring": True,
                "just_in_time_access": True,
                "approval_workflow": True,
                "session_recording": True
            },
            "access_reviews": {
                "last_review_date": "2024-09-15",
                "next_review_date": "2024-12-15",
                "review_frequency": "quarterly",
                "compliance_rate": 97.8,
                "exceptions_granted": 12,
                "access_certifications_pending": 5
            }
        }
        
        return {
            "success": True,
            "access_controls": access_controls,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch access control data: {str(e)}")

@app.get("/api/security/data-protection")
async def get_data_protection():
    """Get data protection and encryption status"""
    try:
        data_protection = {
            "encryption_status": {
                "data_at_rest": {
                    "enabled": True,
                    "algorithm": "AES-256",
                    "key_management": "HSM",
                    "coverage_percentage": 100.0,
                    "compliance_standards": ["FIPS 140-2", "Common Criteria"]
                },
                "data_in_transit": {
                    "enabled": True,
                    "protocol": "TLS 1.3",
                    "certificate_authority": "Let's Encrypt",
                    "perfect_forward_secrecy": True,
                    "hsts_enabled": True
                },
                "data_in_use": {
                    "enabled": True,
                    "technology": "Intel SGX",
                    "coverage_percentage": 85.0,
                    "sensitive_data_only": True
                },
                "backup_encryption": {
                    "enabled": True,
                    "algorithm": "AES-256",
                    "key_rotation": "monthly",
                    "offsite_encryption": True
                }
            },
            "data_classification": {
                "total_data_assets": 2847563,
                "classified_assets": 2745891,
                "classification_coverage": 96.4,
                "categories": {
                    "highly_sensitive": {
                        "count": 234567,
                        "percentage": 8.2,
                        "protection_level": "maximum",
                        "examples": ["Personal identification", "Financial data", "Legal documents"]
                    },
                    "sensitive": {
                        "count": 1456789,
                        "percentage": 51.2,
                        "protection_level": "high",
                        "examples": ["Planning applications", "Project details", "Client communications"]
                    },
                    "internal": {
                        "count": 987654,
                        "percentage": 34.7,
                        "protection_level": "medium",
                        "examples": ["System logs", "Performance metrics", "Configuration data"]
                    },
                    "public": {
                        "count": 168553,
                        "percentage": 5.9,
                        "protection_level": "basic",
                        "examples": ["Marketing materials", "Public policies", "Documentation"]
                    }
                }
            },
            "data_lifecycle_management": {
                "retention_policies": 23,
                "automated_deletion": True,
                "policy_compliance": 96.8,
                "data_minimization": True,
                "purpose_limitation": True,
                "storage_optimization": 23.4,
                "lifecycle_stages": {
                    "creation": {
                        "classification_required": True,
                        "encryption_automatic": True,
                        "access_logging": True
                    },
                    "processing": {
                        "purpose_validation": True,
                        "consent_verification": True,
                        "activity_monitoring": True
                    },
                    "storage": {
                        "retention_enforcement": True,
                        "access_controls": True,
                        "integrity_monitoring": True
                    },
                    "archival": {
                        "automated_migration": True,
                        "reduced_access": True,
                        "cost_optimization": True
                    },
                    "disposal": {
                        "secure_deletion": True,
                        "certificate_generation": True,
                        "audit_trail": True
                    }
                }
            },
            "privacy_controls": {
                "data_subject_rights": {
                    "access_portal": True,
                    "rectification_automation": True,
                    "erasure_automation": True,
                    "portability_tools": True,
                    "objection_handling": True,
                    "consent_management": True
                },
                "consent_management": {
                    "granular_consent": True,
                    "consent_withdrawal": True,
                    "consent_refresh": True,
                    "third_party_sharing": True,
                    "marketing_preferences": True,
                    "audit_trail": True
                },
                "privacy_by_design": {
                    "default_settings": "privacy_first",
                    "data_minimization": True,
                    "purpose_limitation": True,
                    "transparency": True,
                    "user_control": True,
                    "security_integration": True
                }
            },
            "backup_recovery": {
                "backup_frequency": "3x daily",
                "backup_retention": "30 days",
                "offsite_backups": True,
                "backup_encryption": True,
                "restore_testing": "monthly",
                "recovery_time_objective": "4 hours",
                "recovery_point_objective": "1 hour",
                "backup_success_rate": 100.0,
                "last_restore_test": "2024-09-25T03:00:00Z",
                "backup_locations": [
                    "Primary data center - London",
                    "Secondary data center - Manchester", 
                    "Cloud backup - AWS EU-West-2",
                    "Offline backup - Secure facility"
                ]
            },
            "data_loss_prevention": {
                "dlp_enabled": True,
                "content_scanning": True,
                "endpoint_protection": True,
                "email_monitoring": True,
                "web_filtering": True,
                "removable_media_control": True,
                "policy_violations_month": 12,
                "false_positives_rate": 2.3,
                "detection_accuracy": 97.7
            }
        }
        
        return {
            "success": True,
            "data_protection": data_protection,
            "assessment_timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch data protection information: {str(e)}")

@app.post("/api/security/incident")
async def report_security_incident(incident: SecurityEvent):
    """Report a security incident"""
    try:
        incident_id = f"INC-{int(time.time())}"
        
        # In a real implementation, this would:
        # 1. Store the incident in the security incident database
        # 2. Trigger automated response procedures
        # 3. Notify the security team
        # 4. Begin incident investigation workflow
        
        return {
            "success": True,
            "incident_id": incident_id,
            "incident": {
                "id": incident_id,
                "event_type": incident.event_type,
                "severity": incident.severity,
                "description": incident.description,
                "source_ip": incident.source_ip,
                "user_id": incident.user_id,
                "resource": incident.resource,
                "metadata": incident.metadata,
                "reported_at": datetime.now().isoformat(),
                "status": "reported",
                "assigned_to": "security_team"
            },
            "automated_response": {
                "response_initiated": True,
                "notifications_sent": True,
                "investigation_started": True,
                "containment_measures": True if incident.severity in ["high", "critical"] else False
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to report security incident: {str(e)}")

@app.get("/api/security/compliance-report")
async def generate_compliance_report():
    """Generate comprehensive compliance report"""
    try:
        report_id = f"RPT-{int(time.time())}"
        
        compliance_report = {
            "report_id": report_id,
            "generated_at": datetime.now().isoformat(),
            "report_period": {
                "start_date": "2024-07-01",
                "end_date": "2024-09-30",
                "quarter": "Q3 2024"
            },
            "executive_summary": {
                "overall_compliance_score": 96.7,
                "gdpr_compliance": 98.4,
                "iso27001_compliance": 96.8,
                "cyber_essentials_status": "certified",
                "security_incidents": 0,
                "data_breaches": 0,
                "audit_findings": 3,
                "remediation_status": "complete"
            },
            "regulatory_compliance": {
                "gdpr": {
                    "status": "compliant",
                    "score": 98.4,
                    "areas_assessed": 8,
                    "non_compliance_items": 0,
                    "recommendations": 2
                },
                "uk_data_protection_act": {
                    "status": "compliant",
                    "score": 97.2,
                    "areas_assessed": 6,
                    "non_compliance_items": 0,
                    "recommendations": 1
                },
                "iso_27001": {
                    "status": "compliant",
                    "score": 96.8,
                    "controls_implemented": 114,
                    "controls_total": 114,
                    "non_compliance_items": 0
                },
                "cyber_essentials_plus": {
                    "status": "certified",
                    "certification_date": "2024-07-10",
                    "expiry_date": "2025-07-10",
                    "assessment_score": 100.0
                }
            },
            "security_metrics": {
                "security_incidents_quarter": 0,
                "data_breaches_quarter": 0,
                "vulnerability_assessments": 3,
                "penetration_tests": 1,
                "security_training_completion": 98.7,
                "password_policy_compliance": 97.8,
                "mfa_adoption_rate": 94.7
            },
            "audit_activities": {
                "internal_audits": 2,
                "external_audits": 1,
                "compliance_reviews": 4,
                "findings_total": 3,
                "findings_resolved": 3,
                "open_findings": 0
            },
            "recommendations": [
                {
                    "priority": "medium",
                    "category": "access_control",
                    "recommendation": "Implement automated access review process to reduce manual effort",
                    "estimated_effort": "2 weeks",
                    "target_completion": "2024-11-30"
                },
                {
                    "priority": "low",
                    "category": "training",
                    "recommendation": "Enhance security awareness training with phishing simulation exercises",
                    "estimated_effort": "1 week",
                    "target_completion": "2024-12-15"
                }
            ],
            "certification_status": {
                "iso_27001": {
                    "certified": True,
                    "certificate_number": "ISO27001-UK-2024-001",
                    "issue_date": "2024-02-20",
                    "expiry_date": "2027-02-20",
                    "certification_body": "BSI Group"
                },
                "cyber_essentials_plus": {
                    "certified": True,
                    "certificate_number": "CE-PLUS-2024-7890",
                    "issue_date": "2024-07-10",
                    "expiry_date": "2025-07-10",
                    "certification_body": "IASME Consortium"
                }
            }
        }
        
        return {
            "success": True,
            "compliance_report": compliance_report,
            "download_url": f"/api/security/reports/{report_id}/download",
            "expiry_date": (datetime.now() + timedelta(days=30)).isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to generate compliance report: {str(e)}")

# Enterprise Features & Scaling API Endpoints
@app.get("/api/enterprise/overview")
async def get_enterprise_overview():
    """Get enterprise platform overview and metrics"""
    try:
        overview = {
            "platform_status": "operational",
            "last_updated": datetime.now().isoformat(),
            "enterprise_metrics": {
                "active_tenants": 247,
                "total_users": 15847,
                "total_projects": 2456,
                "api_calls_per_hour": 47000,
                "uptime_percentage": 99.97,
                "average_response_time": 142,
                "success_rate": 99.2,
                "storage_used_gb": 2847,
                "bandwidth_gb_month": 567,
                "active_nodes": 12,
                "capacity_rps": 2400,
                "current_utilization": 67
            },
            "scaling_status": {
                "auto_scaling_enabled": True,
                "last_scale_event": "2024-10-15T14:30:00Z",
                "scale_direction": "up",
                "target_utilization": 70,
                "min_nodes": 3,
                "max_nodes": 20,
                "scale_cooldown": 300
            },
            "multi_tenant_stats": {
                "enterprise_tenants": 89,
                "professional_tenants": 126,
                "trial_tenants": 32,
                "data_isolation": "complete",
                "tenant_sla_compliance": 99.8
            },
            "white_label_adoption": {
                "configured_brands": 156,
                "custom_domains": 34,
                "customization_completion": 92,
                "ssl_certificates": "auto_managed"
            }
        }
        
        return {
            "success": True,
            "overview": overview,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch enterprise overview: {str(e)}")

@app.get("/api/enterprise/tenants")
async def get_tenant_list(status: str = None, plan: str = None, limit: int = 50):
    """Get list of tenants with filtering options"""
    try:
        # Mock tenant data - in production this would query the database
        tenants = [
            {
                "id": "westminster-council",
                "name": "Westminster Council",
                "status": "active",
                "plan": "Enterprise Pro",
                "users": 1247,
                "projects": 156,
                "storage_gb": 89,
                "billing_status": "current",
                "domain": "planning.westminster.gov.uk",
                "created_date": "2024-01-15T10:00:00Z",
                "last_activity": "2024-10-15T16:45:00Z",
                "monthly_cost": 4999,
                "sla_compliance": 99.9
            },
            {
                "id": "manchester-council",
                "name": "Manchester City Council",
                "status": "active",
                "plan": "Enterprise",
                "users": 892,
                "projects": 234,
                "storage_gb": 127,
                "billing_status": "current",
                "domain": "planning.manchester.gov.uk",
                "created_date": "2024-02-01T09:30:00Z",
                "last_activity": "2024-10-15T17:12:00Z",
                "monthly_cost": 3499,
                "sla_compliance": 99.7
            },
            {
                "id": "barratt-dev",
                "name": "Barratt Developments",
                "status": "trial",
                "plan": "Trial",
                "users": 156,
                "projects": 23,
                "storage_gb": 12,
                "billing_status": "trial",
                "domain": None,
                "created_date": "2024-10-01T14:20:00Z",
                "last_activity": "2024-10-15T15:30:00Z",
                "trial_expires": "2024-10-29T23:59:59Z",
                "monthly_cost": 0,
                "sla_compliance": 98.5
            },
            {
                "id": "savills-planning",
                "name": "Savills Planning",
                "status": "pending",
                "plan": "Enterprise",
                "users": 0,
                "projects": 0,
                "storage_gb": 0,
                "billing_status": "setup",
                "domain": "planning.savills.com",
                "created_date": "2024-10-14T11:45:00Z",
                "last_activity": None,
                "monthly_cost": 3499,
                "sla_compliance": None
            }
        ]
        
        # Apply filters
        filtered_tenants = tenants
        if status:
            filtered_tenants = [t for t in filtered_tenants if t["status"] == status]
        if plan:
            filtered_tenants = [t for t in filtered_tenants if t["plan"] == plan]
        
        # Apply limit
        filtered_tenants = filtered_tenants[:limit]
        
        return {
            "success": True,
            "tenants": filtered_tenants,
            "total_count": len(tenants),
            "filtered_count": len(filtered_tenants),
            "filters_applied": {
                "status": status,
                "plan": plan,
                "limit": limit
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch tenant list: {str(e)}")

@app.post("/api/enterprise/tenants")
async def create_tenant(tenant_data: dict):
    """Create a new tenant"""
    try:
        required_fields = ["name", "plan", "admin_email"]
        for field in required_fields:
            if field not in tenant_data:
                raise HTTPException(status_code=400, detail=f"Missing required field: {field}")
        
        tenant_id = tenant_data["name"].lower().replace(" ", "-").replace("'", "")
        
        new_tenant = {
            "id": tenant_id,
            "name": tenant_data["name"],
            "status": "pending",
            "plan": tenant_data["plan"],
            "admin_email": tenant_data["admin_email"],
            "users": 0,
            "projects": 0,
            "storage_gb": 0,
            "billing_status": "setup",
            "domain": tenant_data.get("domain"),
            "created_date": datetime.now().isoformat(),
            "provisioning_status": "initializing",
            "estimated_setup_time": "5-10 minutes"
        }
        
        # Simulate tenant provisioning process
        provisioning_steps = [
            "Creating isolated database schema",
            "Setting up security boundaries",
            "Configuring domain and SSL",
            "Applying white-label configuration",
            "Initializing analytics tracking",
            "Setting up backup procedures",
            "Configuring monitoring alerts"
        ]
        
        return {
            "success": True,
            "tenant": new_tenant,
            "provisioning_steps": provisioning_steps,
            "estimated_completion": (datetime.now() + timedelta(minutes=7)).isoformat(),
            "setup_url": f"/setup/{tenant_id}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create tenant: {str(e)}")

@app.get("/api/enterprise/scaling/metrics")
async def get_scaling_metrics():
    """Get current auto-scaling metrics"""
    try:
        import random
        
        current_metrics = {
            "timestamp": datetime.now().isoformat(),
            "infrastructure": {
                "active_nodes": 12,
                "capacity_rps": 2400,
                "current_rps": random.randint(800, 1600),
                "cpu_utilization": random.randint(45, 85),
                "memory_utilization": random.randint(40, 80),
                "network_io": random.randint(100, 500),
                "disk_io": random.randint(50, 200)
            },
            "performance": {
                "average_response_time": random.randint(120, 180),
                "p95_response_time": random.randint(200, 350),
                "error_rate": round(random.uniform(0.1, 0.8), 2),
                "throughput": random.randint(1800, 2200),
                "active_connections": random.randint(500, 1200)
            },
            "scaling_history": [
                {
                    "timestamp": "2024-10-15T14:30:00Z",
                    "action": "scale_up",
                    "from_nodes": 10,
                    "to_nodes": 12,
                    "reason": "cpu_threshold",
                    "trigger_value": 82
                },
                {
                    "timestamp": "2024-10-14T09:15:00Z",
                    "action": "scale_down",
                    "from_nodes": 12,
                    "to_nodes": 10,
                    "reason": "low_utilization",
                    "trigger_value": 28
                },
                {
                    "timestamp": "2024-10-13T16:45:00Z",
                    "action": "scale_up",
                    "from_nodes": 8,
                    "to_nodes": 12,
                    "reason": "capacity_threshold",
                    "trigger_value": 92
                }
            ],
            "scaling_config": {
                "min_nodes": 3,
                "max_nodes": 20,
                "target_cpu_utilization": 70,
                "scale_up_threshold": 80,
                "scale_down_threshold": 30,
                "cooldown_period": 300,
                "auto_scaling_enabled": True
            }
        }
        
        return {
            "success": True,
            "metrics": current_metrics,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch scaling metrics: {str(e)}")

@app.post("/api/enterprise/scaling/trigger")
async def trigger_manual_scaling(scaling_request: dict):
    """Manually trigger scaling action"""
    try:
        action = scaling_request.get("action")  # "scale_up" or "scale_down"
        target_nodes = scaling_request.get("target_nodes")
        reason = scaling_request.get("reason", "manual_request")
        
        if action not in ["scale_up", "scale_down"]:
            raise HTTPException(status_code=400, detail="Invalid scaling action")
        
        if target_nodes and (target_nodes < 3 or target_nodes > 20):
            raise HTTPException(status_code=400, detail="Target nodes must be between 3 and 20")
        
        current_nodes = 12  # In production, get from actual infrastructure
        
        if not target_nodes:
            target_nodes = current_nodes + 2 if action == "scale_up" else current_nodes - 1
            target_nodes = max(3, min(20, target_nodes))
        
        scaling_event = {
            "scaling_id": f"scale-{int(time.time())}",
            "action": action,
            "from_nodes": current_nodes,
            "to_nodes": target_nodes,
            "reason": reason,
            "initiated_by": "manual",
            "started_at": datetime.now().isoformat(),
            "estimated_completion": (datetime.now() + timedelta(minutes=3)).isoformat(),
            "status": "in_progress"
        }
        
        return {
            "success": True,
            "scaling_event": scaling_event,
            "message": f"Scaling {action} initiated from {current_nodes} to {target_nodes} nodes"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to trigger scaling: {str(e)}")

@app.get("/api/enterprise/white-label/{tenant_id}")
async def get_white_label_config(tenant_id: str):
    """Get white-label configuration for a tenant"""
    try:
        # Mock white-label configuration
        config = {
            "tenant_id": tenant_id,
            "company_name": "Westminster Planning Solutions",
            "primary_color": "#1e40af",
            "secondary_color": "#3b82f6",
            "logo_url": "https://example.com/logo.png",
            "custom_domain": "planning.westminster.gov.uk",
            "ssl_certificate": "auto_managed",
            "features_enabled": [
                "planning_ai",
                "auto_docs",
                "property_api",
                "document_management",
                "task_management",
                "reporting_analytics"
            ],
            "user_limits": {
                "max_users": 500,
                "current_users": 247,
                "storage_limit_gb": 1000,
                "storage_used_gb": 89
            },
            "customization": {
                "header_logo": True,
                "custom_css": True,
                "favicon": True,
                "login_branding": True,
                "email_templates": True,
                "footer_customization": True
            },
            "domain_config": {
                "dns_configured": True,
                "ssl_active": True,
                "cdn_enabled": True,
                "redirects": ["www.planning.westminster.gov.uk"]
            },
            "last_updated": "2024-10-10T14:30:00Z",
            "configuration_status": "active"
        }
        
        return {
            "success": True,
            "white_label_config": config,
            "customization_completion": 92
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch white-label config: {str(e)}")

@app.put("/api/enterprise/white-label/{tenant_id}")
async def update_white_label_config(tenant_id: str, config_data: dict):
    """Update white-label configuration for a tenant"""
    try:
        updated_config = {
            "tenant_id": tenant_id,
            "company_name": config_data.get("company_name", "Planning Platform"),
            "primary_color": config_data.get("primary_color", "#1e40af"),
            "secondary_color": config_data.get("secondary_color", "#3b82f6"),
            "logo_url": config_data.get("logo_url"),
            "custom_domain": config_data.get("custom_domain"),
            "features_enabled": config_data.get("features_enabled", []),
            "user_limits": config_data.get("user_limits", {}),
            "last_updated": datetime.now().isoformat(),
            "configuration_status": "updating"
        }
        
        # Simulate configuration update process
        update_steps = [
            "Validating configuration parameters",
            "Updating database settings",
            "Regenerating custom CSS",
            "Updating CDN configuration",
            "Applying domain changes",
            "Testing configuration",
            "Activating new settings"
        ]
        
        return {
            "success": True,
            "updated_config": updated_config,
            "update_steps": update_steps,
            "estimated_completion": (datetime.now() + timedelta(minutes=5)).isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to update white-label config: {str(e)}")

@app.get("/api/enterprise/analytics/overview")
async def get_enterprise_analytics():
    """Get enterprise-level analytics overview"""
    try:
        import random
        
        analytics = {
            "period": {
                "start_date": "2024-09-01",
                "end_date": "2024-09-30",
                "period_name": "September 2024"
            },
            "usage_metrics": {
                "total_api_calls": 2847562,
                "unique_users": 15847,
                "active_projects": 2456,
                "documents_generated": 18945,
                "ai_analyses_completed": 7234,
                "property_searches": 45678,
                "report_downloads": 3421
            },
            "performance_metrics": {
                "average_response_time": 142,
                "uptime_percentage": 99.97,
                "error_rate": 0.23,
                "successful_requests": 99.77,
                "peak_concurrent_users": 1247,
                "data_transfer_gb": 567
            },
            "tenant_analytics": {
                "enterprise_usage": 67.8,
                "professional_usage": 28.4,
                "trial_usage": 3.8,
                "top_performing_tenants": [
                    {"name": "Westminster Council", "usage_score": 94.2},
                    {"name": "Manchester City Council", "usage_score": 89.7},
                    {"name": "Birmingham Council", "usage_score": 87.3}
                ]
            },
            "feature_adoption": {
                "planning_ai": 89.4,
                "auto_docs": 76.8,
                "property_api": 92.1,
                "document_management": 84.6,
                "task_management": 71.3,
                "reporting_analytics": 88.9,
                "communications_hub": 65.7,
                "offsets_marketplace": 34.2
            },
            "geographic_distribution": {
                "uk_england": 78.4,
                "uk_scotland": 12.7,
                "uk_wales": 6.8,
                "uk_northern_ireland": 2.1
            },
            "growth_metrics": {
                "monthly_growth_rate": 12.4,
                "new_tenants_this_month": 8,
                "user_growth_rate": 15.7,
                "revenue_growth_rate": 18.9
            }
        }
        
        return {
            "success": True,
            "analytics": analytics,
            "generated_at": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch enterprise analytics: {str(e)}")

@app.get("/api/enterprise/api-limits")
async def get_api_rate_limits():
    """Get current API rate limits and usage"""
    try:
        import random
        
        rate_limits = {
            "global_limits": {
                "requests_per_minute": 10000,
                "requests_per_hour": 100000,
                "requests_per_day": 1000000,
                "current_minute": random.randint(3000, 8000),
                "current_hour": random.randint(25000, 75000),
                "current_day": random.randint(200000, 800000)
            },
            "endpoint_limits": [
                {
                    "endpoint": "/api/planning-ai/*",
                    "limit_per_minute": 200,
                    "current_usage": random.randint(80, 180),
                    "usage_percentage": round(random.uniform(40, 90), 1),
                    "tenant_breakdown": {
                        "enterprise": 67,
                        "professional": 28,
                        "trial": 5
                    }
                },
                {
                    "endpoint": "/api/property/*",
                    "limit_per_minute": 150,
                    "current_usage": random.randint(60, 140),
                    "usage_percentage": round(random.uniform(40, 93), 1),
                    "tenant_breakdown": {
                        "enterprise": 72,
                        "professional": 25,
                        "trial": 3
                    }
                },
                {
                    "endpoint": "/api/documents/*",
                    "limit_per_minute": 100,
                    "current_usage": random.randint(30, 90),
                    "usage_percentage": round(random.uniform(30, 90), 1),
                    "tenant_breakdown": {
                        "enterprise": 58,
                        "professional": 35,
                        "trial": 7
                    }
                },
                {
                    "endpoint": "/api/security/*",
                    "limit_per_minute": 50,
                    "current_usage": random.randint(10, 45),
                    "usage_percentage": round(random.uniform(20, 90), 1),
                    "tenant_breakdown": {
                        "enterprise": 89,
                        "professional": 11,
                        "trial": 0
                    }
                }
            ],
            "tenant_quotas": {
                "enterprise_pro": {
                    "api_calls_per_month": 1000000,
                    "storage_gb": 1000,
                    "users": 1000,
                    "projects": 500
                },
                "enterprise": {
                    "api_calls_per_month": 500000,
                    "storage_gb": 500,
                    "users": 500,
                    "projects": 250
                },
                "professional": {
                    "api_calls_per_month": 100000,
                    "storage_gb": 100,
                    "users": 100,
                    "projects": 50
                },
                "trial": {
                    "api_calls_per_month": 10000,
                    "storage_gb": 10,
                    "users": 10,
                    "projects": 5
                }
            },
            "rate_limit_policies": {
                "burst_allowance": 150,
                "sliding_window": True,
                "grace_period": 60,
                "escalation_thresholds": [75, 90, 95]
            }
        }
        
        return {
            "success": True,
            "rate_limits": rate_limits,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch API rate limits: {str(e)}")

@app.get("/api/enterprise/performance")
async def get_performance_monitoring():
    """Get enterprise performance monitoring data"""
    try:
        import random
        
        performance_data = {
            "system_health": {
                "overall_status": "healthy",
                "uptime_percentage": 99.97,
                "last_incident": "2024-09-15T03:22:00Z",
                "incident_duration": "00:07:34",
                "mttr_minutes": 7.5,
                "mtbf_hours": 2840
            },
            "response_times": {
                "average_ms": random.randint(120, 180),
                "p50_ms": random.randint(100, 150),
                "p95_ms": random.randint(200, 350),
                "p99_ms": random.randint(400, 800),
                "max_ms": random.randint(1000, 2000)
            },
            "throughput": {
                "requests_per_second": random.randint(180, 250),
                "peak_rps": random.randint(300, 450),
                "total_requests_today": random.randint(15000000, 25000000),
                "successful_requests_percentage": 99.2
            },
            "resource_utilization": {
                "cpu_percentage": random.randint(45, 85),
                "memory_percentage": random.randint(40, 80),
                "disk_io_percentage": random.randint(20, 60),
                "network_io_mbps": random.randint(100, 500),
                "database_connections": random.randint(50, 200)
            },
            "error_tracking": {
                "error_rate_percentage": round(random.uniform(0.1, 0.8), 2),
                "errors_last_hour": random.randint(5, 50),
                "critical_errors": 0,
                "warning_errors": random.randint(2, 20),
                "info_errors": random.randint(10, 100)
            },
            "geographic_performance": {
                "london": {"avg_response_ms": 89, "uptime": 99.98},
                "manchester": {"avg_response_ms": 94, "uptime": 99.97},
                "birmingham": {"avg_response_ms": 92, "uptime": 99.96},
                "edinburgh": {"avg_response_ms": 104, "uptime": 99.95},
                "cardiff": {"avg_response_ms": 98, "uptime": 99.97}
            },
            "alerts": [
                {
                    "severity": "warning",
                    "message": "API response time above threshold for planning-ai endpoint",
                    "threshold": "500ms",
                    "current": "523ms",
                    "since": "2024-10-15T16:30:00Z"
                },
                {
                    "severity": "info",
                    "message": "Scheduled maintenance window approaching",
                    "scheduled": "2024-10-20T02:00:00Z",
                    "duration": "2 hours",
                    "impact": "minimal"
                }
            ]
        }
        
        return {
            "success": True,
            "performance": performance_data,
            "monitoring_active": True,
            "last_updated": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch performance monitoring: {str(e)}")

@app.post("/api/enterprise/optimize")
async def optimize_enterprise_performance():
    """Trigger enterprise performance optimization"""
    try:
        optimization_id = f"opt-{int(time.time())}"
        
        optimization_tasks = [
            "Analyzing system performance bottlenecks",
            "Optimizing database query performance",
            "Cleaning up temporary files and caches",
            "Rebalancing load across nodes",
            "Updating performance configurations",
            "Precompiling frequently used templates",
            "Optimizing static asset delivery",
            "Tuning garbage collection settings"
        ]
        
        optimization_result = {
            "optimization_id": optimization_id,
            "started_at": datetime.now().isoformat(),
            "estimated_completion": (datetime.now() + timedelta(minutes=15)).isoformat(),
            "tasks": optimization_tasks,
            "expected_improvements": {
                "response_time_reduction": "8-15%",
                "throughput_increase": "5-12%",
                "memory_efficiency": "10-20%",
                "cache_hit_rate": "15-25%"
            },
            "status": "in_progress",
            "progress_percentage": 0
        }
        
        return {
            "success": True,
            "optimization": optimization_result,
            "message": "Enterprise performance optimization initiated"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to start optimization: {str(e)}")

# =====================================
# VIABILITY ASSESSMENT MODULE
# =====================================

@app.get("/api/viability/presets")
async def get_viability_presets(current_user: dict = Depends(get_current_user)):
    """Get organization's viability presets"""
    try:
        # TODO: Implement org-scoped preset retrieval
        default_presets = [
            {
                "id": 1,
                "name": "Residential Development",
                "description": "Standard assumptions for residential schemes",
                "config": {
                    "build_costs_sqm": 1800,
                    "professional_fees_percent": 12,
                    "marketing_percent": 3,
                    "contingency_percent": 5,
                    "finance_rate_percent": 6.5,
                    "profit_target_percent": 20,
                    "cil_rate_sqm": 120
                },
                "is_default": True
            },
            {
                "id": 2,
                "name": "Commercial Office",
                "description": "Office development assumptions",
                "config": {
                    "build_costs_sqm": 2200,
                    "professional_fees_percent": 15,
                    "marketing_percent": 2,
                    "contingency_percent": 7,
                    "finance_rate_percent": 5.8,
                    "profit_target_percent": 18,
                    "cil_rate_sqm": 185
                },
                "is_default": False
            }
        ]
        
        return {
            "success": True,
            "presets": default_presets,
            "org_id": current_user["org_id"]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch viability presets: {str(e)}")

@app.post("/api/viability/presets")
async def create_viability_preset(
    preset_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Create or update viability preset"""
    try:
        # TODO: Implement preset creation with RBAC check
        preset_id = f"preset-{int(time.time())}"
        
        return {
            "success": True,
            "preset_id": preset_id,
            "preset": {
                "id": preset_id,
                "name": preset_data.get("name", "New Preset"),
                "description": preset_data.get("description", ""),
                "config": preset_data.get("config", {}),
                "created_at": datetime.now().isoformat()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create viability preset: {str(e)}")

@app.post("/api/viability/run")
async def run_viability_assessment(
    assessment_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Run viability assessment"""
    try:
        # TODO: Implement quota check and viability calculation
        project_id = assessment_data.get("project_id")
        preset_id = assessment_data.get("preset_id")
        
        # Mock viability calculation
        gdv = assessment_data.get("gdv", 5000000)
        build_costs = gdv * 0.65
        fees = build_costs * 0.12
        total_costs = build_costs + fees
        residual = gdv - total_costs
        profit_percent = (residual / gdv) * 100
        
        viability_result = {
            "run_id": f"viab-{int(time.time())}",
            "project_id": project_id,
            "preset_id": preset_id,
            "inputs": assessment_data,
            "outputs": {
                "gdv": gdv,
                "build_costs": build_costs,
                "professional_fees": fees,
                "total_costs": total_costs,
                "residual_value": residual,
                "profit_percentage": round(profit_percent, 2),
                "viability_status": "viable" if profit_percent > 15 else "marginal" if profit_percent > 10 else "unviable"
            },
            "created_at": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "assessment": viability_result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to run viability assessment: {str(e)}")

@app.get("/api/viability/runs")
async def get_viability_runs(
    project_id: Optional[str] = None,
    current_user: dict = Depends(get_current_user)
):
    """Get viability assessment runs for project"""
    try:
        # TODO: Implement org-scoped run retrieval
        mock_runs = [
            {
                "id": "viab-1635789123",
                "project_id": project_id or "proj-123",
                "scenario_name": "Base Case",
                "profit_percentage": 18.5,
                "viability_status": "viable",
                "created_at": "2024-10-02T14:30:00Z"
            },
            {
                "id": "viab-1635789456",
                "project_id": project_id or "proj-123",
                "scenario_name": "Affordable Housing 35%",
                "profit_percentage": 12.3,
                "viability_status": "marginal",
                "created_at": "2024-10-02T15:45:00Z"
            }
        ]
        
        return {
            "success": True,
            "runs": mock_runs,
            "total": len(mock_runs)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch viability runs: {str(e)}")

# =====================================
# BNG (BIODIVERSITY NET GAIN) MODULE
# =====================================

@app.post("/api/bng/baseline")
async def upload_bng_baseline(
    baseline_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Upload and parse BNG baseline data"""
    try:
        # TODO: Implement file upload to S3 and parsing
        baseline_id = f"baseline-{int(time.time())}"
        
        return {
            "success": True,
            "baseline_id": baseline_id,
            "baseline": {
                "id": baseline_id,
                "project_id": baseline_data.get("project_id"),
                "habitat_units": baseline_data.get("habitat_units", 0),
                "hedgerow_units": baseline_data.get("hedgerow_units", 0),
                "watercourse_units": baseline_data.get("watercourse_units", 0),
                "created_at": datetime.now().isoformat()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to upload BNG baseline: {str(e)}")

@app.post("/api/bng/calc")
async def calculate_bng(
    calc_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Calculate BNG deficit/surplus"""
    try:
        # TODO: Implement quota check and BNG calculation
        baseline_units = calc_data.get("baseline_units", 100)
        post_dev_units = calc_data.get("post_dev_units", 85)
        net_gain_target = calc_data.get("net_gain_target", 10)  # 10% minimum
        
        required_units = baseline_units * (1 + net_gain_target / 100)
        deficit_units = max(0, required_units - post_dev_units)
        surplus_units = max(0, post_dev_units - required_units)
        net_gain_percent = ((post_dev_units - baseline_units) / baseline_units) * 100
        
        calculation_result = {
            "calculation_id": f"bng-{int(time.time())}",
            "project_id": calc_data.get("project_id"),
            "baseline_id": calc_data.get("baseline_id"),
            "inputs": calc_data,
            "results": {
                "baseline_units": baseline_units,
                "post_development_units": post_dev_units,
                "required_units": required_units,
                "deficit_units": deficit_units,
                "surplus_units": surplus_units,
                "net_gain_percentage": round(net_gain_percent, 2),
                "compliant": net_gain_percent >= net_gain_target
            },
            "created_at": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "calculation": calculation_result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to calculate BNG: {str(e)}")

@app.get("/api/bng/runs")
async def get_bng_runs(
    project_id: Optional[str] = None,
    current_user: dict = Depends(get_current_user)
):
    """Get BNG calculation runs for project"""
    try:
        # TODO: Implement org-scoped run retrieval
        mock_runs = [
            {
                "id": "bng-1635789123",
                "project_id": project_id or "proj-123",
                "net_gain_percentage": 12.5,
                "deficit_units": 0,
                "surplus_units": 15.2,
                "compliant": True,
                "created_at": "2024-10-02T14:30:00Z"
            }
        ]
        
        return {
            "success": True,
            "runs": mock_runs,
            "total": len(mock_runs)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch BNG runs: {str(e)}")

# =====================================
# TRANSPORT & HIGHWAYS MODULE
# =====================================

@app.post("/api/transport/assess")
async def assess_transport_impact(
    assessment_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Run transport impact assessment"""
    try:
        # TODO: Implement quota check and transport assessment
        development_type = assessment_data.get("development_type", "residential")
        units = assessment_data.get("units", 50)
        
        # Mock transport assessment calculation
        trip_rate = {"residential": 0.85, "office": 0.45, "retail": 2.1}.get(development_type, 0.85)
        daily_trips = units * trip_rate
        peak_hour_trips = daily_trips * 0.12
        parking_spaces = units * 1.5 if development_type == "residential" else units * 0.3
        
        risk_factors = [
            {"factor": "Junction capacity", "risk": "medium", "score": 60},
            {"factor": "Pedestrian safety", "risk": "low", "score": 25},
            {"factor": "Parking provision", "risk": "low", "score": 30}
        ]
        
        overall_risk = sum(f["score"] for f in risk_factors) / len(risk_factors)
        
        assessment_result = {
            "assessment_id": f"transport-{int(time.time())}",
            "project_id": assessment_data.get("project_id"),
            "inputs": assessment_data,
            "trip_generation": {
                "daily_trips": round(daily_trips),
                "peak_hour_trips": round(peak_hour_trips),
                "trip_rate_used": trip_rate
            },
            "parking": {
                "spaces_required": round(parking_spaces),
                "spaces_provided": assessment_data.get("parking_spaces", parking_spaces)
            },
            "risk_assessment": {
                "overall_score": round(overall_risk, 1),
                "risk_level": "low" if overall_risk < 40 else "medium" if overall_risk < 70 else "high",
                "factors": risk_factors
            },
            "mitigations": [
                "Travel Plan implementation required",
                "Contribution to junction improvements: Â£15,000",
                "Cycle parking provision: 1 space per unit",
                "Car club membership for residents"
            ],
            "created_at": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "assessment": assessment_result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to assess transport impact: {str(e)}")

@app.get("/api/transport/runs")
async def get_transport_runs(
    project_id: Optional[str] = None,
    current_user: dict = Depends(get_current_user)
):
    """Get transport assessment runs for project"""
    try:
        # TODO: Implement org-scoped run retrieval
        mock_runs = [
            {
                "id": "transport-1635789123",
                "project_id": project_id or "proj-123",
                "daily_trips": 42,
                "risk_level": "medium",
                "overall_score": 55.5,
                "created_at": "2024-10-02T14:30:00Z"
            }
        ]
        
        return {
            "success": True,
            "runs": mock_runs,
            "total": len(mock_runs)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch transport runs: {str(e)}")

# =====================================
# ENVIRONMENT & CLIMATE MODULE
# =====================================

@app.post("/api/environment/assess")
async def assess_environment_risk(
    assessment_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Run environmental risk assessment"""
    try:
        # TODO: Implement quota check and environmental assessment
        assessment_types = assessment_data.get("assessment_types", ["air_quality", "climate"])
        
        risk_results = {}
        overall_scores = []
        all_mitigations = []
        all_citations = []
        
        for assess_type in assessment_types:
            if assess_type == "air_quality":
                score = random.randint(15, 45)
                risk_results[assess_type] = {
                    "score": score,
                    "risk_level": "low" if score < 30 else "medium" if score < 60 else "high",
                    "indicators": {
                        "pm25_ugm3": random.randint(8, 15),
                        "no2_ugm3": random.randint(20, 35),
                        "distance_to_aqma_m": random.randint(500, 2000)
                    }
                }
                all_mitigations.extend([
                    "Electric vehicle charging points",
                    "Green roof implementation",
                    "Air quality monitoring during construction"
                ])
                all_citations.append({
                    "policy": "National Planning Policy Framework",
                    "section": "Paragraph 174",
                    "url": "https://gov.uk/nppf"
                })
                
            elif assess_type == "climate":
                score = random.randint(25, 55)
                risk_results[assess_type] = {
                    "score": score,
                    "risk_level": "low" if score < 30 else "medium" if score < 60 else "high",
                    "indicators": {
                        "overheating_risk": "medium",
                        "flood_risk_zone": "1",
                        "energy_efficiency": "A-rated"
                    }
                }
                all_mitigations.extend([
                    "Solar panel installation",
                    "Heat pump heating system",
                    "Enhanced insulation standards",
                    "Sustainable drainage systems"
                ])
                all_citations.append({
                    "policy": "Climate Change Act 2008",
                    "section": "Net Zero Target",
                    "url": "https://legislation.gov.uk/ukpga/2008/27"
                })
            
            overall_scores.append(score)
        
        overall_risk = sum(overall_scores) / len(overall_scores)
        
        assessment_result = {
            "assessment_id": f"env-{int(time.time())}",
            "project_id": assessment_data.get("project_id"),
            "assessment_types": assessment_types,
            "risk_results": risk_results,
            "overall_risk": {
                "score": round(overall_risk, 1),
                "risk_level": "low" if overall_risk < 30 else "medium" if overall_risk < 60 else "high"
            },
            "mitigations": list(set(all_mitigations)),
            "citations": all_citations,
            "created_at": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "assessment": assessment_result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to assess environmental risk: {str(e)}")

@app.get("/api/environment/runs")
async def get_environment_runs(
    project_id: Optional[str] = None,
    current_user: dict = Depends(get_current_user)
):
    """Get environmental assessment runs for project"""
    try:
        # TODO: Implement org-scoped run retrieval
        mock_runs = [
            {
                "id": "env-1635789123",
                "project_id": project_id or "proj-123",
                "assessment_types": ["air_quality", "climate"],
                "overall_risk_level": "medium",
                "overall_score": 42.5,
                "created_at": "2024-10-02T14:30:00Z"
            }
        ]
        
        return {
            "success": True,
            "runs": mock_runs,
            "total": len(mock_runs)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch environment runs: {str(e)}")

# =====================================
# SUBMISSION PACK MODULE
# =====================================

@app.post("/api/submission-pack/create")
async def create_submission_pack(
    request: Request,
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Create submission pack with manifest and integrity checking"""
    try:
        from document_integrity import DocumentBundleService
        
        pack_data = await request.json()
        project_id = pack_data.get("project_id")
        selected_docs = pack_data.get("documents", [])
        pack_name = pack_data.get("pack_name", "Planning Submission")
        
        # Check quota
        has_quota = await QuotaService.check_quota(
            org_id=current_user["org_id"],
            resource="packs_created",
            db=db
        )
        
        if not has_quota:
            raise HTTPException(status_code=403, detail="Submission pack quota exceeded")
        
        # Mock file paths (in production, these would be real document paths)
        mock_files = []
        for doc in selected_docs:
            # Create mock file for demonstration
            mock_path = f"/tmp/mock_{doc['filename']}"
            with open(mock_path, 'w') as f:
                f.write(f"Mock content for {doc['filename']}\nGenerated at {datetime.now()}")
            mock_files.append(mock_path)
        
        # Generate pack ID
        pack_id = f"pack-{datetime.now().strftime('%Y%m%d-%H%M%S')}-{random.randint(1000, 9999)}"
        output_path = f"/tmp/{pack_id}.zip"
        
        # Get data freshness for manifest
        freshness_data = await FreshnessService.get_source_freshness(db)
        
        # Prepare pack metadata
        pack_metadata = {
            "pack_id": pack_id,
            "title": pack_name,
            "project_name": f"Project {project_id}",
            "created_by": current_user["email"],
            "model_version": "domus-docs-v2.1.0",
            "data_freshness": freshness_data,
            "authority_context": {
                "submission_date": datetime.now().isoformat(),
                "platform": "Domus Planning Intelligence",
                "verification_available": True
            }
        }
        
        # Create submission pack with integrity checking
        bundle_result = DocumentBundleService.create_submission_pack(
            files_to_bundle=mock_files,
            output_path=output_path,
            pack_metadata=pack_metadata
        )
        
        # Clean up mock files
        for mock_path in mock_files:
            if os.path.exists(mock_path):
                os.remove(mock_path)
        
        if not bundle_result["success"]:
            raise HTTPException(status_code=500, detail=f"Pack creation failed: {bundle_result['error']}")
        
        # Store submission pack record
        from models import SubmissionPacks
        submission_pack = SubmissionPacks(
            org_id=current_user["org_id"],
            project_id=project_id,
            pack_name=pack_name,
            manifest_json=bundle_result["manifest"],
            zip_path=output_path,
            zip_checksum=bundle_result["zip_checksum"],
            authority_token=f"auth-{random.randint(100000, 999999)}",
            created_at=datetime.now()
        )
        
        db.add(submission_pack)
        db.commit()
        db.refresh(submission_pack)
        
        # Increment usage
        await QuotaService.increment_usage(
            org_id=current_user["org_id"],
            resource="packs_created",
            db=db
        )
        
        # Prepare response
        pack_result = {
            "pack_id": pack_id,
            "project_id": project_id,
            "pack_name": pack_name,
            "manifest": bundle_result["manifest"],
            "integrity": {
                "zip_checksum": bundle_result["zip_checksum"],
                "total_files": bundle_result["total_files"],
                "total_size_bytes": bundle_result["total_size"],
                "verification_available": True
            },
            "download_url": f"https://storage.domusplanning.co.uk/packs/{pack_id}.zip",
            "authority_token": submission_pack.authority_token,
            "authority_url": f"https://domusplanning.co.uk/authority/{submission_pack.authority_token}",
            "created_at": datetime.now().isoformat(),
            "expires_at": (datetime.now() + timedelta(days=90)).isoformat()
        }
        
        return {
            "success": True,
            "submission_pack": pack_result,
            "manifest_included": True,
            "integrity_verification": "SHA256 checksums included for all files"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create submission pack: {str(e)}")

@app.post("/api/submission-pack/verify")
async def verify_submission_pack(
    request: Request,
    current_user: dict = Depends(get_current_user)
):
    """Verify integrity of a submission pack"""
    try:
        from document_integrity import IntegrityVerificationService
        
        body = await request.json()
        pack_id = body.get("pack_id")
        
        if not pack_id:
            raise HTTPException(status_code=400, detail="Pack ID required")
        
        # In production, retrieve the actual ZIP file path from storage
        zip_path = f"/tmp/{pack_id}.zip"
        
        if not os.path.exists(zip_path):
            raise HTTPException(status_code=404, detail="Submission pack not found")
        
        # Verify the pack
        verification_result = IntegrityVerificationService.verify_submission_pack(zip_path)
        
        return {
            "success": True,
            "verification": verification_result,
            "message": "Integrity verification completed" if verification_result["pack_valid"] else "Integrity verification failed"
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Verification failed: {str(e)}")

# Authority portal route
@app.get("/authority/{verification_token}")
async def authority_portal(verification_token: str, request: Request):
    """Authority portal for viewing submission packages"""
    return templates.TemplateResponse("authority_portal.html", {"request": request, "token": verification_token})

# Authority API endpoint for submission data
@app.get("/api/authority/submission/{verification_token}")
async def get_authority_submission(verification_token: str):
    """Get submission package data for authority portal"""
    try:
        pack_record = db.session.query(SubmissionPacks).filter_by(verification_token=verification_token).first()
        if not pack_record:
            raise HTTPException(status_code=404, detail="Submission not found or access expired")
        
        return {
            "submission_pack": {
                "pack_id": pack_record.pack_id,
                "project_name": pack_record.project_name,
                "pack_name": pack_record.pack_name,
                "created_at": pack_record.created_at.isoformat(),
                "created_by": pack_record.created_by
            },
            "manifest": pack_record.manifest_data,
            "download_url": f"/api/authority/download/{verification_token}"
        }
    except Exception as e:
        logger.error(f"Error retrieving authority submission {verification_token}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to retrieve submission: {str(e)}")

# Authority download endpoint
@app.get("/api/authority/download/{verification_token}")
async def download_authority_submission(verification_token: str):
    """Download submission package via authority portal"""
    try:
        pack_record = db.session.query(SubmissionPacks).filter_by(verification_token=verification_token).first()
        if not pack_record:
            raise HTTPException(status_code=404, detail="Submission not found or access expired")
        
        if not os.path.exists(pack_record.pack_path):
            raise HTTPException(status_code=404, detail="Package file not found")
        
        return FileResponse(
            pack_record.pack_path,
            media_type='application/zip',
            filename=f"{pack_record.pack_id}.zip"
        )
    except Exception as e:
        logger.error(f"Error downloading authority submission {verification_token}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Download failed: {str(e)}")

# Authority verification endpoint
@app.get("/api/authority/verify/{verification_token}")
async def verify_authority_submission(verification_token: str):
    """Verify submission pack integrity via authority portal"""
    try:
        pack_record = db.session.query(SubmissionPacks).filter_by(verification_token=verification_token).first()
        if not pack_record:
            raise HTTPException(status_code=404, detail="Submission not found or access expired")
        
        verification_service = IntegrityVerificationService()
        results = verification_service.verify_pack_integrity(pack_record.pack_path, pack_record.manifest_data)
        
        return {
            "pack_id": pack_record.pack_id,
            "verification_results": results,
            "verified_at": datetime.utcnow().isoformat(),
            "authority_access": True
        }
    except Exception as e:
        logger.error(f"Error verifying authority submission {verification_token}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Verification failed: {str(e)}")

# Security hardening endpoints
if SECURITY_ENABLED:
    
    @app.post("/api/auth/setup-2fa")
    @rate_limit('auth')
    async def setup_2fa(current_user: dict = Depends(get_current_user)):
        """Setup two-factor authentication"""
        try:
            user_id = current_user['user_id']
            secret = two_factor_auth.generate_secret()
            
            # Store secret in database (temporarily)
            # In production, store in user record
            
            qr_code = two_factor_auth.generate_qr_code(current_user['email'], secret)
            backup_codes = two_factor_auth.generate_backup_codes()
            
            log_security_event('2fa_setup_initiated', {'user_id': user_id})
            
            return {
                'secret': secret,
                'qr_code': qr_code,
                'backup_codes': backup_codes,
                'instructions': 'Scan the QR code with your authenticator app and enter a verification code to complete setup.'
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"2FA setup failed: {str(e)}")

    @app.post("/api/auth/verify-2fa")
    @rate_limit('auth')
    async def verify_2fa(
        request: Request,
        current_user: dict = Depends(get_current_user)
    ):
        """Verify and enable 2FA"""
        try:
            data = await request.json()
            secret = data.get('secret')
            token = data.get('token')
            
            if not secret or not token:
                raise HTTPException(status_code=400, detail="Secret and token required")
            
            if not two_factor_auth.verify_token(secret, token):
                log_security_event('2fa_verification_failed', {'user_id': current_user['user_id']})
                raise HTTPException(status_code=400, detail="Invalid verification code")
            
            # Store secret in user record
            # In production: update user.two_factor_secret = secret
            
            log_security_event('2fa_enabled', {'user_id': current_user['user_id']})
            
            return {'success': True, 'message': '2FA enabled successfully'}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"2FA verification failed: {str(e)}")

    @app.post("/api/auth/disable-2fa")
    @require_2fa
    @rate_limit('auth')
    async def disable_2fa(
        request: Request,
        current_user: dict = Depends(get_current_user)
    ):
        """Disable two-factor authentication"""
        try:
            data = await request.json()
            password = data.get('password')
            
            if not password:
                raise HTTPException(status_code=400, detail="Password required to disable 2FA")
            
            # Verify password
            # In production: verify against user.password_hash
            
            # Remove 2FA secret from user record
            # In production: user.two_factor_secret = None
            
            log_security_event('2fa_disabled', {'user_id': current_user['user_id']})
            
            return {'success': True, 'message': '2FA disabled successfully'}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Failed to disable 2FA: {str(e)}")

    @app.get("/api/security/captcha")
    @rate_limit('auth')
    async def get_captcha():
        """Generate CAPTCHA challenge"""
        try:
            captcha_data = captcha_service.generate_captcha()
            return captcha_data
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"CAPTCHA generation failed: {str(e)}")

    @app.post("/api/security/verify-captcha")
    @rate_limit('auth')
    async def verify_captcha_endpoint(request: Request):
        """Verify CAPTCHA response"""
        try:
            data = await request.json()
            captcha_id = data.get('captcha_id')
            answer = data.get('answer')
            
            if not captcha_id or not answer:
                raise HTTPException(status_code=400, detail="CAPTCHA ID and answer required")
            
            is_valid = captcha_service.verify_captcha(captcha_id, answer)
            
            if not is_valid:
                log_security_event('captcha_failed', {'ip': request.client.host})
            
            return {'valid': is_valid}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"CAPTCHA verification failed: {str(e)}")

    @app.post("/api/security/report-csp-violation")
    async def report_csp_violation(request: Request):
        """Report Content Security Policy violations"""
        try:
            violation_data = await request.json()
            
            log_security_event('csp_violation', {
                'violation': violation_data,
                'ip': request.client.host,
                'user_agent': request.headers.get('user-agent')
            })
            
            return {'status': 'reported'}
        except Exception as e:
            # Don't fail CSP reporting
            print(f"CSP violation reporting failed: {e}")
            return {'status': 'error'}

    @app.get("/api/security/check-password")
    @rate_limit('auth')
    async def check_password_strength(password: str):
        """Check password strength"""
        try:
            validation = security_manager.validate_password_strength(password)
            return validation
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Password validation failed: {str(e)}")

    @app.post("/api/auth/change-password")
    @rate_limit('auth')
    async def change_password(
        request: Request,
        current_user: dict = Depends(get_current_user)
    ):
        """Change user password"""
        try:
            data = await request.json()
            current_password = data.get('current_password')
            new_password = data.get('new_password')
            
            if not current_password or not new_password:
                raise HTTPException(status_code=400, detail="Current and new passwords required")
            
            # Verify current password
            # In production: verify against user.password_hash
            
            # Validate new password strength
            validation = security_manager.validate_password_strength(new_password)
            if not validation['valid']:
                raise HTTPException(status_code=400, detail={
                    'message': 'Password does not meet requirements',
                    'issues': validation['issues']
                })
            
            # Hash and store new password
            # In production: user.password_hash = security_manager.hash_password(new_password)
            
            log_security_event('password_changed', {'user_id': current_user['user_id']})
            
            return {'success': True, 'message': 'Password changed successfully'}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Password change failed: {str(e)}")

    @app.get("/api/security/audit-log")
    @require_permission("admin")
    @rate_limit('api')
    async def get_security_audit_log(
        limit: int = 100,
        offset: int = 0,
        event_type: Optional[str] = None,
        current_user: dict = Depends(get_current_user)
    ):
        """Get security audit log (admin only)"""
        try:
            # In production, query security events from database
            # This is a placeholder implementation
            
            events = [
                {
                    'timestamp': datetime.utcnow().isoformat(),
                    'event_type': 'login_success',
                    'user_id': current_user['user_id'],
                    'ip_address': '192.168.1.1',
                    'details': {'method': '2fa'}
                }
            ]
            
            return {
                'events': events,
                'total': len(events),
                'limit': limit,
                'offset': offset
            }
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Failed to retrieve audit log: {str(e)}")

else:
    # Security endpoints disabled - development mode
    @app.get("/api/security/status")
    async def security_status():
        return {'status': 'disabled', 'message': 'Security hardening not available in development mode'}

@app.get("/api/submission-pack")
async def get_submission_packs(
    project_id: Optional[str] = None,
    current_user: dict = Depends(get_current_user)
):
    """Get submission packs for project"""
    try:
        # TODO: Implement org-scoped pack retrieval
        mock_packs = [
            {
                "pack_id": "pack-1635789123",
                "project_id": project_id or "proj-123",
                "pack_name": "Full Planning Application",
                "document_count": 8,
                "total_size_mb": 24.5,
                "authority_token": "auth-456789",
                "status": "active",
                "created_at": "2024-10-02T14:30:00Z",
                "expires_at": "2025-01-02T14:30:00Z"
            }
        ]
        
        return {
            "success": True,
            "packs": mock_packs,
            "total": len(mock_packs)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch submission packs: {str(e)}")

# =====================================
# OBJECTION RISK & APPEALS MODULE
# =====================================

@app.get("/api/objection/themes")
async def get_objection_themes(
    lpa: str,
    current_user: dict = Depends(get_current_user)
):
    """Get objection themes for LPA"""
    try:
        # TODO: Implement objection corpus query
        mock_themes = [
            {
                "theme": "traffic_impact",
                "frequency": 85,
                "common_concerns": [
                    "Increased traffic congestion",
                    "Safety concerns at school times",
                    "Inadequate parking provision"
                ],
                "mitigations": [
                    "Comprehensive Traffic Impact Assessment",
                    "Travel Plan implementation",
                    "Junction improvement contribution"
                ],
                "citations": [
                    {
                        "policy": "Local Transport Plan",
                        "section": "Policy T1",
                        "url": f"https://{lpa}.gov.uk/transport-policy"
                    }
                ]
            },
            {
                "theme": "character_design",
                "frequency": 72,
                "common_concerns": [
                    "Out of character with area",
                    "Overdevelopment of site",
                    "Building height concerns"
                ],
                "mitigations": [
                    "Detailed Design and Access Statement",
                    "Character assessment",
                    "Community consultation"
                ],
                "citations": [
                    {
                        "policy": "Local Plan",
                        "section": "Policy DES1",
                        "url": f"https://{lpa}.gov.uk/local-plan"
                    }
                ]
            }
        ]
        
        return {
            "success": True,
            "lpa_code": lpa,
            "themes": mock_themes,
            "total_objections_analyzed": 1247,
            "last_updated": "2024-10-01T00:00:00Z"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch objection themes: {str(e)}")

@app.get("/api/appeals/cases")
async def get_appeals_cases(
    lpa: str,
    current_user: dict = Depends(get_current_user)
):
    """Get appeals cases for LPA"""
    try:
        # TODO: Implement appeals database query
        mock_cases = [
            {
                "appeal_ref": "APP/2024/123456",
                "application_ref": "24/00123/FUL",
                "decision": "allowed",
                "appeal_type": "written_representations",
                "development_type": "residential",
                "decision_date": "2024-09-15",
                "summary": "Appeal allowed due to insufficient harm to justify refusal",
                "key_issues": [
                    "Character and appearance",
                    "Highway safety",
                    "Residential amenity"
                ],
                "inspector_conclusions": [
                    "Limited harm to character area",
                    "Adequate visibility splays demonstrated",
                    "No significant overlooking issues"
                ],
                "url": "https://planninginspectorate.gov.uk/appeals/APP/2024/123456"
            }
        ]
        
        success_rate = random.randint(35, 65)
        
        return {
            "success": True,
            "lpa_code": lpa,
            "cases": mock_cases,
            "statistics": {
                "total_appeals": 45,
                "allowed": 28,
                "dismissed": 17,
                "success_rate_percent": success_rate,
                "average_determination_weeks": 12.5
            },
            "last_updated": "2024-10-01T00:00:00Z"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch appeals cases: {str(e)}")

# =====================================
# COLLABORATION MODULE
# =====================================

@app.post("/api/collab/invite")
async def invite_collaborator(
    invite_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Invite collaborator to project"""
    try:
        # TODO: Implement RBAC check and email invitation
        invite_id = f"invite-{int(time.time())}"
        
        invitation = {
            "invite_id": invite_id,
            "project_id": invite_data.get("project_id"),
            "email": invite_data.get("email"),
            "role": invite_data.get("role", "viewer"),
            "invited_by": current_user["email"],
            "invited_at": datetime.now().isoformat(),
            "status": "pending",
            "expires_at": (datetime.now() + timedelta(days=7)).isoformat()
        }
        
        return {
            "success": True,
            "invitation": invitation,
            "message": f"Invitation sent to {invite_data.get('email')}"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to send invitation: {str(e)}")

@app.post("/api/comments")
async def create_comment(
    comment_data: dict,
    current_user: dict = Depends(get_current_user)
):
    """Create comment on project"""
    try:
        # TODO: Implement comment creation with audit logging
        comment_id = f"comment-{int(time.time())}"
        
        comment = {
            "comment_id": comment_id,
            "project_id": comment_data.get("project_id"),
            "context": comment_data.get("context", "doc"),
            "body": comment_data.get("body"),
            "author": {
                "id": current_user["id"],
                "email": current_user["email"],
                "role": current_user["role"]
            },
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "comment": comment
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to create comment: {str(e)}")

# =====================================
# ADVANCED ANALYTICS MODULE
# =====================================

@app.get("/api/analytics/lpa")
async def get_lpa_analytics(
    lpa_code: Optional[str] = None,
    current_user: dict = Depends(get_current_user)
):
    """Get LPA performance analytics"""
    try:
        # TODO: Implement LPA metrics aggregation
        lpa_data = {
            "lpa_code": lpa_code or "E07000008",
            "lpa_name": "Cambridge City Council",
            "performance_metrics": {
                "approval_rate_percent": random.randint(70, 90),
                "average_decision_time_weeks": random.randint(10, 16),
                "appeal_success_rate_percent": random.randint(30, 60),
                "housing_delivery_test_percent": random.randint(85, 120),
                "five_year_land_supply_years": round(random.uniform(3.5, 6.2), 1),
                "tilted_balance_active": random.choice([True, False])
            },
            "trend_data": {
                "approval_rates_12m": [random.randint(70, 90) for _ in range(12)],
                "decision_times_12m": [random.randint(10, 16) for _ in range(12)],
                "application_volumes_12m": [random.randint(50, 150) for _ in range(12)]
            },
            "last_updated": "2024-10-01T00:00:00Z"
        }
        
        return {
            "success": True,
            "lpa_analytics": lpa_data
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch LPA analytics: {str(e)}")

@app.get("/api/analytics/org-insights")
async def get_org_insights(
    current_user: dict = Depends(get_current_user)
):
    """Get organization insights and knowledge graph"""
    try:
        # TODO: Implement org knowledge graph analysis
        insights = {
            "org_id": current_user["org_id"],
            "success_patterns": [
                {
                    "pattern": "Early community engagement",
                    "frequency": 12,
                    "success_rate_percent": 89,
                    "description": "Projects with early engagement have higher approval rates"
                },
                {
                    "pattern": "Comprehensive transport assessment",
                    "frequency": 8,
                    "success_rate_percent": 85,
                    "description": "Detailed transport work reduces objection risk"
                }
            ],
            "risk_factors": [
                {
                    "factor": "Insufficient parking provision",
                    "frequency": 6,
                    "impact_score": 75,
                    "mitigation": "Robust parking demand analysis"
                },
                {
                    "factor": "Heritage concerns",
                    "frequency": 4,
                    "impact_score": 65,
                    "mitigation": "Early heritage pre-application advice"
                }
            ],
            "performance_trends": {
                "approval_rate_6m": [82, 85, 78, 91, 88, 86],
                "average_determination_time_weeks": [14, 13, 15, 12, 13, 14],
                "cost_savings_gbp": [15000, 22000, 18000, 31000, 28000, 25000]
            },
            "recommendations": [
                "Consider standardizing community engagement approach",
                "Develop heritage assessment checklist",
                "Improve transport consultant briefing process"
            ],
            "last_updated": datetime.now().isoformat()
        }
        
        return {
            "success": True,
            "org_insights": insights
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to fetch org insights: {str(e)}")

# =====================================
# HEALTH & MONITORING ENDPOINTS
# =====================================

from health_monitoring import HealthService, FreshnessService, AlertService

@app.get("/health")
async def health_check():
    """Liveness check - basic service health"""
    try:
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "service": "domus-platform",
            "version": "1.0.0"
        }
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Service unhealthy: {str(e)}")

@app.get("/ready")
async def readiness_check(db: Session = Depends(get_db)):
    """Readiness check - verify all dependencies"""
    try:
        checks = {}
        overall_status = "ready"
        
        # Check database
        db_check = await HealthService.check_database()
        checks["database"] = db_check
        if db_check["status"] != "healthy":
            overall_status = "not_ready"
        
        # Check S3
        s3_check = await HealthService.check_s3()
        checks["s3"] = s3_check
        if s3_check["status"] != "healthy":
            overall_status = "not_ready"
        
        # Check Stripe
        stripe_check = await HealthService.check_stripe()
        checks["stripe"] = stripe_check
        if stripe_check["status"] != "healthy":
            overall_status = "not_ready"
        
        # Get system info
        system_info = await HealthService.get_system_info()
        checks["system"] = system_info
        
        # Get data freshness
        freshness = await FreshnessService.get_source_freshness(db)
        checks["data_freshness"] = freshness
        
        status_code = 200 if overall_status == "ready" else 503
        
        return {
            "status": overall_status,
            "timestamp": datetime.now().isoformat(),
            "checks": checks
        }
        
    except Exception as e:
        raise HTTPException(status_code=503, detail=f"Readiness check failed: {str(e)}")

@app.get("/api/monitoring/freshness")
async def get_freshness_status(
    current_user: dict = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Get data freshness status for authenticated users"""
    try:
        freshness = await FreshnessService.get_source_freshness(db)
        return {"freshness": freshness}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/monitoring/alert")
async def send_test_alert(
    request: Request,
    current_user: dict = Depends(get_current_user)
):
    """Send test alert (admin only)"""
    try:
        # Check if user is admin
        if current_user.get("role") not in ["admin", "super_admin"]:
            raise HTTPException(status_code=403, detail="Admin access required")
        
        body = await request.json()
        title = body.get("title", "Test Alert")
        message = body.get("message", "This is a test alert from Domus Platform")
        level = body.get("level", "info")
        
        success = await AlertService.send_alert(title, message, level)
        
        return {"success": success, "message": "Alert sent" if success else "Failed to send alert"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    print("\nStarting Domus Professional Platform...")
    uvicorn.run(app, host="0.0.0.0", port=8000)